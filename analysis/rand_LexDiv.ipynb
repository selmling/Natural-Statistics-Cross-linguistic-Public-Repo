{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e95ac1c",
   "metadata": {},
   "source": [
    "# Natural Statistics Cross-linguistic: \n",
    "\n",
    "#### Lexical diversity analysis - random sample \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0, \"data_proc\")\n",
    "import analytic_proc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_dat_inc = pd.read_csv(\"../data/rand_dat_inc_master.csv\",index_col=0,low_memory=False)\n",
    "rand_dat_inc=rand_dat_inc[rand_dat_inc[\"language\"]!=\"ara\"]\n",
    "rand_dat_inc=rand_dat_inc[(rand_dat_inc[\"target_child_age\"]>=5) & (rand_dat_inc[\"target_child_age\"]<=30)]\n",
    "\n",
    "rand_dat_inc_cg = rand_dat_inc[rand_dat_inc[\"caregiver\"]==\"caregiver\"]\n",
    "\n",
    "rand_dat_inc_cg[\"contingent\"] = np.where(rand_dat_inc_cg[\"contingent\"]==1, \"contingent\", \"non-contingent\")\n",
    "\n",
    "rand_dat_inc_cg = rand_dat_inc_cg[rand_dat_inc_cg[\"gloss\"].notna()]\n",
    "rand_dat_inc_cg = rand_dat_inc_cg[rand_dat_inc_cg[\"gloss\"]!=\"xxx\"]\n",
    "rand_dat_inc_cg = rand_dat_inc_cg[rand_dat_inc_cg[\"gloss\"]!=\"yyy\"]\n",
    "rand_dat_inc_cg = rand_dat_inc_cg[rand_dat_inc_cg[\"gloss\"]!=\"www\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would call the following if we could run lexical diversity analysis globally:\n",
    "\n",
    "```python\n",
    "analytic_proc.create_result(rand_dat_inc_cg)\n",
    "```\n",
    "\n",
    "However, we want to have seperate dictionaries for contingent and non-contingent words so we can compare them to one another.\n",
    "\n",
    "The function will allow us to have a different dictionary for each transcript.\n",
    "\n",
    "Finally, to compare, we can run mixed effects to understand whether contingent and non-contingent utterances differ in their lexical diversity, controlling for number of transcripts."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### Seperate contingent and non-contingent utterances into individual dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_dat_inc_cg_cc = rand_dat_inc_cg[rand_dat_inc_cg[\"contingent\"]==\"contingent\"].reset_index(drop=True)\n",
    "rand_dat_inc_cg_nc = rand_dat_inc_cg[rand_dat_inc_cg[\"contingent\"]==\"non-contingent\"].reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### Loop through each unique transcript to compute the lexical diversity counts across languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "analytic_proc.create_c_result(rand_dat_inc_cg_cc,\"rand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "analytic_proc.create_nc_result(rand_dat_inc_cg_nc,\"rand\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### Lexical Diversity plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_dat_inc_cg_cc = pd.read_csv(\"../data/rand_dat_inc_master_cc_lexdiv.csv\",index_col=0,low_memory=False)\n",
    "rand_dat_inc_cg_nc = pd.read_csv(\"../data/rand_dat_inc_master_nc_lexdiv.csv\",index_col=0,low_memory=False)\n",
    "\n",
    "# combine dataframes into one\n",
    "\n",
    "rand_dat_inc_cg = pd.concat([rand_dat_inc_cg_cc,rand_dat_inc_cg_nc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "470b2a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add play context and year of study\n",
    "\n",
    "play_context = pd.read_csv(\"../data/context_data.csv\")\n",
    "play_context = play_context.rename(columns={\"Corpus\": \"corpus_name\"})\n",
    "\n",
    "# print(play_context.to_markdown())\n",
    "\n",
    "rand_dat_inc_cg = rand_dat_inc_cg.merge(play_context,on='corpus_name',how=\"right\")\n",
    "\n",
    "rand_dat_inc_cg[\"context\"] = rand_dat_inc_cg[\"Location\"] + rand_dat_inc_cg[\"Activity\"]\n",
    "\n",
    "rand_dat_inc_cg[\"context\"] = rand_dat_inc_cg[\"context\"].replace({\"HomeBook-reading\":\"Home: book reading\",\n",
    "                                                                 \"HomeInterview/Unstructured\":\"Home: interview/unstructured\",\n",
    "                                                                 \"HomeNaN\":\"Home: unreported\",\n",
    "                                                                 \"HomeOther\":\"Home: other\",\n",
    "                                                                 \"HomeUnstructured\":\"Home: unstructured\",\n",
    "                                                                 \"LabOther\":\"Lab: other\",\n",
    "                                                                 \"LabTabletop play\":\"Lab: tabletop play\",\n",
    "                                                                 \"LabInterview/Unstructured\":\"Lab: interview/unstructured\",\n",
    "                                                                 \"LabUnstructured\":\"Lab: unstructured\",\n",
    "                                                                 \"NaNNaN\":\"Unreported\",\n",
    "                                                                 \"OtherUnstructured\":\"Other: unstructured\"})\n",
    "\n",
    "# year of study\n",
    "corpora_year = pd.read_csv(\"../data/corpora_year.csv\")\n",
    "corpora_year = corpora_year.rename(columns={\"Corpora\": \"corpus_name\"})\n",
    "\n",
    "rand_dat_inc_cg = rand_dat_inc_cg.merge(corpora_year,on='corpus_name',how=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | stat   |      age |\n",
      "|---:|:-------|---------:|\n",
      "|  0 | min    |  5.98575 |\n",
      "|  1 | max    | 29.9862  |\n",
      "|  2 | mean   | 19.033   |\n",
      "|  3 | stdev  |  6.75331 |\n"
     ]
    }
   ],
   "source": [
    "ar = [['min', rand_dat_inc_cg[\"target_child_age\"].min()],\n",
    "      ['max', rand_dat_inc_cg[\"target_child_age\"].max()],\n",
    "      ['mean', rand_dat_inc_cg[\"target_child_age\"].mean()],\n",
    "      ['stdev', rand_dat_inc_cg[\"target_child_age\"].std()]]\n",
    "\n",
    "age_range = pd.DataFrame(ar, columns = ['stat', 'age'])\n",
    "\n",
    "print(age_range.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_lex_stats = (rand_dat_inc_cg.groupby([\"Language_name\",\"target_child_id\",\"transcript_id\",\"contingent\", 'context'])\n",
    "                                  .uniquenss\n",
    "                                  .agg([\"sum\"])\n",
    "                                  .reset_index())\n",
    "rand_lex_sumstats =  rand_lex_stats.rename({'sum': 'sums'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rand_lex_sumstats[\"Language_name\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1461"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rand_lex_sumstats[\"transcript_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_lex_sumstats.to_csv(\"../data/rand_lex_sumstats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Loading required package: Matrix\n",
      "\n",
      "R[write to console]: ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n",
      "\n",
      "R[write to console]: ✔ ggplot2 3.4.2     ✔ purrr   1.0.1\n",
      "✔ tibble  3.2.1     ✔ dplyr   1.1.2\n",
      "✔ tidyr   1.3.0     ✔ stringr 1.5.0\n",
      "✔ readr   2.1.4     ✔ forcats 1.0.0\n",
      "\n",
      "R[write to console]: ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "✖ tidyr::expand() masks Matrix::expand()\n",
      "✖ dplyr::filter() masks stats::filter()\n",
      "✖ dplyr::lag()    masks stats::lag()\n",
      "✖ tidyr::pack()   masks Matrix::pack()\n",
      "✖ tidyr::unpack() masks Matrix::unpack()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R -i rand_lex_sumstats\n",
    "\n",
    "library(\"lme4\")\n",
    "library(\"repr\")\n",
    "library(\"repr\")\n",
    "library(\"knitr\")\n",
    "library(\"broom\")\n",
    "library(\"emmeans\")\n",
    "library(\"tidyverse\")\n",
    "\n",
    "options(repr.plot.width=6, repr.plot.height=12, scipen=999)\n",
    "\n",
    "xlabs <- c(\"C\", \"NC\")\n",
    "\n",
    "# ara_label <- data.frame(means=c(0),contingent = c(1.5),language=\"ara\") # no adult speech transcribed\n",
    "deu_label <- data.frame(sums=c(240),contingent = c(1.5),Language_name=\"German\")\n",
    "eng_label <- data.frame(sums=c(240),contingent = c(1.5),Language_name=\"English\")\n",
    "est_label <- data.frame(sums=c(240),contingent = c(1.5),Language_name=\"Estonian\")\n",
    "fas_label <- data.frame(sums=c(240),contingent = c(1.5),Language_name=\"Persian\")\n",
    "fra_label <- data.frame(sums=c(240),contingent = c(1.5),Language_name=\"French\")\n",
    "hrv_label <- data.frame(sums=c(240),contingent = c(1.5),Language_name=\"Croatian\")\n",
    "jpn_label <- data.frame(sums=c(240),contingent = c(1.5),Language_name=\"Japanese\")\n",
    "kor_label <- data.frame(sums=c(240),contingent = c(1.5),Language_name=\"Korean\")\n",
    "# nor_label <- data.frame(means=c(5.8),contingent = c(1.5),Language_name=\"Norwegian\")\n",
    "nor_ns_label <- data.frame(sums=c(247),contingent = c(1.5),Language_name=\"Norwegian\")\n",
    "pol_ns_label <- data.frame(sums=c(247),contingent = c(1.5),Language_name=\"Polish\")\n",
    "por_label <- data.frame(sums=c(240),contingent = c(1.5),Language_name=\"Portuguese\")\n",
    "spa_ns_label <- data.frame(sums=c(247),contingent = c(1.5),Language_name=\"Spanish\")\n",
    "swe_label <- data.frame(sums=c(247),contingent = c(1.5),Language_name=\"Swedish\")\n",
    "zho_label <- data.frame(sums=c(240),contingent = c(1.5),Language_name=\"Mandarin\")\n",
    "# zho_ns_label <- data.frame(means=c(6),contingent = c(1.5),Language_name=\"Mandarin\")\n",
    "\n",
    "\n",
    "p <- ggplot(rand_lex_sumstats, aes(x = contingent, y = sums, color = Language_name)) +\n",
    "     stat_summary(fun.y=mean, geom=\"point\", shape=19, size=1.75) + \n",
    "     stat_summary(fun.data = mean_se, geom = \"errorbar\", size=1.25, width = .5) +\n",
    "     facet_wrap(. ~ Language_name,ncol = 7) + \n",
    "     geom_text(data = deu_label,label = \"***\",size=8,color=\"black\") + \n",
    "     geom_text(data = eng_label,label = \"***\",size=8,color=\"black\") +  \n",
    "     geom_text(data = est_label,label = \"**\",size=8,color=\"black\") +  \n",
    "#      geom_text(data = fas_ns_label,label = \"*\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "     geom_text(data = fas_label,label = \"*\",size=8, color=\"black\") +\n",
    "     geom_text(data = fra_label,label = \"***\",size=8,color=\"black\") +  \n",
    "     geom_text(data = hrv_label,label = \"***\",size=8,color=\"black\") + \n",
    "     geom_text(data = jpn_label,label = \"***\",size=8,color=\"black\") + \n",
    "     geom_text(data = kor_label,label = \"***\",size=8,color=\"black\") +  \n",
    "     geom_text(data = nor_ns_label,label = \"ns\",size=4,color=\"black\",fontface = \"italic\") +  \n",
    "#      geom_text(data = pol_ns_label,label = \"ns\", size=4,color=\"black\",fontface = \"italic\") +  \n",
    "     geom_text(data = por_label,label = \"**\",size=8,color=\"black\") +  \n",
    "     geom_text(data = spa_ns_label,label = \"ns\",size=4,color=\"black\",fontface = \"italic\") + \n",
    "     geom_text(data = swe_label,label = \"ns\",size=4,color=\"black\",fontface = \"italic\") + \n",
    "#      geom_text(data = zho_ns_label,label = \"ns\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "     geom_text(data = zho_label,label = \"^\",size=8, color=\"black\") +\n",
    "     ylim(0, 250) +\n",
    "     labs(tag = \"A\",\n",
    "          y = \"Number of Unique Words\", x = \"\") +\n",
    "     theme_classic() +\n",
    "     scale_x_discrete(labels= xlabs) +\n",
    "     theme(text = element_text(size=16),\n",
    "           axis.text.x = element_text(vjust = 0.5, hjust=.5),\n",
    "           legend.title = element_blank(),\n",
    "           legend.background = element_rect(fill=alpha(\"white\",0.90),\n",
    "                                                            size=0, linetype=\"dotted\",\n",
    "                                                            colour = \"white\"),\n",
    "           legend.text=element_text(size=16))\n",
    "     ggsave(\"../figures/lexical_diversity_rand.pdf\", width = 11.7, height = 6.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for manuscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i rand_lex_sumstats\n",
    "\n",
    "library('ggplot2')\n",
    "library('repr')\n",
    "options(repr.plot.width=6, repr.plot.height=12)\n",
    "\n",
    "xlabs <- c(\"C\", \"NC\")\n",
    "\n",
    "# ara_label <- data.frame(means=c(0),contingent = c(1.5),language=\"ara\") # no adult speech transcribed\n",
    "deu_label <- data.frame(sums=c(235),contingent = c(1.5),Language_name=\"German\")\n",
    "eng_label <- data.frame(sums=c(235),contingent = c(1.5),Language_name=\"English\")\n",
    "est_label <- data.frame(sums=c(235),contingent = c(1.5),Language_name=\"Estonian\")\n",
    "fas_label <- data.frame(sums=c(235),contingent = c(1.5),Language_name=\"Persian\")\n",
    "fra_label <- data.frame(sums=c(235),contingent = c(1.5),Language_name=\"French\")\n",
    "hrv_label <- data.frame(sums=c(235),contingent = c(1.5),Language_name=\"Croatian\")\n",
    "jpn_label <- data.frame(sums=c(235),contingent = c(1.5),Language_name=\"Japanese\")\n",
    "kor_label <- data.frame(sums=c(235),contingent = c(1.5),Language_name=\"Korean\")\n",
    "# nor_label <- data.frame(means=c(5.8),contingent = c(1.5),Language_name=\"Norwegian\")\n",
    "nor_ns_label <- data.frame(sums=c(247),contingent = c(1.5),Language_name=\"Norwegian\")\n",
    "pol_ns_label <- data.frame(sums=c(247),contingent = c(1.5),Language_name=\"Polish\")\n",
    "por_label <- data.frame(sums=c(235),contingent = c(1.5),Language_name=\"Portuguese\")\n",
    "spa_ns_label <- data.frame(sums=c(247),contingent = c(1.5),Language_name=\"Spanish\")\n",
    "swe_label <- data.frame(sums=c(247),contingent = c(1.5),Language_name=\"Swedish\")\n",
    "zho_label <- data.frame(sums=c(235),contingent = c(1.5),Language_name=\"Mandarin\")\n",
    "# zho_ns_label <- data.frame(means=c(6),contingent = c(1.5),Language_name=\"Mandarin\")\n",
    "\n",
    "\n",
    "p <- ggplot(rand_lex_sumstats, aes(x = contingent, y = sums, color = Language_name)) +\n",
    "     stat_summary(fun.y=mean, geom=\"point\", shape=19, size=1.75) + \n",
    "     stat_summary(fun.data = mean_se, geom = \"errorbar\", size=1.25, width = .4) +\n",
    "     facet_wrap(. ~ Language_name,ncol = 7) + \n",
    "     geom_text(data = deu_label,label = \"***\",size=6,color=\"black\") + \n",
    "     geom_text(data = eng_label,label = \"***\",size=6,color=\"black\") +  \n",
    "     geom_text(data = est_label,label = \"**\",size=6,color=\"black\") +  \n",
    "     geom_text(data = fas_label,label = \"*\",size=6, color=\"black\") +\n",
    "     geom_text(data = fra_label,label = \"***\",size=6,color=\"black\") +  \n",
    "     geom_text(data = hrv_label,label = \"***\",size=6,color=\"black\") + \n",
    "     geom_text(data = jpn_label,label = \"***\",size=6,color=\"black\") + \n",
    "     geom_text(data = kor_label,label = \"***\",size=6,color=\"black\") +  \n",
    "     geom_text(data = nor_ns_label,label = \"ns\",size=3,color=\"black\",fontface = \"italic\") +  \n",
    "     geom_text(data = por_label,label = \"**\",size=6,color=\"black\") +  \n",
    "     geom_text(data = spa_ns_label,label = \"ns\",size=3,color=\"black\",fontface = \"italic\") + \n",
    "     geom_text(data = swe_label,label = \"ns\",size=3,color=\"black\",fontface = \"italic\") + \n",
    "     geom_text(data = zho_label,label = \"^\",size=3, color=\"black\") +\n",
    "     ylim(0, 250) +\n",
    "     labs(tag = \"A\",\n",
    "          y = \"Number of Unique Words\", x = \"\") +\n",
    "     theme_classic() +\n",
    "     scale_x_discrete(labels= xlabs) +\n",
    "     theme(text = element_text(size=11.5),\n",
    "           axis.text.x = element_text(vjust = 0.5, hjust=0.5),\n",
    "           legend.position=\"none\")\n",
    "     ggsave(\"../figures/figure_2_A.pdf\", width = 11.5, height = 4.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot + effect estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "deu_est_label <- data.frame(sums=c(.25),contingent = c(1),Language_name=\"German\")\n",
    "eng_est_label <- data.frame(sums=c(.25),contingent = c(1),Language_name=\"English\")\n",
    "est_est_label <- data.frame(sums=c(.25),contingent = c(1),Language_name=\"Estonian\")\n",
    "fas_est_label <- data.frame(sums=c(.25),contingent = c(1),Language_name=\"Persian\")\n",
    "fra_est_label <- data.frame(sums=c(.25),contingent = c(1),Language_name=\"French\")\n",
    "hrv_est_label <- data.frame(sums=c(.25),contingent = c(1),Language_name=\"Croatian\")\n",
    "jpn_est_label <- data.frame(sums=c(.25),contingent = c(1),Language_name=\"Japanese\")\n",
    "kor_est_label <- data.frame(sums=c(.25),contingent = c(1),Language_name=\"Korean\")\n",
    "nor_est_label <- data.frame(sums=c(.25),contingent = c(1),Language_name=\"Norwegian\")\n",
    "por_est_label <- data.frame(sums=c(.25),contingent = c(1),Language_name=\"Portuguese\")\n",
    "spa_est_label <- data.frame(sums=c(.25),contingent = c(1),Language_name=\"Spanish\")\n",
    "swe_est_label <- data.frame(sums=c(.25),contingent = c(1),Language_name=\"Swedish\")\n",
    "zho_est_label <- data.frame(sums=c(.25),contingent = c(1),Language_name=\"Mandarin\")\n",
    "\n",
    "p <- p + geom_text(data = deu_est_label,label = \"est=-66\",size=4,color=\"black\") +\n",
    "         geom_text(data = eng_est_label,label = \"est=-122\",size=4,color=\"black\") +\n",
    "         geom_text(data = est_est_label,label = \"est=-54.2\",size=4,color=\"black\") +\n",
    "         geom_text(data = fas_est_label,label = \"est=-51.1\",size=4,color=\"black\") +\n",
    "         geom_text(data = fra_est_label,label = \"est=-67.3\",size=4,color=\"black\") +\n",
    "         geom_text(data = hrv_est_label,label = \"est=-37.5\",size=4,color=\"black\") +\n",
    "         geom_text(data = jpn_est_label,label = \"est=-41.9\",size=4,color=\"black\") +\n",
    "         geom_text(data = kor_est_label,label = \"est=-101\",size=4,color=\"black\") +\n",
    "#          geom_text(data = nor_est_label,label = \"est=-.68\",size=4,color=\"black\") +\n",
    "         geom_text(data = por_est_label,label = \"est=-32.5\",size=4,color=\"black\") +\n",
    "#          geom_text(data = spa_est_label,label = \"est=-.39\",size=4,color=\"black\") +\n",
    "         geom_text(data = swe_est_label,label = \"est=-43.4\",size=4,color=\"black\") +\n",
    "         geom_text(data = zho_est_label,label = \"est=-60\",size=4,color=\"black\")\n",
    "         \n",
    "\n",
    "ggsave(\"../figures/lexical_diversity_rand_eff.pdf\", width = 11.7, height = 6.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\+ sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "deu_n_label <- data.frame(sums=c(.25),contingent = c(1.7),Language_name=\"German\")\n",
    "eng_n_label <- data.frame(sums=c(.25),contingent = c(1.7),Language_name=\"English\")\n",
    "est_n_label <- data.frame(sums=c(.25),contingent = c(1.7),Language_name=\"Estonian\")\n",
    "fas_n_label <- data.frame(sums=c(.25),contingent = c(1.7),Language_name=\"Persian\")\n",
    "fra_n_label <- data.frame(sums=c(.25),contingent = c(1.7),Language_name=\"French\")\n",
    "hrv_n_label <- data.frame(sums=c(.25),contingent = c(1.7),Language_name=\"Croatian\")\n",
    "jpn_n_label <- data.frame(sums=c(.25),contingent = c(1.7),Language_name=\"Japanese\")\n",
    "kor_n_label <- data.frame(sums=c(.25),contingent = c(1.7),Language_name=\"Korean\")\n",
    "nor_n_label <- data.frame(sums=c(.25),contingent = c(1.7),Language_name=\"Norwegian\")\n",
    "pol_n_label <- data.frame(sums=c(.25),contingent = c(1.7),Language_name=\"Polish\")\n",
    "por_n_label <- data.frame(sums=c(.25),contingent = c(1.7),Language_name=\"Portuguese\")\n",
    "spa_n_label <- data.frame(sums=c(.25),contingent = c(1.7),Language_name=\"Spanish\")\n",
    "swe_n_label <- data.frame(sums=c(.25),contingent = c(1.7),Language_name=\"Swedish\")\n",
    "zho_n_label <- data.frame(sums=c(.25),contingent = c(1.7),Language_name=\"Mandarin\")\n",
    "\n",
    "deu_sz_label <- data.frame(sums=c(.25),contingent = c(2.1),Language_name=\"German\")\n",
    "eng_sz_label <- data.frame(sums=c(.25),contingent = c(2.1),Language_name=\"English\")\n",
    "est_sz_label <- data.frame(sums=c(.25),contingent = c(2.1),Language_name=\"Estonian\")\n",
    "fas_sz_label <- data.frame(sums=c(.25),contingent = c(2.1),Language_name=\"Persian\")\n",
    "fra_sz_label <- data.frame(sums=c(.25),contingent = c(2.1),Language_name=\"French\")\n",
    "hrv_sz_label <- data.frame(sums=c(.25),contingent = c(2.1),Language_name=\"Croatian\")\n",
    "jpn_sz_label <- data.frame(sums=c(.25),contingent = c(2.1),Language_name=\"Japanese\")\n",
    "kor_sz_label <- data.frame(sums=c(.25),contingent = c(2.1),Language_name=\"Korean\")\n",
    "nor_sz_label <- data.frame(sums=c(.25),contingent = c(2.1),Language_name=\"Norwegian\")\n",
    "pol_sz_label <- data.frame(sums=c(.25),contingent = c(2.1),Language_name=\"Polish\")\n",
    "por_sz_label <- data.frame(sums=c(.25),contingent = c(2.1),Language_name=\"Portuguese\")\n",
    "spa_sz_label <- data.frame(sums=c(.25),contingent = c(2.1),Language_name=\"Spanish\")\n",
    "swe_sz_label <- data.frame(sums=c(.25),contingent = c(2.1),Language_name=\"Swedish\")\n",
    "zho_sz_label <- data.frame(sums=c(.25),contingent = c(2.1),Language_name=\"Mandarin\")\n",
    "\n",
    "p <- p + geom_text(data = deu_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = eng_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = est_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = fas_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = fra_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = hrv_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = jpn_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = kor_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = nor_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = pol_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = por_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = spa_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = swe_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = zho_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = deu_sz_label,label = \" = 39\",size=4,color=\"black\") +\n",
    "         geom_text(data = eng_sz_label,label = \" = 1005\",size=4,color=\"black\") +\n",
    "         geom_text(data = est_sz_label,label = \" = 22\",size=4,color=\"black\") +\n",
    "         geom_text(data = fas_sz_label,label = \" = 12\",size=4,color=\"black\") +\n",
    "         geom_text(data = fra_sz_label,label = \" = 303\",size=4,color=\"black\") +\n",
    "         geom_text(data = hrv_sz_label,label = \" = 79\",size=4,color=\"black\") +\n",
    "         geom_text(data = jpn_sz_label,label = \" = 139\",size=4,color=\"black\") +\n",
    "         geom_text(data = kor_sz_label,label = \" = 37\",size=4,color=\"black\") +\n",
    "         geom_text(data = nor_sz_label,label = \" = 56\",size=4,color=\"black\") +\n",
    "         geom_text(data = pol_sz_label,label = \" = 1\",size=4,color=\"black\") +\n",
    "         geom_text(data = por_sz_label,label = \" = 24\",size=4,color=\"black\") +\n",
    "         geom_text(data = spa_sz_label,label = \" = 31\",size=4,color=\"black\") +\n",
    "         geom_text(data = swe_sz_label,label = \" = 16\",size=4,color=\"black\") +\n",
    "         geom_text(data = zho_sz_label,label = \" = 2\",size=4,color=\"black\")\n",
    "         \n",
    "\n",
    "ggsave(\"../figures/lexical_diversity_rand_eff_n.pdf\", width = 11.7, height = 6.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2657c43",
   "metadata": {},
   "source": [
    "#### Statistical analyses\n",
    "\n",
    "By language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ac4a35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_lex_sumstats = rand_lex_sumstats[['Language_name','sums','contingent','transcript_id','target_child_id', 'context']]\n",
    "\n",
    "rand_dat_inc_cg_count = rand_dat_inc_cg[['Language_name','transcript_id','target_child_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc9e213b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "|Language_name |target_child_id |transcript_id |contingent |context                                                                                                                                                                                                                               |sums |\n",
      "|:-------------|:---------------|:-------------|:----------|:-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:----|\n",
      "|NULL          |NULL            |NULL          |NULL       |Home: book reading          , Home: interview/unstructured, Home: other                 , Home: unstructured          , Lab: interview/unstructured , Lab: tabletop play          , Lab: unstructured           , Other: unstructured |NULL |\n"
     ]
    }
   ],
   "source": [
    "%%R \n",
    "\n",
    "library(\"kableExtra\")\n",
    "\n",
    "rand_lex_sumstats %>%\n",
    "     mutate_at(c('context'), as.factor) %>% \n",
    "     summarise_each(funs(list(levels(.)))) %>%\n",
    "     kable(\"pipe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6ce845dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in `mutate()`:\n",
      "ℹ In argument: `fit = map(...)`.\n",
      "ℹ In group 1: `Language_name = \"Croatian\"`.\n",
      "Caused by error in `map()`:\n",
      "ℹ In index: 1.\n",
      "Caused by error in `contrasts<-`:\n",
      "! contrasts can be applied only to factors with 2 or more levels\n",
      "Run `rlang::last_trace()` to see where the error occurred.\n",
      "\n",
      "Error in mutate(., fit = map(data, ~lmer(sums ~ contingent + context +  : \n",
      "  \n",
      "ℹ In group 1: `Language_name = \"Croatian\"`.\n",
      "Caused by error in `map()`:\n",
      "ℹ In index: 1.\n",
      "Caused by error in `contrasts<-`:\n",
      "! contrasts can be applied only to factors with 2 or more levels\n"
     ]
    },
    {
     "ename": "RInterpreterError",
     "evalue": "Failed to parse and evaluate line '\\n# vectors for rows to remove from lmer\\ncase_study <- c(\"Korean\", \"Mandarin\", \"Persian\") # only 1 target child analyzed\\n\\nsingle_tran <- c(\"Polish\") # only 1 transcript\\n\\n# nests of models\\nlexdiv_nest1 <- rand_lex_sumstats %>%\\n    mutate_at(c(\\'context\\'), as.factor) %>%\\n    filter(!Language_name %in% case_study) %>%\\n    filter(!Language_name %in% single_tran) %>%\\n    group_by(Language_name) %>%\\n    nest() %>%\\n    mutate(fit = map(data, ~ lmer(sums ~ contingent + context +\\n                                (1|target_child_id) +\\n                                (1|transcript_id),\\n                                data = .,\\n                                REML= FALSE)),\\n           summary = map(fit, ~ emmeans(., \"contingent\")),\\n           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\\n           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\\n    select(Language_name, contrasts, effect_size) %>%\\n    unnest(cols = c(contrasts)) %>%\\n    mutate(effect_size = map(effect_size, ~ summary(.))) %>%\\n    unnest() %>%\\n    mutate(statistic = coalesce(`t.ratio`), .before = p.value) %>%\\n    select (-c(`t.ratio`))\\n\\n# lexdiv_nest2 <- rand_lex_sumstats %>%\\n#     filter(Language_name %in% case_study) %>%\\n#     group_by(Language_name) %>%\\n#     nest() %>%\\n#     mutate(fit = map(data, ~ lmer(sums ~ contingent +\\n#                                 (1|transcript_id),\\n#                                 data = .,\\n#                                 REML= FALSE)),\\n#            summary = map(fit, ~ emmeans(., \"contingent\")),\\n#            contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\\n#            effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\\n#     select(Language_name, contrasts, effect_size) %>%\\n#     unnest(cols = c(contrasts)) %>%\\n#     mutate(effect_size = map(effect_size, ~ summary(.))) %>%\\n#     unnest() %>%\\n#     mutate(statistic = coalesce(`t.ratio`), .before = p.value) %>%\\n#     select (-c(`t.ratio`))\\n\\n# lexdiv_nest3 <- rand_lex_sumstats %>%\\n#     filter(Language_name %in% single_tran) %>%\\n#     group_by(Language_name) %>%\\n#     nest() %>%\\n#     mutate(fit = map(data, ~ lm(sums ~ contingent,\\n#                                 data = .,\\n#                                 REML= FALSE)),\\n#            summary = map(fit, ~ emmeans(., \"contingent\")),\\n#            contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\")))) %>%\\n#     select(Language_name, contrasts) %>%\\n#     unnest(cols = c(contrasts))  %>%\\n#     rename(statistic = `t.ratio`)\\n    \\n# # number of transcripts per language\\n# sample_size <- rand_dat_inc_cg_count %>%\\n#     group_by(Language_name) %>%\\n#     summarize(n = n_distinct(transcript_id))\\n    \\n# # combine lmer summaries and correct p-values for multiple comparisons\\n# emms_all <- list(lexdiv_nest1, lexdiv_nest2, lexdiv_nest3) %>% \\n#     reduce(bind_rows) %>%\\n#     mutate(p.value = p.adjust(p.value, \"holm\", 14)) %>%\\n#     left_join(sample_size)\\n'.\nR error message: 'Error in mutate(., fit = map(data, ~lmer(sums ~ contingent + context +  : \\n  \\nℹ In group 1: `Language_name = \"Croatian\"`.\\nCaused by error in `map()`:\\nℹ In index: 1.\\nCaused by error in `contrasts<-`:\\n! contrasts can be applied only to factors with 2 or more levels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRRuntimeError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/rpy2/ipython/rmagic.py:385\u001b[0m, in \u001b[0;36mRMagics.eval\u001b[0;34m(self, code)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m     \u001b[39m# Need the newline in case the last line in code is a comment.\u001b[39;00m\n\u001b[0;32m--> 385\u001b[0m     value, visible \u001b[39m=\u001b[39m ro\u001b[39m.\u001b[39;49mr(\u001b[39m\"\u001b[39;49m\u001b[39mwithVisible(\u001b[39;49m\u001b[39m{\u001b[39;49m\u001b[39m%s\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m})\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m%\u001b[39;49m code)\n\u001b[1;32m    386\u001b[0m \u001b[39mexcept\u001b[39;00m (ri\u001b[39m.\u001b[39membedded\u001b[39m.\u001b[39mRRuntimeError, \u001b[39mValueError\u001b[39;00m) \u001b[39mas\u001b[39;00m exception:\n\u001b[1;32m    387\u001b[0m     \u001b[39m# Otherwise next return seems to have copy of error.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/rpy2/robjects/__init__.py:459\u001b[0m, in \u001b[0;36mR.__call__\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    458\u001b[0m p \u001b[39m=\u001b[39m rinterface\u001b[39m.\u001b[39mparse(string)\n\u001b[0;32m--> 459\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meval(p)\n\u001b[1;32m    460\u001b[0m \u001b[39mreturn\u001b[39;00m conversion\u001b[39m.\u001b[39mget_conversion()\u001b[39m.\u001b[39mrpy2py(res)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/rpy2/robjects/functions.py:208\u001b[0m, in \u001b[0;36mSignatureTranslatedFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m         kwargs[r_k] \u001b[39m=\u001b[39m v\n\u001b[0;32m--> 208\u001b[0m \u001b[39mreturn\u001b[39;00m (\u001b[39msuper\u001b[39;49m(SignatureTranslatedFunction, \u001b[39mself\u001b[39;49m)\n\u001b[1;32m    209\u001b[0m         \u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/rpy2/robjects/functions.py:131\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m         new_kwargs[k] \u001b[39m=\u001b[39m cv\u001b[39m.\u001b[39mpy2rpy(v)\n\u001b[0;32m--> 131\u001b[0m res \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m(Function, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49mnew_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mnew_kwargs)\n\u001b[1;32m    132\u001b[0m res \u001b[39m=\u001b[39m cv\u001b[39m.\u001b[39mrpy2py(res)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/rpy2/rinterface_lib/conversion.py:45\u001b[0m, in \u001b[0;36m_cdata_res_to_rinterface.<locals>._\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m---> 45\u001b[0m     cdata \u001b[39m=\u001b[39m function(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     46\u001b[0m     \u001b[39m# TODO: test cdata is of the expected CType\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/rpy2/rinterface.py:817\u001b[0m, in \u001b[0;36mSexpClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[39mif\u001b[39;00m error_occured[\u001b[39m0\u001b[39m]:\n\u001b[0;32m--> 817\u001b[0m         \u001b[39mraise\u001b[39;00m embedded\u001b[39m.\u001b[39mRRuntimeError(_rinterface\u001b[39m.\u001b[39m_geterrmessage())\n\u001b[1;32m    818\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "\u001b[0;31mRRuntimeError\u001b[0m: Error in mutate(., fit = map(data, ~lmer(sums ~ contingent + context +  : \n  \nℹ In group 1: `Language_name = \"Croatian\"`.\nCaused by error in `map()`:\nℹ In index: 1.\nCaused by error in `contrasts<-`:\n! contrasts can be applied only to factors with 2 or more levels\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRInterpreterError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m get_ipython()\u001b[39m.\u001b[39;49mrun_cell_magic(\u001b[39m'\u001b[39;49m\u001b[39mR\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m-i rand_lex_sumstats -i rand_dat_inc_cg_count\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m# vectors for rows to remove from lmer\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39mcase_study <- c(\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mKorean\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m, \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mMandarin\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m, \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPersian\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m) # only 1 target child analyzed\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39msingle_tran <- c(\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPolish\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m) # only 1 transcript\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m# nests of models\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39mlexdiv_nest1 <- rand_lex_sumstats \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m>\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m    mutate_at(c(\u001b[39;49m\u001b[39m\\'\u001b[39;49;00m\u001b[39mcontext\u001b[39;49m\u001b[39m\\'\u001b[39;49;00m\u001b[39m), as.factor) \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m>\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m    filter(!Language_name \u001b[39;49m\u001b[39m%i\u001b[39;49;00m\u001b[39mn\u001b[39;49m\u001b[39m% c\u001b[39;49;00m\u001b[39mase_study) \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m>\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m    filter(!Language_name \u001b[39;49m\u001b[39m%i\u001b[39;49;00m\u001b[39mn\u001b[39;49m\u001b[39m% s\u001b[39;49;00m\u001b[39mingle_tran) \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m>\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m    group_by(Language_name) \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m>\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m    nest() \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m>\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m    mutate(fit = map(data, ~ lmer(sums ~ contingent + context +\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m                                (1|target_child_id) +\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m                                (1|transcript_id),\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m                                data = .,\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m                                REML= FALSE)),\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m           summary = map(fit, ~ emmeans(., \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcontingent\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m)),\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m           contrasts = map(summary, ~ summary(contrast(., method = \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpairwise\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m))),\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m>\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m    select(Language_name, contrasts, effect_size) \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m>\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m    unnest(cols = c(contrasts)) \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m>\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m    mutate(effect_size = map(effect_size, ~ summary(.))) \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m>\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m    unnest() \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m>\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m    mutate(statistic = coalesce(`t.ratio`), .before = p.value) \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m>\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m    select (-c(`t.ratio`))\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m# lexdiv_nest2 <- rand_lex_sumstats \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m>\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m#     filter(Language_name \u001b[39;49m\u001b[39m%i\u001b[39;49;00m\u001b[39mn\u001b[39;49m\u001b[39m% c\u001b[39;49;00m\u001b[39mase_study) \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m>\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m#     group_by(Language_name) \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m>\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m#     nest() \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m>\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m#     mutate(fit = map(data, ~ lmer(sums ~ contingent +\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m#                                 (1|transcript_id),\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m#                                 data = .,\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m#                                 REML= FALSE)),\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m#            summary = map(fit, ~ emmeans(., \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcontingent\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m)),\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m#            contrasts = map(summary, ~ summary(contrast(., method = \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpairwise\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m))),\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m#            effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m>\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m#     select(Language_name, contrasts, effect_size) \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m>\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m#     unnest(cols = c(contrasts)) \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m>\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m#     mutate(effect_size = map(effect_size, ~ summary(.))) \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m>\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m#     unnest() \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m>\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m#     mutate(statistic = coalesce(`t.ratio`), .before = p.value) \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m>\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m#     select (-c(`t.ratio`))\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m# lexdiv_nest3 <- rand_lex_sumstats \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m>\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m#     filter(Language_name \u001b[39;49m\u001b[39m%i\u001b[39;49;00m\u001b[39mn\u001b[39;49m\u001b[39m% s\u001b[39;49;00m\u001b[39mingle_tran) \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m>\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m#     group_by(Language_name) \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m>\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m#     nest() \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m>\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m#     mutate(fit = map(data, ~ lm(sums ~ contingent,\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m#                                 data = .,\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m#                                 REML= FALSE)),\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m#            summary = map(fit, ~ emmeans(., \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcontingent\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m)),\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m#            contrasts = map(summary, ~ summary(contrast(., method = \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpairwise\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m)))) \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m>\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m#     select(Language_name, contrasts) \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m>\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m#     unnest(cols = c(contrasts))  \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m>\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m#     rename(statistic = `t.ratio`)\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m    \u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m# # number of transcripts per language\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m# sample_size <- rand_dat_inc_cg_count \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m>\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m#     group_by(Language_name) \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m>\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m#     summarize(n = n_distinct(transcript_id))\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m    \u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m# # combine lmer summaries and correct p-values for multiple comparisons\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m# emms_all <- list(lexdiv_nest1, lexdiv_nest2, lexdiv_nest3) \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m>\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m#     reduce(bind_rows) \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m>\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m#     mutate(p.value = p.adjust(p.value, \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mholm\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m, 14)) \u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m>\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m#     left_join(sample_size)\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2478\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2476\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2477\u001b[0m     args \u001b[39m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2478\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2480\u001b[0m \u001b[39m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2481\u001b[0m \u001b[39m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2482\u001b[0m \u001b[39m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2483\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(fn, magic\u001b[39m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[39mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/rpy2/ipython/rmagic.py:943\u001b[0m, in \u001b[0;36mRMagics.R\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m    941\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m e\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mendswith(e\u001b[39m.\u001b[39merr):\n\u001b[1;32m    942\u001b[0m         \u001b[39mprint\u001b[39m(e\u001b[39m.\u001b[39merr)\n\u001b[0;32m--> 943\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    944\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    945\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice \u001b[39min\u001b[39;00m DEVICES_STATIC:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/rpy2/ipython/rmagic.py:923\u001b[0m, in \u001b[0;36mRMagics.R\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m    921\u001b[0m         return_output \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    922\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 923\u001b[0m     text_result, result, visible \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meval(code)\n\u001b[1;32m    924\u001b[0m     text_output \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m text_result\n\u001b[1;32m    925\u001b[0m     \u001b[39mif\u001b[39;00m visible:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/rpy2/ipython/rmagic.py:389\u001b[0m, in \u001b[0;36mRMagics.eval\u001b[0;34m(self, code)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[39mexcept\u001b[39;00m (ri\u001b[39m.\u001b[39membedded\u001b[39m.\u001b[39mRRuntimeError, \u001b[39mValueError\u001b[39;00m) \u001b[39mas\u001b[39;00m exception:\n\u001b[1;32m    387\u001b[0m     \u001b[39m# Otherwise next return seems to have copy of error.\u001b[39;00m\n\u001b[1;32m    388\u001b[0m     warning_or_other_msg \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflush()\n\u001b[0;32m--> 389\u001b[0m     \u001b[39mraise\u001b[39;00m RInterpreterError(code, \u001b[39mstr\u001b[39m(exception),\n\u001b[1;32m    390\u001b[0m                             warning_or_other_msg)\n\u001b[1;32m    391\u001b[0m text_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflush()\n\u001b[1;32m    392\u001b[0m \u001b[39mreturn\u001b[39;00m text_output, value, visible[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mRInterpreterError\u001b[0m: Failed to parse and evaluate line '\\n# vectors for rows to remove from lmer\\ncase_study <- c(\"Korean\", \"Mandarin\", \"Persian\") # only 1 target child analyzed\\n\\nsingle_tran <- c(\"Polish\") # only 1 transcript\\n\\n# nests of models\\nlexdiv_nest1 <- rand_lex_sumstats %>%\\n    mutate_at(c(\\'context\\'), as.factor) %>%\\n    filter(!Language_name %in% case_study) %>%\\n    filter(!Language_name %in% single_tran) %>%\\n    group_by(Language_name) %>%\\n    nest() %>%\\n    mutate(fit = map(data, ~ lmer(sums ~ contingent + context +\\n                                (1|target_child_id) +\\n                                (1|transcript_id),\\n                                data = .,\\n                                REML= FALSE)),\\n           summary = map(fit, ~ emmeans(., \"contingent\")),\\n           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\\n           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\\n    select(Language_name, contrasts, effect_size) %>%\\n    unnest(cols = c(contrasts)) %>%\\n    mutate(effect_size = map(effect_size, ~ summary(.))) %>%\\n    unnest() %>%\\n    mutate(statistic = coalesce(`t.ratio`), .before = p.value) %>%\\n    select (-c(`t.ratio`))\\n\\n# lexdiv_nest2 <- rand_lex_sumstats %>%\\n#     filter(Language_name %in% case_study) %>%\\n#     group_by(Language_name) %>%\\n#     nest() %>%\\n#     mutate(fit = map(data, ~ lmer(sums ~ contingent +\\n#                                 (1|transcript_id),\\n#                                 data = .,\\n#                                 REML= FALSE)),\\n#            summary = map(fit, ~ emmeans(., \"contingent\")),\\n#            contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\\n#            effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\\n#     select(Language_name, contrasts, effect_size) %>%\\n#     unnest(cols = c(contrasts)) %>%\\n#     mutate(effect_size = map(effect_size, ~ summary(.))) %>%\\n#     unnest() %>%\\n#     mutate(statistic = coalesce(`t.ratio`), .before = p.value) %>%\\n#     select (-c(`t.ratio`))\\n\\n# lexdiv_nest3 <- rand_lex_sumstats %>%\\n#     filter(Language_name %in% single_tran) %>%\\n#     group_by(Language_name) %>%\\n#     nest() %>%\\n#     mutate(fit = map(data, ~ lm(sums ~ contingent,\\n#                                 data = .,\\n#                                 REML= FALSE)),\\n#            summary = map(fit, ~ emmeans(., \"contingent\")),\\n#            contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\")))) %>%\\n#     select(Language_name, contrasts) %>%\\n#     unnest(cols = c(contrasts))  %>%\\n#     rename(statistic = `t.ratio`)\\n    \\n# # number of transcripts per language\\n# sample_size <- rand_dat_inc_cg_count %>%\\n#     group_by(Language_name) %>%\\n#     summarize(n = n_distinct(transcript_id))\\n    \\n# # combine lmer summaries and correct p-values for multiple comparisons\\n# emms_all <- list(lexdiv_nest1, lexdiv_nest2, lexdiv_nest3) %>% \\n#     reduce(bind_rows) %>%\\n#     mutate(p.value = p.adjust(p.value, \"holm\", 14)) %>%\\n#     left_join(sample_size)\\n'.\nR error message: 'Error in mutate(., fit = map(data, ~lmer(sums ~ contingent + context +  : \\n  \\nℹ In group 1: `Language_name = \"Croatian\"`.\\nCaused by error in `map()`:\\nℹ In index: 1.\\nCaused by error in `contrasts<-`:\\n! contrasts can be applied only to factors with 2 or more levels'"
     ]
    }
   ],
   "source": [
    "%%R -i rand_lex_sumstats -i rand_dat_inc_cg_count\n",
    "\n",
    "# vectors for rows to remove from lmer\n",
    "case_study <- c(\"Korean\", \"Mandarin\", \"Persian\") # only 1 target child analyzed\n",
    "\n",
    "single_tran <- c(\"Polish\") # only 1 transcript\n",
    "\n",
    "# nests of models\n",
    "lexdiv_nest1 <- rand_lex_sumstats %>%\n",
    "    mutate_at(c('context'), as.factor) %>%\n",
    "    filter(!Language_name %in% case_study) %>%\n",
    "    filter(!Language_name %in% single_tran) %>%\n",
    "    group_by(Language_name) %>%\n",
    "    nest() %>%\n",
    "    mutate(fit = map(data, ~ lmer(sums ~ contingent + context +\n",
    "                                (1|target_child_id) +\n",
    "                                (1|transcript_id),\n",
    "                                data = .,\n",
    "                                REML= FALSE)),\n",
    "           summary = map(fit, ~ emmeans(., \"contingent\")),\n",
    "           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\n",
    "           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\n",
    "    select(Language_name, contrasts, effect_size) %>%\n",
    "    unnest(cols = c(contrasts)) %>%\n",
    "    mutate(effect_size = map(effect_size, ~ summary(.))) %>%\n",
    "    unnest() %>%\n",
    "    mutate(statistic = coalesce(`t.ratio`), .before = p.value) %>%\n",
    "    select (-c(`t.ratio`))\n",
    "\n",
    "# lexdiv_nest2 <- rand_lex_sumstats %>%\n",
    "#     filter(Language_name %in% case_study) %>%\n",
    "#     group_by(Language_name) %>%\n",
    "#     nest() %>%\n",
    "#     mutate(fit = map(data, ~ lmer(sums ~ contingent +\n",
    "#                                 (1|transcript_id),\n",
    "#                                 data = .,\n",
    "#                                 REML= FALSE)),\n",
    "#            summary = map(fit, ~ emmeans(., \"contingent\")),\n",
    "#            contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\n",
    "#            effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\n",
    "#     select(Language_name, contrasts, effect_size) %>%\n",
    "#     unnest(cols = c(contrasts)) %>%\n",
    "#     mutate(effect_size = map(effect_size, ~ summary(.))) %>%\n",
    "#     unnest() %>%\n",
    "#     mutate(statistic = coalesce(`t.ratio`), .before = p.value) %>%\n",
    "#     select (-c(`t.ratio`))\n",
    "\n",
    "# lexdiv_nest3 <- rand_lex_sumstats %>%\n",
    "#     filter(Language_name %in% single_tran) %>%\n",
    "#     group_by(Language_name) %>%\n",
    "#     nest() %>%\n",
    "#     mutate(fit = map(data, ~ lm(sums ~ contingent,\n",
    "#                                 data = .,\n",
    "#                                 REML= FALSE)),\n",
    "#            summary = map(fit, ~ emmeans(., \"contingent\")),\n",
    "#            contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\")))) %>%\n",
    "#     select(Language_name, contrasts) %>%\n",
    "#     unnest(cols = c(contrasts))  %>%\n",
    "#     rename(statistic = `t.ratio`)\n",
    "    \n",
    "# # number of transcripts per language\n",
    "# sample_size <- rand_dat_inc_cg_count %>%\n",
    "#     group_by(Language_name) %>%\n",
    "#     summarize(n = n_distinct(transcript_id))\n",
    "    \n",
    "# # combine lmer summaries and correct p-values for multiple comparisons\n",
    "# emms_all <- list(lexdiv_nest1, lexdiv_nest2, lexdiv_nest3) %>% \n",
    "#     reduce(bind_rows) %>%\n",
    "#     mutate(p.value = p.adjust(p.value, \"holm\", 14)) %>%\n",
    "#     left_join(sample_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d9cf6b09",
   "metadata": {},
   "source": [
    "format statistics table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e695be65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "|Language (n)    |Estimate (SE)   | Test statistic| Effect size|Adjusted p-value |\n",
      "|:---------------|:---------------|--------------:|-----------:|:----------------|\n",
      "|Croatian (58)   |-48.34 (3.66)   |         -13.22|       -2.48|<.0001           |\n",
      "|English (872)   |-112.58 (2.21)  |         -50.98|       -2.47|<.0001           |\n",
      "|Estonian (22)   |-75.05 (12.55)  |          -5.98|       -1.85|0.0001           |\n",
      "|French (275)    |-70.88 (3.17)   |         -22.39|       -1.92|<.0001           |\n",
      "|German (38)     |-66.82 (7.89)   |          -8.47|       -1.97|<.0001           |\n",
      "|Japanese (160)  |-53.96 (3.17)   |         -17.01|       -1.90|<.0001           |\n",
      "|Korean (28)     |-116.71 (10.89) |         -10.72|       -2.92|<.0001           |\n",
      "|Mandarin (2)    |-91 (2)         |         -45.50|      -64.35|<.0001           |\n",
      "|Norwegian (26)  |-42.24 (12.61)  |          -3.35|       -1.02|0.0356           |\n",
      "|Persian (11)    |-63.09 (10.62)  |          -5.94|       -2.66|0.0009           |\n",
      "|Polish (1)      |-26 (NaN)       |            NaN|          NA|NaN              |\n",
      "|Portuguese (23) |-80.43 (16.21)  |          -4.96|       -1.50|0.0006           |\n",
      "|Spanish (30)    |-15.77 (5.21)   |          -3.03|       -0.79|0.0691           |\n",
      "|Swedish (16)    |-39.19 (12.64)  |          -3.10|       -1.13|0.0906           |\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "table_maker = function(data) { data %>%\n",
    "    select(Language_name, n, estimate, SE, statistic, effect.size, p.value) %>%\n",
    "    `colnames<-`(c(\"Language\", \"n\", \"Estimate\", \"SE\", \"Test statistic\", \"Effect size\", \"Adjusted p-value\")) %>%\n",
    "    mutate_at(vars(-c(`Adjusted p-value`,Language)), round,2) %>%\n",
    "    mutate(`Adjusted p-value` = format(round(`Adjusted p-value`,4),nsmall=4)) %>%\n",
    "    mutate(`Adjusted p-value` = gsub(\"0.0000\",\"<.0001\",`Adjusted p-value`)) %>%\n",
    "    unite(\"Estimate (SE)\", c('Estimate','SE'), sep=\" (\") %>%\n",
    "    mutate(`Estimate (SE)` = paste0(`Estimate (SE)`,\")\")) %>%\n",
    "    unite(\"Language (n)\", c('Language','n'), sep=\" (\") %>%\n",
    "    mutate(`Language (n)` = paste0(`Language (n)`,\")\")) %>%\n",
    "    arrange(`Language (n)`)\n",
    "    }\n",
    "\n",
    "lexdiv_stats_table <- table_maker(emms_all)\n",
    "\n",
    "kable(lexdiv_stats_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed81e707",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R \n",
    "\n",
    "# add columns sample and measure and save\n",
    "\n",
    "lexdiv_stats_table %>%\n",
    "    mutate(sample = \"rand\",\n",
    "           measure = \"lexdiv\") %>%\n",
    "    write.csv(file = \"../data/rand_lexdiv_stats.csv\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c88dec2c",
   "metadata": {},
   "source": [
    "By play context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d686f969",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_lex_sumstats_contex = (rand_dat_inc_cg.groupby([\"context\",\"target_child_id\",\"transcript_id\",\"contingent\"])\n",
    "                                  .uniquenss\n",
    "                                  .agg([\"sum\"])\n",
    "                                  .reset_index())\n",
    "\n",
    "rand_lex_sumstats_contex =  rand_lex_sumstats_contex.rename({'sum': 'sums'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d061c367",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: boundary (singular) fit: see help('isSingular')\n",
      "\n",
      "R[write to console]: boundary (singular) fit: see help('isSingular')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining with `by = join_by(context)`\n",
      "\n",
      "\n",
      "|Play context (n)                  |Estimate (SE)   | Test statistic| Effect size|Adjusted p-value |\n",
      "|:---------------------------------|:---------------|--------------:|-----------:|:----------------|\n",
      "|Home: book reading (28)           |-116.71 (10.89) |         -10.72|       -2.92|<.0001           |\n",
      "|Home: other (20)                  |-50.3 (4.96)    |         -10.14|       -3.29|<.0001           |\n",
      "|Home: unstructured (898)          |-75.53 (1.83)   |         -41.29|       -1.96|<.0001           |\n",
      "|Lab: interview/unstructured (360) |-137.9 (2.81)   |         -49.06|       -3.74|<.0001           |\n",
      "|Lab: tabletop play (26)           |-138.54 (17.93) |          -7.73|       -2.19|<.0001           |\n",
      "|Lab: unstructured (26)            |-69.27 (8.96)   |          -7.73|       -2.19|<.0001           |\n",
      "|Other: unstructured (128)         |-90.59 (4.61)   |         -19.65|       -2.47|<.0001           |\n"
     ]
    }
   ],
   "source": [
    "%%R -i rand_lex_sumstats_contex\n",
    "\n",
    "# vectors for rows to remove from lmer\n",
    "single_tran <- c(\"Home: interview/unstructured\") # only 1 transcript\n",
    "\n",
    "contex_sample_size <- rand_lex_sumstats_contex %>%\n",
    "    group_by(context) %>%\n",
    "    summarize(n = n_distinct(transcript_id))\n",
    "\n",
    "lexdiv_contex_nest_1 <- rand_lex_sumstats_contex %>%\n",
    "    filter(!context %in% single_tran) %>%\n",
    "    group_by(context) %>%\n",
    "    nest() %>%\n",
    "    mutate(fit = map(data, ~ lmer(sums ~ contingent +\n",
    "                                (1|transcript_id),\n",
    "                                data = .,\n",
    "                                REML= FALSE)),\n",
    "           summary = map(fit, ~ emmeans(., \"contingent\")),\n",
    "           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\n",
    "           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\n",
    "    select(context, contrasts, effect_size) %>%\n",
    "    unnest(cols = c(contrasts)) %>%\n",
    "    mutate(effect_size = map(effect_size, ~ summary(.))) %>%\n",
    "    unnest() %>%\n",
    "    mutate(statistic = coalesce(`t.ratio`), .before = p.value) %>%\n",
    "    select (-c(`t.ratio`)) %>%\n",
    "    mutate(p.value = p.adjust(p.value, \"holm\", 8)) %>%\n",
    "    left_join(contex_sample_size)\n",
    "    \n",
    "table_maker = function(data) { data %>%\n",
    "    select(context, n, estimate, SE, statistic, effect.size, p.value) %>%\n",
    "    `colnames<-`(c(\"Play context\", \"n\", \"Estimate\", \"SE\", \"Test statistic\", \"Effect size\", \"Adjusted p-value\")) %>%\n",
    "    mutate_at(vars(-c(`Adjusted p-value`,`Play context`)), round,2) %>%\n",
    "    mutate(`Adjusted p-value` = format(round(`Adjusted p-value`,4),nsmall=4)) %>%\n",
    "    mutate(`Adjusted p-value` = gsub(\"0.0000\",\"<.0001\",`Adjusted p-value`)) %>%\n",
    "    unite(\"Estimate (SE)\", c('Estimate','SE'), sep=\" (\") %>%\n",
    "    mutate(`Estimate (SE)` = paste0(`Estimate (SE)`,\")\")) %>%\n",
    "    unite(\"Play context (n)\", c(`Play context`,'n'), sep=\" (\") %>%\n",
    "    mutate(`Play context (n)` = paste0(`Play context (n)`,\")\")) %>%\n",
    "    arrange(`Play context (n)`)\n",
    "    }\n",
    "    \n",
    "lexdiv_context_stats_table <- table_maker(lexdiv_contex_nest_1)\n",
    "\n",
    "kable(lexdiv_context_stats_table)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc886786",
   "metadata": {},
   "source": [
    "By language family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab971057",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_lex_sumstats_fam = (rand_dat_inc_cg.groupby([\"Language_Family\",\"target_child_id\",\"transcript_id\",\"contingent\"])\n",
    "                                  .uniquenss\n",
    "                                  .agg([\"sum\"])\n",
    "                                  .reset_index())\n",
    "\n",
    "rand_lex_sumstats_fam =  rand_lex_sumstats_fam.rename({'sum': 'sums'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "342c0d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: boundary (singular) fit: see help('isSingular')\n",
      "\n",
      "R[write to console]: boundary (singular) fit: see help('isSingular')\n",
      "\n",
      "R[write to console]: boundary (singular) fit: see help('isSingular')\n",
      "\n",
      "R[write to console]: boundary (singular) fit: see help('isSingular')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining, by = \"Language_Family\"\n",
      "\n",
      "\n",
      "|Language Family (n)  |Estimate (SE)  | Test statistic| Effect size|Adjusted p-value |\n",
      "|:--------------------|:--------------|--------------:|-----------:|:----------------|\n",
      "|Indo-European (1483) |-91.31 (1.77)  |         -51.64|       -1.93|<.0001           |\n",
      "|Japonic (160)        |-51.53 (3.53)  |         -14.58|       -1.64|<.0001           |\n",
      "|Koreanic (28)        |-107 (12.81)   |          -8.36|       -2.27|<.0001           |\n",
      "|Sino-Tibetan (2)     |-91.5 (0.5)    |        -183.00|     -258.80|<.0001           |\n",
      "|Uralic (22)          |-69.36 (15.29) |          -4.54|       -1.40|0.0007           |\n"
     ]
    }
   ],
   "source": [
    "%%R -i rand_lex_sumstats_fam\n",
    "\n",
    "fam_sample_size <- rand_lex_sumstats_fam %>%\n",
    "    group_by(Language_Family) %>%\n",
    "    summarize(n = n_distinct(transcript_id))\n",
    "    \n",
    "lexdiv_fam_nest <- rand_lex_sumstats_fam %>%\n",
    "    group_by(Language_Family) %>%\n",
    "    nest() %>%\n",
    "    mutate(fit = map(data, ~ lmer(sums ~ contingent +\n",
    "                                (1|transcript_id),\n",
    "                                data = .,\n",
    "                                REML= FALSE)),\n",
    "           summary = map(fit, ~ emmeans(., \"contingent\")),\n",
    "           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\n",
    "           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\n",
    "    select(Language_Family, contrasts, effect_size) %>%\n",
    "    unnest(cols = c(contrasts)) %>%\n",
    "    mutate(effect_size = map(effect_size, ~ summary(.))) %>%\n",
    "    unnest() %>%\n",
    "    mutate(statistic = coalesce(`t.ratio`), .before = p.value) %>%\n",
    "    select (-c(`t.ratio`)) %>%\n",
    "    mutate(p.value = p.adjust(p.value, \"holm\", 5)) %>%\n",
    "    left_join(fam_sample_size)\n",
    "    \n",
    "table_maker = function(data) { data %>%\n",
    "    select(Language_Family, n, estimate, SE, statistic, effect.size, p.value) %>%\n",
    "    `colnames<-`(c(\"Language Family\", \"n\", \"Estimate\", \"SE\", \"Test statistic\", \"Effect size\", \"Adjusted p-value\")) %>%\n",
    "    mutate_at(vars(-c(`Adjusted p-value`,`Language Family`)), round,2) %>%\n",
    "    mutate(`Adjusted p-value` = format(round(`Adjusted p-value`,4),nsmall=4)) %>%\n",
    "    mutate(`Adjusted p-value` = gsub(\"0.0000\",\"<.0001\",`Adjusted p-value`)) %>%\n",
    "    unite(\"Estimate (SE)\", c('Estimate','SE'), sep=\" (\") %>%\n",
    "    mutate(`Estimate (SE)` = paste0(`Estimate (SE)`,\")\")) %>%\n",
    "    unite(\"Language Family (n)\", c(`Language Family`,'n'), sep=\" (\") %>%\n",
    "    mutate(`Language Family (n)` = paste0(`Language Family (n)`,\")\")) %>%\n",
    "    arrange(`Language Family (n)`)\n",
    "    }\n",
    "    \n",
    "lexdiv_fam_stats_table <- table_maker(lexdiv_fam_nest)\n",
    "\n",
    "kable(lexdiv_fam_stats_table)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "82639a51",
   "metadata": {},
   "source": [
    "By language genus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a7f5acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_lex_sumstats_gen = (rand_dat_inc_cg.groupby([\"Language_Genus\",\"target_child_id\",\"transcript_id\",\"contingent\"])\n",
    "                                  .uniquenss\n",
    "                                  .agg([\"sum\"])\n",
    "                                  .reset_index())\n",
    "\n",
    "rand_lex_sumstats_gen =  rand_lex_sumstats_gen.rename({'sum': 'sums'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43c8a6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: boundary (singular) fit: see help('isSingular')\n",
      "\n",
      "R[write to console]: boundary (singular) fit: see help('isSingular')\n",
      "\n",
      "R[write to console]: boundary (singular) fit: see help('isSingular')\n",
      "\n",
      "R[write to console]: boundary (singular) fit: see help('isSingular')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining, by = \"Language_Genus\"\n",
      "\n",
      "\n",
      "|Language Genus (n) |Estimate (SE)  | Test statistic| Effect size|Adjusted p-value |\n",
      "|:------------------|:--------------|--------------:|-----------:|:----------------|\n",
      "|Chinese (2)        |-91.5 (0.5)    |        -183.00|     -258.80|<.0001           |\n",
      "|Finnic (22)        |-69.36 (15.29) |          -4.54|       -1.40|0.0007           |\n",
      "|Germanic (1077)    |-104.9 (2.08)  |         -50.36|       -2.22|<.0001           |\n",
      "|Iranian (11)       |-63.36 (12.9)  |          -4.91|       -2.20|0.0018           |\n",
      "|Japanese (160)     |-51.53 (3.53)  |         -14.58|       -1.64|<.0001           |\n",
      "|Korean (28)        |-107 (12.81)   |          -8.36|       -2.27|<.0001           |\n",
      "|Romance (335)      |-59.85 (3.09)  |         -19.39|       -1.51|<.0001           |\n",
      "|Savlic (60)        |-36.16 (3.92)  |          -9.22|       -1.71|<.0001           |\n"
     ]
    }
   ],
   "source": [
    "%%R -i rand_lex_sumstats_gen\n",
    "    \n",
    "gen_sample_size <- rand_lex_sumstats_gen %>%\n",
    "    group_by(Language_Genus) %>%\n",
    "    summarize(n = n_distinct(transcript_id))\n",
    "    \n",
    "lexdiv_gen_nest <- rand_lex_sumstats_gen %>%\n",
    "    group_by(Language_Genus) %>%\n",
    "    nest() %>%\n",
    "    mutate(fit = map(data, ~ lmer(sums ~ contingent +\n",
    "                                (1|transcript_id),\n",
    "                                data = .,\n",
    "                                REML= FALSE)),\n",
    "           summary = map(fit, ~ emmeans(., \"contingent\")),\n",
    "           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\n",
    "           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\n",
    "    select(Language_Genus, contrasts, effect_size) %>%\n",
    "    unnest(cols = c(contrasts)) %>%\n",
    "    mutate(effect_size = map(effect_size, ~ summary(.))) %>%\n",
    "    unnest() %>%\n",
    "    mutate(statistic = coalesce(`t.ratio`), .before = p.value) %>%\n",
    "    select (-c(`t.ratio`)) %>%\n",
    "    mutate(p.value = p.adjust(p.value, \"holm\", 5)) %>%\n",
    "    left_join(gen_sample_size)\n",
    "    \n",
    "table_maker = function(data) { data %>%\n",
    "    select(Language_Genus, n, estimate, SE, statistic, effect.size, p.value) %>%\n",
    "    `colnames<-`(c(\"Language Genus\", \"n\", \"Estimate\", \"SE\", \"Test statistic\", \"Effect size\", \"Adjusted p-value\")) %>%\n",
    "    mutate_at(vars(-c(`Adjusted p-value`,`Language Genus`)), round,2) %>%\n",
    "    mutate(`Adjusted p-value` = format(round(`Adjusted p-value`,4),nsmall=4)) %>%\n",
    "    mutate(`Adjusted p-value` = gsub(\"0.0000\",\"<.0001\",`Adjusted p-value`)) %>%\n",
    "    unite(\"Estimate (SE)\", c('Estimate','SE'), sep=\" (\") %>%\n",
    "    mutate(`Estimate (SE)` = paste0(`Estimate (SE)`,\")\")) %>%\n",
    "    unite(\"Language Genus (n)\", c(`Language Genus`,'n'), sep=\" (\") %>%\n",
    "    mutate(`Language Genus (n)` = paste0(`Language Genus (n)`,\")\")) %>%\n",
    "    arrange(`Language Genus (n)`)\n",
    "    }\n",
    "    \n",
    "lexdiv_gen_stats_table <- table_maker(lexdiv_gen_nest)\n",
    "\n",
    "kable(lexdiv_gen_stats_table)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "82923a7b",
   "metadata": {},
   "source": [
    "By agglutinate status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d4e82073",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_lex_sumstats_agg = (rand_dat_inc_cg.groupby([\"Agglutinative\",\"target_child_id\",\"transcript_id\",\"contingent\"])\n",
    "                                  .uniquenss\n",
    "                                  .agg([\"sum\"])\n",
    "                                  .reset_index())\n",
    "\n",
    "rand_lex_sumstats_agg =  rand_lex_sumstats_agg.rename({'sum': 'sums'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22cb2eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining, by = \"Agglutinative\"\n",
      "\n",
      "\n",
      "|Agglutinative Status (n) |Estimate (SE) | Test statistic| Effect size|Adjusted p-value |\n",
      "|:------------------------|:-------------|--------------:|-----------:|:----------------|\n",
      "|0 (1485)                 |-91.31 (1.77) |         -51.71|       -1.93|<.0001           |\n",
      "|1 (210)                  |-60.79 (3.96) |         -15.35|       -1.50|<.0001           |\n"
     ]
    }
   ],
   "source": [
    "%%R -i rand_lex_sumstats_agg\n",
    "\n",
    "rand_lex_sumstats_agg %>% \n",
    "    count(Agglutinative)\n",
    "    \n",
    "agg_sample_size <- rand_lex_sumstats_agg %>%\n",
    "    group_by(Agglutinative) %>%\n",
    "    summarize(n = n_distinct(transcript_id))\n",
    "    \n",
    "lexdiv_agg_nest <- rand_lex_sumstats_agg %>%\n",
    "    group_by(Agglutinative) %>%\n",
    "    nest() %>%\n",
    "    mutate(fit = map(data, ~ lmer(sums ~ contingent +\n",
    "                                (1|transcript_id),\n",
    "                                data = .,\n",
    "                                REML= FALSE)),\n",
    "           summary = map(fit, ~ emmeans(., \"contingent\")),\n",
    "           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\n",
    "           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\n",
    "    select(Agglutinative, contrasts, effect_size) %>%\n",
    "    unnest(cols = c(contrasts)) %>%\n",
    "    mutate(effect_size = map(effect_size, ~ summary(.))) %>%\n",
    "    unnest() %>%\n",
    "    mutate(statistic = coalesce(`t.ratio`), .before = p.value) %>%\n",
    "    select (-c(`t.ratio`)) %>%\n",
    "    mutate(p.value = p.adjust(p.value, \"holm\", 5)) %>%\n",
    "    left_join(agg_sample_size)\n",
    "    \n",
    "table_maker = function(data) { data %>%\n",
    "    select(Agglutinative, n, estimate, SE, statistic, effect.size, p.value) %>%\n",
    "    `colnames<-`(c(\"Agglutinative Status\", \"n\", \"Estimate\", \"SE\", \"Test statistic\", \"Effect size\", \"Adjusted p-value\")) %>%\n",
    "    mutate_at(vars(-c(`Adjusted p-value`,`Agglutinative Status`)), round,2) %>%\n",
    "    mutate(`Adjusted p-value` = format(round(`Adjusted p-value`,4),nsmall=4)) %>%\n",
    "    mutate(`Adjusted p-value` = gsub(\"0.0000\",\"<.0001\",`Adjusted p-value`)) %>%\n",
    "    unite(\"Estimate (SE)\", c('Estimate','SE'), sep=\" (\") %>%\n",
    "    mutate(`Estimate (SE)` = paste0(`Estimate (SE)`,\")\")) %>%\n",
    "    unite(\"Agglutinative Status (n)\", c(`Agglutinative Status`,'n'), sep=\" (\") %>%\n",
    "    mutate(`Agglutinative Status (n)` = paste0(`Agglutinative Status (n)`,\")\")) %>%\n",
    "    arrange(`Agglutinative Status (n)`)\n",
    "    }\n",
    "    \n",
    "lexdiv_agg_stats_table <- table_maker(lexdiv_agg_nest)\n",
    "\n",
    "kable(lexdiv_agg_stats_table)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### Lexical diversity mixed models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ara=rand_dat_inc_cg[['language','num_tokens','contingent','transcript_id','target_child_id']][rand_dat_inc_cg[\"language\"]==\"ara\"] # no adult speech transcribed\n",
    "deu=rand_lex_sumstats[['Language_name','sums','contingent','transcript_id','target_child_id']][rand_lex_sumstats[\"Language_name\"]==\"German\"]\n",
    "eng=rand_lex_sumstats[['Language_name','sums','contingent','transcript_id','target_child_id']][rand_lex_sumstats[\"Language_name\"]==\"English\"]\n",
    "est=rand_lex_sumstats[['Language_name','sums','contingent','transcript_id','target_child_id']][rand_lex_sumstats[\"Language_name\"]==\"Estonian\"]\n",
    "fas=rand_lex_sumstats[['Language_name','sums','contingent','transcript_id','target_child_id']][rand_lex_sumstats[\"Language_name\"]==\"Persian\"]\n",
    "fra=rand_lex_sumstats[['Language_name','sums','contingent','transcript_id','target_child_id']][rand_lex_sumstats[\"Language_name\"]==\"French\"]\n",
    "hrv=rand_lex_sumstats[['Language_name','sums','contingent','transcript_id','target_child_id']][rand_lex_sumstats[\"Language_name\"]==\"Croatian\"]\n",
    "jpn=rand_lex_sumstats[['Language_name','sums','contingent','transcript_id','target_child_id']][rand_lex_sumstats[\"Language_name\"]==\"Japanese\"]\n",
    "kor=rand_lex_sumstats[['Language_name','sums','contingent','transcript_id','target_child_id']][rand_lex_sumstats[\"Language_name\"]==\"Korean\"]\n",
    "nor=rand_lex_sumstats[['Language_name','sums','contingent','transcript_id','target_child_id']][rand_lex_sumstats[\"Language_name\"]==\"Norwegian\"]\n",
    "pol=rand_lex_sumstats[['Language_name','sums','contingent','transcript_id','target_child_id']][rand_lex_sumstats[\"Language_name\"]==\"Polish\"]\n",
    "por=rand_lex_sumstats[['Language_name','sums','contingent','transcript_id','target_child_id']][rand_lex_sumstats[\"Language_name\"]==\"Portuguese\"]\n",
    "spa=rand_lex_sumstats[['Language_name','sums','contingent','transcript_id','target_child_id']][rand_lex_sumstats[\"Language_name\"]==\"Spanish\"]\n",
    "swe=rand_lex_sumstats[['Language_name','sums','contingent','transcript_id','target_child_id']][rand_lex_sumstats[\"Language_name\"]==\"Swedish\"]\n",
    "zho=rand_lex_sumstats[['Language_name','sums','contingent','transcript_id','target_child_id']][rand_lex_sumstats[\"Language_name\"]==\"Mandarin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Loading required package: Matrix\n",
      "\n",
      "R[write to console]: \n",
      "Attaching package: ‘lmerTest’\n",
      "\n",
      "\n",
      "R[write to console]: The following object is masked from ‘package:lme4’:\n",
      "\n",
      "    lmer\n",
      "\n",
      "\n",
      "R[write to console]: The following object is masked from ‘package:stats’:\n",
      "\n",
      "    step\n",
      "\n",
      "\n",
      "R[write to console]: ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n",
      "\n",
      "R[write to console]: ✔ tibble  3.1.8      ✔ dplyr   1.0.10\n",
      "✔ tidyr   1.2.0      ✔ stringr 1.4.1 \n",
      "✔ readr   2.1.2      ✔ forcats 0.5.2 \n",
      "✔ purrr   0.3.5      \n",
      "\n",
      "R[write to console]: ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "✖ tidyr::expand() masks Matrix::expand()\n",
      "✖ dplyr::filter() masks stats::filter()\n",
      "✖ dplyr::lag()    masks stats::lag()\n",
      "✖ tidyr::pack()   masks Matrix::pack()\n",
      "✖ tidyr::unpack() masks Matrix::unpack()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "library(\"lme4\")\n",
    "library(\"emmeans\")\n",
    "library(\"lmerTest\")\n",
    "library(\"tidyverse\")\n",
    "\n",
    "options(scipen = 999)\n",
    "\n",
    "effect_sizes <- data.frame(matrix(ncol = 2, nrow = 0))\n",
    "cols <- c(\"Language_name\", \"rand_effect_size\")\n",
    "colnames(effect_sizes) <- cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate   SE df t.ratio p.value\n",
      " contingent - (non-contingent)    -66.6 7.93 39  -8.392  <.0001\n",
      "\n",
      "Degrees-of-freedom method: kenward-roger \n",
      "\n",
      "[[2]]\n",
      "[1] 0.0000000002850791\n",
      "\n",
      "[1] 0.000000003991107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Since 'object' is a list, we are using the contrasts already present.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Language_name  rand_effect_size\n",
      "1        German -1.95097516423439\n"
     ]
    }
   ],
   "source": [
    "%%R -i deu\n",
    "\n",
    "lm2 <- lmer(sums ~ contingent + (1|target_child_id) + (1|transcript_id),data=deu, REML= FALSE)\n",
    "emm2<-emmeans(lm2,pairwise~contingent)\n",
    "pval<-summary(emm2$contrasts)$p.value\n",
    "print(c(emm2$contrasts, pval))\n",
    "print(p.adjust(pval, \"holm\", 14)) # create big vector of p-values and ajdust those\n",
    "# # summary(emmeans(lm2,\"contingent\",contr=\"pairwise\"),infer=TRUE) #group means\n",
    "# # test(contrast(emmeans(lm2,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "deu_lname <- deu$Language_name[1]\n",
    "\n",
    "deu_eff <- eff_size(emm2,sigma = sigma(lm2), edf = df.residual(lm2))\n",
    "\n",
    "deu_eff <- summary(deu_eff)$effect.size\n",
    "\n",
    "effect_sizes[nrow(effect_sizes)+1,] <- c(deu_lname,deu_eff)\n",
    "effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: boundary (singular) fit: see help('isSingular')\n",
      "\n",
      "R[write to console]: boundary (singular) fit: see help('isSingular')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate   SE  df t.ratio p.value\n",
      " contingent - (non-contingent)     -110 2.03 968 -54.028  <.0001\n",
      "\n",
      "Degrees-of-freedom method: kenward-roger \n",
      "\n",
      "[[2]]\n",
      "[1] 0.000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001969741\n",
      "\n",
      "[1] 0.00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000002757638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Since 'object' is a list, we are using the contrasts already present.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Language_name  rand_effect_size\n",
      "1        German -1.95097516423439\n",
      "2       English -2.48849254106895\n"
     ]
    }
   ],
   "source": [
    "%%R -i eng\n",
    "\n",
    "lm3 <- lmer(sums ~ contingent + (1|target_child_id) + (1|transcript_id),data=eng, REML= FALSE)\n",
    "emm3<-emmeans(lm3,pairwise~contingent)\n",
    "pval<-summary(emm3$contrasts)$p.value\n",
    "print(c(emm3$contrasts, pval))\n",
    "print(p.adjust(pval, \"holm\", 14))\n",
    "# summary(emmeans(lm3,\"contingent\",infer=TRUE)) #group means\n",
    "# test(contrast(emmeans(lm3,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "eng_lname <- eng$Language_name[1]\n",
    "\n",
    "eng_eff <- eff_size(emm3,sigma = sigma(lm3), edf = df.residual(lm3))\n",
    "\n",
    "eng_eff <- summary(eng_eff)$effect.size\n",
    "\n",
    "effect_sizes[nrow(effect_sizes)+1,] <- c(eng_lname,eng_eff)\n",
    "effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: boundary (singular) fit: see help('isSingular')\n",
      "\n",
      "R[write to console]: boundary (singular) fit: see help('isSingular')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate   SE   df t.ratio p.value\n",
      " contingent - (non-contingent)    -69.4 15.3 23.1  -4.535  0.0001\n",
      "\n",
      "Degrees-of-freedom method: kenward-roger \n",
      "\n",
      "[[2]]\n",
      "[1] 0.000147549\n",
      "\n",
      "[1] 0.002065686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Since 'object' is a list, we are using the contrasts already present.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Language_name  rand_effect_size\n",
      "1        German -1.95097516423439\n",
      "2       English -2.48849254106895\n",
      "3      Estonian -1.39964309587243\n"
     ]
    }
   ],
   "source": [
    "%%R -i est\n",
    "\n",
    "lm4 <- lmer(sums ~ contingent + (1|target_child_id) + (1|transcript_id),data=est, REML= FALSE)\n",
    "emm4<-emmeans(lm4,pairwise~contingent)\n",
    "pval<-summary(emm4$contrasts)$p.value\n",
    "print(c(emm4$contrasts, pval))\n",
    "print(p.adjust(pval, \"holm\", 14))\n",
    "# summary(emmeans(lm4,\"contingent\",infer=TRUE)) #group means\n",
    "# test(contrast(emmeans(lm4,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "est_lname <- est$Language_name[1]\n",
    "\n",
    "est_eff <- eff_size(emm4,sigma = sigma(lm4), edf = df.residual(lm4))\n",
    "\n",
    "est_eff <- summary(est_eff)$effect.size\n",
    "\n",
    "effect_sizes[nrow(effect_sizes)+1,] <- c(est_lname,est_eff)\n",
    "effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate   SE   df t.ratio p.value\n",
      " contingent - (non-contingent)    -63.4 12.9 12.1  -4.911  0.0004\n",
      "\n",
      "Degrees-of-freedom method: kenward-roger \n",
      "\n",
      "[[2]]\n",
      "[1] 0.0003505049\n",
      "\n",
      "[1] 0.004907068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Since 'object' is a list, we are using the contrasts already present.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Language_name  rand_effect_size\n",
      "1        German -1.95097516423439\n",
      "2       English -2.48849254106895\n",
      "3      Estonian -1.39964309587243\n",
      "4       Persian -2.19634516956833\n"
     ]
    }
   ],
   "source": [
    "%%R -i fas\n",
    "\n",
    "lm5 <- lmer(sums ~ contingent + (1|transcript_id),data=fas, REML= FALSE)\n",
    "emm5<-emmeans(lm5,pairwise~contingent)\n",
    "pval<-summary(emm5$contrasts)$p.value\n",
    "print(c(emm5$contrasts, pval))\n",
    "print(p.adjust(pval, \"holm\", 14))\n",
    "# summary(emmeans(lm5,\"contingent\",infer=TRUE)) #group means\n",
    "# test(contrast(emmeans(lm5,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "fas_lname <- fas$Language_name[1]\n",
    "\n",
    "fas_eff <- eff_size(emm5,sigma = sigma(lm5), edf = df.residual(lm5))\n",
    "\n",
    "fas_eff <- summary(fas_eff)$effect.size\n",
    "\n",
    "effect_sizes[nrow(effect_sizes)+1,] <- c(fas_lname,fas_eff)\n",
    "effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate  SE  df t.ratio p.value\n",
      " contingent - (non-contingent)    -67.8 3.3 281 -20.581  <.0001\n",
      "\n",
      "Degrees-of-freedom method: kenward-roger \n",
      "\n",
      "[[2]]\n",
      "[1] 0.0000000000000000000000000000000000000000000000000000000004892677\n",
      "\n",
      "[1] 0.000000000000000000000000000000000000000000000000000000006849748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Since 'object' is a list, we are using the contrasts already present.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Language_name  rand_effect_size\n",
      "1        German -1.95097516423439\n",
      "2       English -2.48849254106895\n",
      "3      Estonian -1.39964309587243\n",
      "4       Persian -2.19634516956833\n",
      "5        French -1.74618705563958\n"
     ]
    }
   ],
   "source": [
    "%%R -i fra\n",
    "\n",
    "lm6 <- lmer(sums ~ contingent + (1|target_child_id) + (1|transcript_id),data=fra, REML= FALSE)\n",
    "emm6<-emmeans(lm6,pairwise~contingent)\n",
    "pval<-summary(emm6$contrasts)$p.value\n",
    "print(c(emm6$contrasts, pval))\n",
    "print(p.adjust(pval, \"holm\", 14))\n",
    "# summary(emmeans(lm6,\"contingent\",infer=TRUE)) #group means\n",
    "# test(contrast(emmeans(lm6,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "fra_lname <- fra$Language_name[1]\n",
    "\n",
    "fra_eff <- eff_size(emm6,sigma = sigma(lm6), edf = df.residual(lm6))\n",
    "\n",
    "fra_eff <- summary(fra_eff)$effect.size\n",
    "\n",
    "effect_sizes[nrow(effect_sizes)+1,] <- c(fra_lname,fra_eff)\n",
    "effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate   SE   df t.ratio p.value\n",
      " contingent - (non-contingent)    -36.7 3.96 59.2  -9.267  <.0001\n",
      "\n",
      "Degrees-of-freedom method: kenward-roger \n",
      "\n",
      "[[2]]\n",
      "[1] 0.000000000000396518\n",
      "\n",
      "[1] 0.000000000005551251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Since 'object' is a list, we are using the contrasts already present.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Language_name  rand_effect_size\n",
      "1        German -1.95097516423439\n",
      "2       English -2.48849254106895\n",
      "3      Estonian -1.39964309587243\n",
      "4       Persian -2.19634516956833\n",
      "5        French -1.74618705563958\n",
      "6      Croatian -1.73388694741294\n"
     ]
    }
   ],
   "source": [
    "%%R -i hrv\n",
    "\n",
    "lm7 <- lmer(sums ~ contingent + (1|target_child_id) + (1|transcript_id),data=hrv, REML= FALSE)\n",
    "emm7<-emmeans(lm7,pairwise~contingent)\n",
    "pval<-summary(emm7$contrasts)$p.value\n",
    "print(c(emm7$contrasts, pval))\n",
    "print(p.adjust(pval, \"holm\", 14))\n",
    "# summary(emmeans(lm7,\"contingent\",infer=TRUE)) #group means\n",
    "# test(contrast(emmeans(lm7,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "hrv_lname <- hrv$Language_name[1]\n",
    "\n",
    "hrv_eff <- eff_size(emm7,sigma = sigma(lm7), edf = df.residual(lm7))\n",
    "\n",
    "hrv_eff <- summary(hrv_eff)$effect.size\n",
    "\n",
    "effect_sizes[nrow(effect_sizes)+1,] <- c(hrv_lname,hrv_eff)\n",
    "effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: boundary (singular) fit: see help('isSingular')\n",
      "\n",
      "R[write to console]: boundary (singular) fit: see help('isSingular')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate   SE  df t.ratio p.value\n",
      " contingent - (non-contingent)    -51.5 3.38 160 -15.262  <.0001\n",
      "\n",
      "Degrees-of-freedom method: kenward-roger \n",
      "\n",
      "[[2]]\n",
      "[1] 0.000000000000000000000000000000005236558\n",
      "\n",
      "[1] 0.00000000000000000000000000000007331181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Since 'object' is a list, we are using the contrasts already present.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Language_name  rand_effect_size\n",
      "1        German -1.95097516423439\n",
      "2       English -2.48849254106895\n",
      "3      Estonian -1.39964309587243\n",
      "4       Persian -2.19634516956833\n",
      "5        French -1.74618705563958\n",
      "6      Croatian -1.73388694741294\n",
      "7      Japanese -1.70808151489496\n"
     ]
    }
   ],
   "source": [
    "%%R -i jpn\n",
    "\n",
    "lm8 <- lmer(sums ~ contingent + (1|target_child_id) + (1|transcript_id),data=jpn, REML= FALSE)\n",
    "emm8<-emmeans(lm8,pairwise~contingent)\n",
    "pval<-summary(emm8$contrasts)$p.value\n",
    "print(c(emm8$contrasts, pval))\n",
    "print(p.adjust(pval, \"holm\", 14))\n",
    "# summary(emmeans(lm8,\"contingent\",infer=TRUE)) #group means\n",
    "# test(contrast(emmeans(lm8,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "jpn_lname <- jpn$Language_name[1]\n",
    "\n",
    "jpn_eff <- eff_size(emm8,sigma = sigma(lm8), edf = df.residual(lm8))\n",
    "\n",
    "jpn_eff <- summary(jpn_eff)$effect.size\n",
    "\n",
    "effect_sizes[nrow(effect_sizes)+1,] <- c(jpn_lname,jpn_eff)\n",
    "effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: boundary (singular) fit: see help('isSingular')\n",
      "\n",
      "R[write to console]: boundary (singular) fit: see help('isSingular')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate   SE df t.ratio p.value\n",
      " contingent - (non-contingent)     -107 12.8 29  -8.355  <.0001\n",
      "\n",
      "Degrees-of-freedom method: kenward-roger \n",
      "\n",
      "[[2]]\n",
      "[1] 0.000000003255291\n",
      "\n",
      "[1] 0.00000004557408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Since 'object' is a list, we are using the contrasts already present.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Language_name  rand_effect_size\n",
      "1        German -1.95097516423439\n",
      "2       English -2.48849254106895\n",
      "3      Estonian -1.39964309587243\n",
      "4       Persian -2.19634516956833\n",
      "5        French -1.74618705563958\n",
      "6      Croatian -1.73388694741294\n",
      "7      Japanese -1.70808151489496\n",
      "8        Korean -2.27400592391078\n"
     ]
    }
   ],
   "source": [
    "%%R -i kor\n",
    "\n",
    "lm9 <- lmer(sums ~ contingent + (1|transcript_id), data=kor, REML= FALSE)\n",
    "emm9<-emmeans(lm9,pairwise~contingent)\n",
    "pval<-summary(emm9$contrasts)$p.value\n",
    "print(c(emm9$contrasts, pval))\n",
    "print(p.adjust(pval, \"holm\", 14))\n",
    "# summary(emmeans(lm9,\"contingent\",infer=TRUE)) #group means\n",
    "# test(contrast(emmeans(lm9,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "kor_lname <- kor$Language_name[1]\n",
    "\n",
    "kor_eff <- eff_size(emm9,sigma = sigma(lm9), edf = df.residual(lm9))\n",
    "\n",
    "kor_eff <- summary(kor_eff)$effect.size\n",
    "\n",
    "effect_sizes[nrow(effect_sizes)+1,] <- c(kor_lname,kor_eff)\n",
    "effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: boundary (singular) fit: see help('isSingular')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate   SE   df t.ratio p.value\n",
      " contingent - (non-contingent)    -32.1 12.3 28.4  -2.608  0.0144\n",
      "\n",
      "Degrees-of-freedom method: kenward-roger \n",
      "\n",
      "[[2]]\n",
      "[1] 0.01435942\n",
      "\n",
      "[1] 0.2010319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Since 'object' is a list, we are using the contrasts already present.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Language_name  rand_effect_size\n",
      "1        German -1.95097516423439\n",
      "2       English -2.48849254106895\n",
      "3      Estonian -1.39964309587243\n",
      "4       Persian -2.19634516956833\n",
      "5        French -1.74618705563958\n",
      "6      Croatian -1.73388694741294\n",
      "7      Japanese -1.70808151489496\n",
      "8        Korean -2.27400592391078\n",
      "9     Norwegian               NaN\n"
     ]
    }
   ],
   "source": [
    "%%R -i nor\n",
    "\n",
    "lm10 <- lmer(sums ~ contingent + (1|target_child_id) + (1|transcript_id), data=nor, REML= FALSE)\n",
    "emm10<-emmeans(lm10,pairwise~contingent)\n",
    "pval<-summary(emm10$contrasts)$p.value\n",
    "print(c(emm10$contrasts, pval))\n",
    "print(p.adjust(pval, \"holm\", 14))\n",
    "# summary(emmeans(lm10,\"contingent\",infer=TRUE)) #group means\n",
    "# test(contrast(emmeans(lm10,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "nor_lname <- nor$Language_name[1]\n",
    "\n",
    "nor_eff <- eff_size(emm10,sigma = sigma(lm10), edf = df.residual(lm10))\n",
    "\n",
    "nor_eff <- summary(nor_eff)$effect.size\n",
    "\n",
    "effect_sizes[nrow(effect_sizes)+1,] <- c(nor_lname,NaN)\n",
    "effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate  SE df t.ratio p.value\n",
      " contingent - (non-contingent)       -7 NaN  0     NaN     NaN\n",
      "\n",
      "\n",
      "[[2]]\n",
      "[1] NaN\n",
      "\n",
      "[1] NaN\n",
      "   Language_name  rand_effect_size\n",
      "1         German -1.95097516423439\n",
      "2        English -2.48849254106895\n",
      "3       Estonian -1.39964309587243\n",
      "4        Persian -2.19634516956833\n",
      "5         French -1.74618705563958\n",
      "6       Croatian -1.73388694741294\n",
      "7       Japanese -1.70808151489496\n",
      "8         Korean -2.27400592391078\n",
      "9      Norwegian               NaN\n",
      "10        Polish               NaN\n"
     ]
    }
   ],
   "source": [
    "%%R -i pol\n",
    "\n",
    "# simple linear model (no random effects, because only 1 transcript from 1 sub)\n",
    "\n",
    "lm11 <- lm(sums ~ contingent ,data=pol, REML= FALSE)\n",
    "emm11<-emmeans(lm11,pairwise~contingent)\n",
    "pval<-summary(emm11$contrasts)$p.value\n",
    "print(c(emm11$contrasts, pval))\n",
    "print(p.adjust(pval, \"holm\", 14))\n",
    "# summary(emmeans(lm11,\"contingent\",infer=TRUE)) #group means\n",
    "# test(contrast(emmeans(lm11,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "pol_lname <- pol$Language_name[1]\n",
    "\n",
    "effect_sizes[nrow(effect_sizes)+1,] <- c(pol_lname,NaN)\n",
    "effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate   SE   df t.ratio p.value\n",
      " contingent - (non-contingent)    -39.4 9.32 24.1  -4.228  0.0003\n",
      "\n",
      "Degrees-of-freedom method: kenward-roger \n",
      "\n",
      "[[2]]\n",
      "[1] 0.00029494\n",
      "\n",
      "[1] 0.004129159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Since 'object' is a list, we are using the contrasts already present.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Language_name  rand_effect_size\n",
      "1         German -1.95097516423439\n",
      "2        English -2.48849254106895\n",
      "3       Estonian -1.39964309587243\n",
      "4        Persian -2.19634516956833\n",
      "5         French -1.74618705563958\n",
      "6       Croatian -1.73388694741294\n",
      "7       Japanese -1.70808151489496\n",
      "8         Korean -2.27400592391078\n",
      "9      Norwegian               NaN\n",
      "10        Polish               NaN\n",
      "11    Portuguese -1.27470969183833\n"
     ]
    }
   ],
   "source": [
    "%%R -i por\n",
    "\n",
    "lm12 <- lmer(sums ~ contingent + (1|target_child_id) + (1|transcript_id),data=por, REML= FALSE)\n",
    "emm12<-emmeans(lm12,pairwise~contingent)\n",
    "pval<-summary(emm12$contrasts)$p.value\n",
    "print(c(emm12$contrasts, pval))\n",
    "print(p.adjust(pval, \"holm\", 14))\n",
    "# summary(emmeans(lm12,\"contingent\",infer=TRUE)) #group means\n",
    "# test(contrast(emmeans(lm12,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "por_lname <- por$Language_name[1]\n",
    "\n",
    "por_eff <- eff_size(emm12,sigma = sigma(lm12), edf = df.residual(lm12))\n",
    "\n",
    "por_eff <- summary(por_eff)$effect.size\n",
    "\n",
    "effect_sizes[nrow(effect_sizes)+1,] <- c(por_lname,por_eff)\n",
    "effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate   SE df t.ratio p.value\n",
      " contingent - (non-contingent)     -2.5 5.96 31  -0.420  0.6777\n",
      "\n",
      "Degrees-of-freedom method: kenward-roger \n",
      "\n",
      "[[2]]\n",
      "[1] 0.6776767\n",
      "\n",
      "[1] 1\n",
      "   Language_name  rand_effect_size\n",
      "1         German -1.95097516423439\n",
      "2        English -2.48849254106895\n",
      "3       Estonian -1.39964309587243\n",
      "4        Persian -2.19634516956833\n",
      "5         French -1.74618705563958\n",
      "6       Croatian -1.73388694741294\n",
      "7       Japanese -1.70808151489496\n",
      "8         Korean -2.27400592391078\n",
      "9      Norwegian               NaN\n",
      "10        Polish               NaN\n",
      "11    Portuguese -1.27470969183833\n",
      "12       Spanish               NaN\n"
     ]
    }
   ],
   "source": [
    "%%R -i spa\n",
    "\n",
    "lm13 <- lmer(sums ~ contingent + (1|target_child_id) + (1|transcript_id),data=spa, REML= FALSE)\n",
    "emm13<-emmeans(lm13,pairwise~contingent)\n",
    "pval<-summary(emm13$contrasts)$p.value\n",
    "print(c(emm13$contrasts, pval))\n",
    "print(p.adjust(pval, \"holm\", 14))\n",
    "# summary(emmeans(lm13,\"contingent\",infer=TRUE)) #group means\n",
    "# test(contrast(emmeans(lm13,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "spa_lname <- spa$Language_name[1]\n",
    "\n",
    "effect_sizes[nrow(effect_sizes)+1,] <- c(spa_lname,NaN)\n",
    "effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: boundary (singular) fit: see help('isSingular')\n",
      "\n",
      "R[write to console]: boundary (singular) fit: see help('isSingular')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate   SE   df t.ratio p.value\n",
      " contingent - (non-contingent)    -38.8 13.1 17.1  -2.947  0.0090\n",
      "\n",
      "Degrees-of-freedom method: kenward-roger \n",
      "\n",
      "[[2]]\n",
      "[1] 0.008988988\n",
      "\n",
      "[1] 0.1258458\n",
      "   Language_name  rand_effect_size\n",
      "1         German -1.95097516423439\n",
      "2        English -2.48849254106895\n",
      "3       Estonian -1.39964309587243\n",
      "4        Persian -2.19634516956833\n",
      "5         French -1.74618705563958\n",
      "6       Croatian -1.73388694741294\n",
      "7       Japanese -1.70808151489496\n",
      "8         Korean -2.27400592391078\n",
      "9      Norwegian               NaN\n",
      "10        Polish               NaN\n",
      "11    Portuguese -1.27470969183833\n",
      "12       Spanish               NaN\n",
      "13       Swedish               NaN\n"
     ]
    }
   ],
   "source": [
    "%%R -i swe\n",
    "\n",
    "lm14 <- lmer(sums ~ contingent + (1|target_child_id) + (1|transcript_id),data=swe, REML= FALSE)\n",
    "emm14<-emmeans(lm14,pairwise~contingent)\n",
    "pval<-summary(emm14$contrasts)$p.value\n",
    "print(c(emm14$contrasts, pval))\n",
    "print(p.adjust(pval, \"holm\", 14))\n",
    "# summary(emmeans(lm14,\"contingent\",infer=TRUE)) #group means\n",
    "# test(contrast(emmeans(lm14,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "swe_lname <- swe$Language_name[1]\n",
    "\n",
    "effect_sizes[nrow(effect_sizes)+1,] <- c(swe_lname,NaN)\n",
    "effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate  SE df  t.ratio p.value\n",
      " contingent - (non-contingent)    -91.5 0.5  4 -183.000  <.0001\n",
      "\n",
      "Degrees-of-freedom method: kenward-roger \n",
      "\n",
      "[[2]]\n",
      "[1] 0.00000000534885\n",
      "\n",
      "[1] 0.0000000748839\n"
     ]
    }
   ],
   "source": [
    "%%R -i zho\n",
    "\n",
    "lm15 <- lmer(sums ~ contingent + (1|transcript_id),data=zho, REML= FALSE)\n",
    "emm15<-emmeans(lm15,pairwise~contingent)\n",
    "pval<-summary(emm15$contrasts)$p.value\n",
    "print(c(emm15$contrasts, pval))\n",
    "print(p.adjust(pval, \"holm\", 14))\n",
    "# summary(emmeans(lm15,\"contingent\",infer=TRUE)) #group means\n",
    "# test(contrast(emmeans(lm15,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "# zho_lname <- zho$Language_name[1]\n",
    "\n",
    "# zho_eff <- eff_size(emm15,sigma = sigma(lm15), edf = df.residual(lm15))\n",
    "\n",
    "# zho_eff <- summary(zho_eff)$effect.size\n",
    "\n",
    "# effect_sizes[nrow(effect_sizes)+1,] <- c(zho_lname,zho_eff)\n",
    "# effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "write.csv(x=effect_sizes,'../data/lexdiv_effect_sizes.csv', row.names = FALSE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
