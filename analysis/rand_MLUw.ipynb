{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Statistics Cross-linguistic: \n",
    "\n",
    "#### MLUw analysis - random sample\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0, \"data_proc\")\n",
    "import contingent_extraction\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_dat_inc = pd.read_csv(\"../data/rand_dat_inc_master.csv\",index_col=0,low_memory=False)\n",
    "rand_dat_inc=rand_dat_inc[rand_dat_inc[\"language\"]!=\"ara\"]\n",
    "rand_dat_inc=rand_dat_inc[(rand_dat_inc[\"target_child_age\"]>=5) & (rand_dat_inc[\"target_child_age\"]<=30)]\n",
    "\n",
    "rand_dat_inc_cg = rand_dat_inc[rand_dat_inc[\"caregiver\"]==\"caregiver\"]\n",
    "\n",
    "rand_dat_inc_cg[\"contingent\"] = np.where(rand_dat_inc_cg[\"contingent\"]==1, \"contingent\", \"non-contingent\")\n",
    "\n",
    "rand_dat_inc_cg = rand_dat_inc_cg[rand_dat_inc_cg[\"gloss\"].notna()]\n",
    "rand_dat_inc_cg = rand_dat_inc_cg[rand_dat_inc_cg[\"gloss\"]!=\"xxx\"]\n",
    "rand_dat_inc_cg = rand_dat_inc_cg[rand_dat_inc_cg[\"gloss\"]!=\"yyy\"]\n",
    "rand_dat_inc_cg = rand_dat_inc_cg[rand_dat_inc_cg[\"gloss\"]!=\"www\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0790afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add play context and year of study\n",
    "\n",
    "play_context = pd.read_csv(\"../data/context_data.csv\")\n",
    "play_context = play_context.rename(columns={\"Corpus\": \"corpus_name\"})\n",
    "\n",
    "# print(play_context.to_markdown())\n",
    "\n",
    "rand_dat_inc_cg = rand_dat_inc_cg.merge(play_context,on='corpus_name')\n",
    "\n",
    "rand_dat_inc_cg[\"context\"] = rand_dat_inc_cg[\"Location\"] + rand_dat_inc_cg[\"Activity\"]\n",
    "\n",
    "rand_dat_inc_cg[\"context\"] = rand_dat_inc_cg[\"context\"].replace({\"HomeBook-reading\":\"Home: book reading\",\n",
    "                                                                 \"HomeInterview/Unstructured\":\"Home: interview/unstructured\",\n",
    "                                                                 \"HomeNaN\":\"Home: unreported\",\n",
    "                                                                 \"HomeOther\":\"Home: other\",\n",
    "                                                                 \"HomeUnstructured\":\"Home: unstructured\",\n",
    "                                                                 \"LabOther\":\"Lab: other\",\n",
    "                                                                 \"LabTabletop play\":\"Lab: tabletop play\",\n",
    "                                                                 \"LabInterview/Unstructured\":\"Lab: interview/unstructured\",\n",
    "                                                                 \"LabUnstructured\":\"Lab: unstructured\",\n",
    "                                                                 np.nan:\"Unreported\",\n",
    "                                                                 \"OtherUnstructured\":\"Other: unstructured\"})\n",
    "\n",
    "# year of study\n",
    "corpora_year = pd.read_csv(\"../data/corpora_year.csv\")\n",
    "corpora_year = corpora_year.rename(columns={\"Corpora\": \"corpus_name\"})\n",
    "corpora_year = corpora_year[[\"corpus_name\", \"Year collected\"]]\n",
    "\n",
    "rand_dat_inc_cg = rand_dat_inc_cg.merge(corpora_year,on='corpus_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ee79e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c25847b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading required package: Matrix\n",
       "\n",
       "Attaching package: ‘lmerTest’\n",
       "\n",
       "The following object is masked from ‘package:lme4’:\n",
       "\n",
       "    lmer\n",
       "\n",
       "The following object is masked from ‘package:stats’:\n",
       "\n",
       "    step\n",
       "\n",
       "── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n",
       "✔ ggplot2 3.4.2     ✔ purrr   1.0.1\n",
       "✔ tibble  3.2.1     ✔ dplyr   1.1.2\n",
       "✔ tidyr   1.3.0     ✔ stringr 1.5.0\n",
       "✔ readr   2.1.4     ✔ forcats 1.0.0\n",
       "── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n",
       "✖ tidyr::expand() masks Matrix::expand()\n",
       "✖ dplyr::filter() masks stats::filter()\n",
       "✖ dplyr::lag()    masks stats::lag()\n",
       "✖ tidyr::pack()   masks Matrix::pack()\n",
       "✖ tidyr::unpack() masks Matrix::unpack()\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R -i rand_dat_inc_cg\n",
    "\n",
    "library(\"lme4\")\n",
    "library(\"knitr\")\n",
    "library(\"broom\")\n",
    "library(\"emmeans\")\n",
    "library(\"lmerTest\")\n",
    "library(\"tidyverse\")\n",
    "\n",
    "options(scipen = 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2cc7137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining with `by = join_by(transcript_id)`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Attaching package: ‘kableExtra’\n",
       "\n",
       "The following object is masked from ‘package:dplyr’:\n",
       "\n",
       "    group_rows\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R -o rand_dat_inc_cg\n",
    "\n",
    "library(\"kableExtra\")\n",
    "\n",
    "caregiver_type <- rand_dat_inc_cg %>%\n",
    "  group_by(transcript_id) %>%\n",
    "  summarise(\n",
    "    caregiver_type = case_when(\n",
    "      all(speaker_role == \"Mother\") ~ \"Mother only\",\n",
    "      all(speaker_role == \"Father\") ~ \"Father only\",\n",
    "      any(speaker_role %in% c(\"Mother\", \"Father\")) ~ \"Mother & Father\",\n",
    "      TRUE ~ \"Unknown\"\n",
    "    )\n",
    "  )\n",
    "\n",
    "rand_dat_inc_cg <- rand_dat_inc_cg %>%\n",
    "  left_join(caregiver_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_mlu_stats = (rand_dat_inc_cg.groupby([\"Language_name\",\"target_child_id\",\"transcript_id\",\"contingent\"])\n",
    "                                  .num_tokens\n",
    "                                  .agg([\"mean\"])\n",
    "                                  .reset_index())\n",
    "rand_mlu_sumstats =  rand_mlu_stats.rename({'mean': 'means'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40e1ccff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NULL\n"
     ]
    }
   ],
   "source": [
    "%%R -i rand_mlu_sumstats\n",
    "\n",
    "# import rand_mlu_sumstats into R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efad6d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining with `by = join_by(transcript_id)`\n"
     ]
    }
   ],
   "source": [
    "%%R -o rand_mlu_sumstats\n",
    "\n",
    "rand_mlu_sumstats <- rand_mlu_sumstats %>%\n",
    "    left_join(caregiver_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_mlu_sumstats.to_csv(\"../data/rand_mlu_sumstats.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### MLUw plot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In addition: Warning messages:\n",
       "1: The `fun.y` argument of `stat_summary()` is deprecated as of ggplot2 3.3.0.\n",
       "ℹ Please use the `fun` argument instead.\n",
       "This warning is displayed once every 8 hours.\n",
       "Call `lifecycle::last_lifecycle_warnings()` to see where this warning was\n",
       "generated. \n",
       "2: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n",
       "ℹ Please use `linewidth` instead.\n",
       "This warning is displayed once every 8 hours.\n",
       "Call `lifecycle::last_lifecycle_warnings()` to see where this warning was\n",
       "generated. \n",
       "3: The `size` argument of `element_rect()` is deprecated as of ggplot2 3.4.0.\n",
       "ℹ Please use the `linewidth` argument instead.\n",
       "This warning is displayed once every 8 hours.\n",
       "Call `lifecycle::last_lifecycle_warnings()` to see where this warning was\n",
       "generated. \n",
       "4: Removed 173 rows containing non-finite values (`stat_summary()`). \n",
       "5: Removed 173 rows containing non-finite values (`stat_summary()`). \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R -i rand_mlu_sumstats\n",
    "\n",
    "library('ggplot2')\n",
    "library('repr')\n",
    "options(repr.plot.width=6, repr.plot.height=12)\n",
    "\n",
    "xlabs <- c(\"C\", \"NC\")\n",
    "\n",
    "# ara_label <- data.frame(means=c(0),contingent = c(1.5),language=\"ara\") # no adult speech transcribed\n",
    "deu_label <- data.frame(means=c(5.8),contingent = c(1.5),Language_name=\"German\")\n",
    "eng_label <- data.frame(means=c(5.8),contingent = c(1.5),Language_name=\"English\")\n",
    "est_label <- data.frame(means=c(5.8),contingent = c(1.5),Language_name=\"Estonian\")\n",
    "# fas_label <- data.frame(means=c(5.8),contingent = c(1.5),Language_name=\"Persian\")\n",
    "fas_ns_label <- data.frame(means=c(6),contingent = c(1.5),Language_name=\"Persian\")\n",
    "fra_label <- data.frame(means=c(5.8),contingent = c(1.5),Language_name=\"French\")\n",
    "hrv_label <- data.frame(means=c(5.8),contingent = c(1.5),Language_name=\"Croatian\")\n",
    "jpn_label <- data.frame(means=c(5.8),contingent = c(1.5),Language_name=\"Japanese\")\n",
    "kor_label <- data.frame(means=c(5.8),contingent = c(1.5),Language_name=\"Korean\")\n",
    "# nor_label <- data.frame(means=c(5.8),contingent = c(1.5),Language_name=\"Norwegian\")\n",
    "nor_ns_label <- data.frame(means=c(5.8),contingent = c(1.5),Language_name=\"Norwegian\")\n",
    "pol_label <- data.frame(means=c(6),contingent = c(1.5),Language_name=\"Polish\")\n",
    "por_label <- data.frame(means=c(5.8),contingent = c(1.5),Language_name=\"Portuguese\")\n",
    "spa_label <- data.frame(means=c(5.8),contingent = c(1.5),Language_name=\"Spanish\")\n",
    "swe_label <- data.frame(means=c(5.8),contingent = c(1.5),Language_name=\"Swedish\")\n",
    "# zho_label <- data.frame(means=c(5.8),contingent = c(1.5),Language_name=\"Mandarin\")\n",
    "zho_ns_label <- data.frame(means=c(6),contingent = c(1.5),Language_name=\"Mandarin\")\n",
    "\n",
    "\n",
    "p <- ggplot(rand_mlu_sumstats, aes(x = contingent, y = means, color = Language_name)) +\n",
    "     stat_summary(fun.y=mean, geom=\"point\", shape=19, size=1.75) + \n",
    "     stat_summary(fun.data = mean_se, geom = \"errorbar\", size=1.25, width = .5) +\n",
    "     facet_wrap(. ~ Language_name,ncol = 7) + \n",
    "     geom_text(data = deu_label,label = \"***\",size=8,color=\"black\") + \n",
    "     geom_text(data = eng_label,label = \"***\",size=8,color=\"black\") +  \n",
    "     geom_text(data = est_label,label = \"**\",size=8,color=\"black\") +  \n",
    "     geom_text(data = fas_ns_label,label = \"ns\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "#      geom_text(data = fas_label,label = \"*\",size=8, color=\"black\") +\n",
    "     geom_text(data = fra_label,label = \"***\",size=8,color=\"black\") +  \n",
    "     geom_text(data = hrv_label,label = \"***\",size=8,color=\"black\") + \n",
    "     geom_text(data = jpn_label,label = \"***\",size=8,color=\"black\") + \n",
    "     geom_text(data = kor_label,label = \"***\",size=8,color=\"black\") +  \n",
    "     geom_text(data = nor_ns_label,label = \"**\",size=8,color=\"black\") +  \n",
    "     geom_text(data = pol_label,label = \"ns\", size=4,color=\"black\",fontface = \"italic\") +  \n",
    "     geom_text(data = por_label,label = \"***\",size=8,color=\"black\") +  \n",
    "     geom_text(data = spa_label,label = \"***\",size=8,color=\"black\") + \n",
    "     geom_text(data = swe_label,label = \"***\",size=8,color=\"black\") + \n",
    "     geom_text(data = zho_ns_label,label = \"ns\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "#      geom_text(data = zho_label,label = \"*\",size=8, color=\"black\") +\n",
    "     ylim(0, 6) +\n",
    "     labs(tag=\"B\",\n",
    "          y = \"Mean Length of Utterances in Words\",\n",
    "          x = \"\") +\n",
    "     theme_classic() +\n",
    "     scale_x_discrete(labels= xlabs) +\n",
    "     theme(text = element_text(size=16),\n",
    "           axis.text.x = element_text(vjust = 0.5, hjust=0.5),\n",
    "           legend.title = element_blank(),\n",
    "           legend.background = element_rect(fill=alpha(\"white\",0.90),\n",
    "                                                            size=0, linetype=\"dotted\",\n",
    "                                                            colour = \"white\"),\n",
    "           legend.text=element_text(size=16))\n",
    "      ggsave(\"../figures/token_mlu_rand.pdf\", width = 11.7, height = 6.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for manuscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In addition: Warning messages:\n",
       "1: Removed 173 rows containing non-finite values (`stat_summary()`). \n",
       "2: Removed 173 rows containing non-finite values (`stat_summary()`). \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R -i rand_mlu_sumstats\n",
    "\n",
    "library('ggplot2')\n",
    "library('repr')\n",
    "options(repr.plot.width=6, repr.plot.height=12)\n",
    "\n",
    "xlabs <- c(\"C\", \"NC\")\n",
    "\n",
    "# ara_label <- data.frame(means=c(0),contingent = c(1.5),language=\"ara\") # no adult speech transcribed\n",
    "deu_label <- data.frame(means=c(5.65),contingent = c(1.5),Language_name=\"German\")\n",
    "eng_label <- data.frame(means=c(5.65),contingent = c(1.5),Language_name=\"English\")\n",
    "est_label <- data.frame(means=c(5.65),contingent = c(1.5),Language_name=\"Estonian\")\n",
    "# fas_label <- data.frame(means=c(5.8),contingent = c(1.5),Language_name=\"Persian\")\n",
    "fas_ns_label <- data.frame(means=c(6),contingent = c(1.5),Language_name=\"Persian\")\n",
    "fra_label <- data.frame(means=c(5.65),contingent = c(1.5),Language_name=\"French\")\n",
    "hrv_label <- data.frame(means=c(5.65),contingent = c(1.5),Language_name=\"Croatian\")\n",
    "jpn_label <- data.frame(means=c(5.65),contingent = c(1.5),Language_name=\"Japanese\")\n",
    "kor_label <- data.frame(means=c(5.65),contingent = c(1.5),Language_name=\"Korean\")\n",
    "# nor_label <- data.frame(means=c(5.8),contingent = c(1.5),Language_name=\"Norwegian\")\n",
    "nor_ns_label <- data.frame(means=c(5.65),contingent = c(1.5),Language_name=\"Norwegian\")\n",
    "pol_label <- data.frame(means=c(6),contingent = c(1.5),Language_name=\"Polish\")\n",
    "por_label <- data.frame(means=c(5.65),contingent = c(1.5),Language_name=\"Portuguese\")\n",
    "spa_label <- data.frame(means=c(5.65),contingent = c(1.5),Language_name=\"Spanish\")\n",
    "swe_label <- data.frame(means=c(5.65),contingent = c(1.5),Language_name=\"Swedish\")\n",
    "# zho_label <- data.frame(means=c(5.8),contingent = c(1.5),Language_name=\"Mandarin\")\n",
    "zho_ns_label <- data.frame(means=c(6),contingent = c(1.5),Language_name=\"Mandarin\")\n",
    "\n",
    "\n",
    "p <- ggplot(rand_mlu_sumstats, aes(x = contingent, y = means, color = Language_name)) +\n",
    "     stat_summary(fun.y=mean, geom=\"point\", shape=19, size=1.75) + \n",
    "     stat_summary(fun.data = mean_se, geom = \"errorbar\", size=1.25, width = .4) +\n",
    "     facet_wrap(. ~ Language_name,ncol = 7) + \n",
    "     geom_text(data = deu_label,label = \"***\",size=6,color=\"black\") + \n",
    "     geom_text(data = eng_label,label = \"***\",size=6,color=\"black\") +  \n",
    "     geom_text(data = est_label,label = \"**\",size=6,color=\"black\") +  \n",
    "     geom_text(data = fas_ns_label,label = \"ns\",size=3,color=\"black\",fontface = \"italic\") +\n",
    "#      geom_text(data = fas_label,label = \"*\",size=8, color=\"black\") +\n",
    "     geom_text(data = fra_label,label = \"***\",size=6,color=\"black\") +  \n",
    "     geom_text(data = hrv_label,label = \"***\",size=6,color=\"black\") + \n",
    "     geom_text(data = jpn_label,label = \"***\",size=6,color=\"black\") + \n",
    "     geom_text(data = kor_label,label = \"***\",size=6,color=\"black\") +  \n",
    "     geom_text(data = nor_ns_label,label = \"**\",size=6,color=\"black\") +  \n",
    "#      geom_text(data = pol_label,label = \"ns\", size=3,color=\"black\",fontface = \"italic\") +  \n",
    "     geom_text(data = por_label,label = \"***\",size=6,color=\"black\") +  \n",
    "     geom_text(data = spa_label,label = \"***\",size=6,color=\"black\") + \n",
    "     geom_text(data = swe_label,label = \"***\",size=6,color=\"black\") + \n",
    "     geom_text(data = zho_ns_label,label = \"ns\",size=3,color=\"black\",fontface = \"italic\") +\n",
    "#      geom_text(data = zho_label,label = \"*\",size=8, color=\"black\") +\n",
    "     ylim(0, 6) +\n",
    "     labs(tag=\"B\",\n",
    "          y = \"Mean Length of Utterances in Words\", x = \"\") +\n",
    "     theme_classic() +\n",
    "     scale_x_discrete(labels= xlabs) +\n",
    "     theme(text = element_text(size=11.5),\n",
    "           axis.text.x = element_text(vjust = 0.5, hjust=0.5),\n",
    "           legend.position=\"none\")\n",
    "      ggsave(\"../figures/figure_2_B.pdf\", width = 11.5, height = 4.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot + effect estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In addition: Warning messages:\n",
       "1: Removed 173 rows containing non-finite values (`stat_summary()`). \n",
       "2: Removed 173 rows containing non-finite values (`stat_summary()`). \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "deu_est_label <- data.frame(means=c(.25),contingent = c(1),Language_name=\"German\")\n",
    "eng_est_label <- data.frame(means=c(.25),contingent = c(1),Language_name=\"English\")\n",
    "est_est_label <- data.frame(means=c(.25),contingent = c(1),Language_name=\"Estonian\")\n",
    "fra_est_label <- data.frame(means=c(.25),contingent = c(1),Language_name=\"French\")\n",
    "hrv_est_label <- data.frame(means=c(.25),contingent = c(1),Language_name=\"Croatian\")\n",
    "jpn_est_label <- data.frame(means=c(.25),contingent = c(1),Language_name=\"Japanese\")\n",
    "kor_est_label <- data.frame(means=c(.25),contingent = c(1),Language_name=\"Korean\")\n",
    "nor_est_label <- data.frame(means=c(.25),contingent = c(1),Language_name=\"Norwegian\")\n",
    "por_est_label <- data.frame(means=c(.25),contingent = c(1),Language_name=\"Portuguese\")\n",
    "spa_est_label <- data.frame(means=c(.25),contingent = c(1),Language_name=\"Spanish\")\n",
    "swe_est_label <- data.frame(means=c(.25),contingent = c(1),Language_name=\"Swedish\")\n",
    "\n",
    "p <- p + geom_text(data = deu_est_label,label = \"est=-.99\",size=4,color=\"black\") +\n",
    "         geom_text(data = eng_est_label,label = \"est=-.62\",size=4,color=\"black\") +\n",
    "         geom_text(data = est_est_label,label = \"est=-.48\",size=4,color=\"black\") +\n",
    "         geom_text(data = fra_est_label,label = \"est=-.39\",size=4,color=\"black\") +\n",
    "         geom_text(data = hrv_est_label,label = \"est=-.46\",size=4,color=\"black\") +\n",
    "         geom_text(data = jpn_est_label,label = \"est=-.65\",size=4,color=\"black\") +\n",
    "         geom_text(data = kor_est_label,label = \"est=-.47\",size=4,color=\"black\") +\n",
    "#          geom_text(data = nor_est_label,label = \"est=-.68\",size=4,color=\"black\") +\n",
    "         geom_text(data = por_est_label,label = \"est=-.66\",size=4,color=\"black\") +\n",
    "         geom_text(data = spa_est_label,label = \"est=-.42\",size=4,color=\"black\") +\n",
    "         geom_text(data = swe_est_label,label = \"est=-.67\",size=4,color=\"black\")\n",
    "         \n",
    "\n",
    "ggsave(\"../figures/token_mlu_rand_eff.pdf\", width = 11.7, height = 6.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\+ sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "In addition: Warning messages:\n",
       "1: Removed 173 rows containing non-finite values (`stat_summary()`). \n",
       "2: Removed 173 rows containing non-finite values (`stat_summary()`). \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "deu_n_label <- data.frame(means=c(.25),contingent = c(1.7),Language_name=\"German\")\n",
    "eng_n_label <- data.frame(means=c(.25),contingent = c(1.7),Language_name=\"English\")\n",
    "est_n_label <- data.frame(means=c(.25),contingent = c(1.7),Language_name=\"Estonian\")\n",
    "fas_n_label <- data.frame(means=c(.25),contingent = c(1.7),Language_name=\"Persian\")\n",
    "fra_n_label <- data.frame(means=c(.25),contingent = c(1.7),Language_name=\"French\")\n",
    "hrv_n_label <- data.frame(means=c(.25),contingent = c(1.7),Language_name=\"Croatian\")\n",
    "jpn_n_label <- data.frame(means=c(.25),contingent = c(1.7),Language_name=\"Japanese\")\n",
    "kor_n_label <- data.frame(means=c(.25),contingent = c(1.7),Language_name=\"Korean\")\n",
    "nor_n_label <- data.frame(means=c(.25),contingent = c(1.7),Language_name=\"Norwegian\")\n",
    "pol_n_label <- data.frame(means=c(.25),contingent = c(1.7),Language_name=\"Polish\")\n",
    "por_n_label <- data.frame(means=c(.25),contingent = c(1.7),Language_name=\"Portuguese\")\n",
    "spa_n_label <- data.frame(means=c(.25),contingent = c(1.7),Language_name=\"Spanish\")\n",
    "swe_n_label <- data.frame(means=c(.25),contingent = c(1.7),Language_name=\"Swedish\")\n",
    "zho_n_label <- data.frame(means=c(.25),contingent = c(1.7),Language_name=\"Mandarin\")\n",
    "\n",
    "deu_sz_label <- data.frame(means=c(.25),contingent = c(2.1),Language_name=\"German\")\n",
    "eng_sz_label <- data.frame(means=c(.25),contingent = c(2.1),Language_name=\"English\")\n",
    "est_sz_label <- data.frame(means=c(.25),contingent = c(2.1),Language_name=\"Estonian\")\n",
    "fas_sz_label <- data.frame(means=c(.25),contingent = c(2.1),Language_name=\"Persian\")\n",
    "fra_sz_label <- data.frame(means=c(.25),contingent = c(2.1),Language_name=\"French\")\n",
    "hrv_sz_label <- data.frame(means=c(.25),contingent = c(2.1),Language_name=\"Croatian\")\n",
    "jpn_sz_label <- data.frame(means=c(.25),contingent = c(2.1),Language_name=\"Japanese\")\n",
    "kor_sz_label <- data.frame(means=c(.25),contingent = c(2.1),Language_name=\"Korean\")\n",
    "nor_sz_label <- data.frame(means=c(.25),contingent = c(2.1),Language_name=\"Norwegian\")\n",
    "pol_sz_label <- data.frame(means=c(.25),contingent = c(2.1),Language_name=\"Polish\")\n",
    "por_sz_label <- data.frame(means=c(.25),contingent = c(2.1),Language_name=\"Portuguese\")\n",
    "spa_sz_label <- data.frame(means=c(.25),contingent = c(2.1),Language_name=\"Spanish\")\n",
    "swe_sz_label <- data.frame(means=c(.25),contingent = c(2.1),Language_name=\"Swedish\")\n",
    "zho_sz_label <- data.frame(means=c(.25),contingent = c(2.1),Language_name=\"Mandarin\")\n",
    "\n",
    "p <- p + geom_text(data = deu_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = eng_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = est_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = fas_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = fra_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = hrv_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = jpn_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = kor_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = nor_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = pol_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = por_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = spa_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = swe_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = zho_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = deu_sz_label,label = \" = 39\",size=4,color=\"black\") +\n",
    "         geom_text(data = eng_sz_label,label = \" = 1005\",size=4,color=\"black\") +\n",
    "         geom_text(data = est_sz_label,label = \" = 22\",size=4,color=\"black\") +\n",
    "         geom_text(data = fas_sz_label,label = \" = 12\",size=4,color=\"black\") +\n",
    "         geom_text(data = fra_sz_label,label = \" = 303\",size=4,color=\"black\") +\n",
    "         geom_text(data = hrv_sz_label,label = \" = 79\",size=4,color=\"black\") +\n",
    "         geom_text(data = jpn_sz_label,label = \" = 139\",size=4,color=\"black\") +\n",
    "         geom_text(data = kor_sz_label,label = \" = 37\",size=4,color=\"black\") +\n",
    "         geom_text(data = nor_sz_label,label = \" = 56\",size=4,color=\"black\") +\n",
    "         geom_text(data = pol_sz_label,label = \" = 1\",size=4,color=\"black\") +\n",
    "         geom_text(data = por_sz_label,label = \" = 24\",size=4,color=\"black\") +\n",
    "         geom_text(data = spa_sz_label,label = \" = 31\",size=4,color=\"black\") +\n",
    "         geom_text(data = swe_sz_label,label = \" = 16\",size=4,color=\"black\") +\n",
    "         geom_text(data = zho_sz_label,label = \" = 2\",size=4,color=\"black\")\n",
    "         \n",
    "\n",
    "ggsave(\"../figures/token_mlu_rand_eff_n.pdf\", width = 11.7, height = 6.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4eb864b8",
   "metadata": {},
   "source": [
    "----\n",
    "#### Statistical analyses\n",
    "\n",
    "By language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbc18705",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLUw_dat = rand_dat_inc_cg[['Language_name','num_tokens','contingent','transcript_id','target_child_id','caregiver_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c024fb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining with `by = join_by(Language_name)`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "boundary (singular) fit: see help('isSingular')\n",
       "boundary (singular) fit: see help('isSingular')\n",
       "Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
       "To enable adjustments, add the argument 'pbkrtest.limit = 5162' (or larger)\n",
       "[or, globally, 'set emm_options(pbkrtest.limit = 5162)' or larger];\n",
       "but be warned that this may result in large computation time and memory use.\n",
       "Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
       "To enable adjustments, add the argument 'lmerTest.limit = 5162' (or larger)\n",
       "[or, globally, 'set emm_options(lmerTest.limit = 5162)' or larger];\n",
       "but be warned that this may result in large computation time and memory use.\n",
       "Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
       "To enable adjustments, add the argument 'pbkrtest.limit = 90009' (or larger)\n",
       "[or, globally, 'set emm_options(pbkrtest.limit = 90009)' or larger];\n",
       "but be warned that this may result in large computation time and memory use.\n",
       "Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
       "To enable adjustments, add the argument 'lmerTest.limit = 90009' (or larger)\n",
       "[or, globally, 'set emm_options(lmerTest.limit = 90009)' or larger];\n",
       "but be warned that this may result in large computation time and memory use.\n",
       "Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
       "To enable adjustments, add the argument 'pbkrtest.limit = 19642' (or larger)\n",
       "[or, globally, 'set emm_options(pbkrtest.limit = 19642)' or larger];\n",
       "but be warned that this may result in large computation time and memory use.\n",
       "Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
       "To enable adjustments, add the argument 'lmerTest.limit = 19642' (or larger)\n",
       "[or, globally, 'set emm_options(lmerTest.limit = 19642)' or larger];\n",
       "but be warned that this may result in large computation time and memory use.\n",
       "Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
       "To enable adjustments, add the argument 'pbkrtest.limit = 4212' (or larger)\n",
       "[or, globally, 'set emm_options(pbkrtest.limit = 4212)' or larger];\n",
       "but be warned that this may result in large computation time and memory use.\n",
       "Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
       "To enable adjustments, add the argument 'lmerTest.limit = 4212' (or larger)\n",
       "[or, globally, 'set emm_options(lmerTest.limit = 4212)' or larger];\n",
       "but be warned that this may result in large computation time and memory use.\n",
       "Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
       "To enable adjustments, add the argument 'pbkrtest.limit = 23066' (or larger)\n",
       "[or, globally, 'set emm_options(pbkrtest.limit = 23066)' or larger];\n",
       "but be warned that this may result in large computation time and memory use.\n",
       "Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
       "To enable adjustments, add the argument 'lmerTest.limit = 23066' (or larger)\n",
       "[or, globally, 'set emm_options(lmerTest.limit = 23066)' or larger];\n",
       "but be warned that this may result in large computation time and memory use.\n",
       "Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
       "To enable adjustments, add the argument 'pbkrtest.limit = 3494' (or larger)\n",
       "[or, globally, 'set emm_options(pbkrtest.limit = 3494)' or larger];\n",
       "but be warned that this may result in large computation time and memory use.\n",
       "Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
       "To enable adjustments, add the argument 'lmerTest.limit = 3494' (or larger)\n",
       "[or, globally, 'set emm_options(lmerTest.limit = 3494)' or larger];\n",
       "but be warned that this may result in large computation time and memory use.\n",
       "Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
       "To enable adjustments, add the argument 'pbkrtest.limit = 3742' (or larger)\n",
       "[or, globally, 'set emm_options(pbkrtest.limit = 3742)' or larger];\n",
       "but be warned that this may result in large computation time and memory use.\n",
       "Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
       "To enable adjustments, add the argument 'lmerTest.limit = 3742' (or larger)\n",
       "[or, globally, 'set emm_options(lmerTest.limit = 3742)' or larger];\n",
       "but be warned that this may result in large computation time and memory use.\n",
       "In addition: Warning messages:\n",
       "1: `cols` is now required when using `unnest()`.\n",
       "ℹ Please use `cols = c(effect_size)`. \n",
       "2: `cols` is now required when using `unnest()`.\n",
       "ℹ Please use `cols = c(effect_size)`. \n",
       "3: `cols` is now required when using `unnest()`.\n",
       "ℹ Please use `cols = c(effect_size)`. \n",
       "4: `cols` is now required when using `unnest()`.\n",
       "ℹ Please use `cols = c(effect_size)`. \n",
       "5: There was 1 warning in `mutate()`.\n",
       "ℹ In argument: `fit = map(data, ~lm(num_tokens ~ contingent, data = ., REML =\n",
       "  FALSE))`.\n",
       "ℹ In group 1: `Language_name = \"Polish\"`.\n",
       "Caused by warning:\n",
       "! In lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) :\n",
       " extra argument ‘REML’ will be disregarded \n",
       "6: `cols` is now required when using `unnest()`.\n",
       "ℹ Please use `cols = c(effect_size)`. \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R -i MLUw_dat\n",
    "\n",
    "# vectors for rows to remove from lmer\n",
    "case_study <- c(\"Mandarin\", \"Persian\") # only 1 target child analyzed\n",
    "\n",
    "case_study_cgtype_compare <- c(\"Korean\") # only 1 target child analyzed, varies in CG type\n",
    "\n",
    "no_cgtype_compare <- c(\"Portuguese\") # only `Mother only`\n",
    "\n",
    "single_tran <- c(\"Polish\") # only 1 transcript\n",
    "\n",
    "# nests of models\n",
    "mlu_nest1 <- MLUw_dat %>%\n",
    "    filter(!Language_name %in% case_study) %>%\n",
    "    filter(!Language_name %in% single_tran) %>%\n",
    "    filter(!Language_name %in% no_cgtype_compare) %>%\n",
    "    filter(!Language_name %in% case_study_cgtype_compare) %>%\n",
    "    group_by(Language_name) %>%\n",
    "    nest() %>%\n",
    "    mutate(fit = map(data, ~ lmer(num_tokens ~ contingent + caregiver_type +\n",
    "                                (1|target_child_id) +\n",
    "                                (1|transcript_id),\n",
    "                                data = .,\n",
    "                                REML= FALSE)),\n",
    "           summary = map(fit, ~ emmeans(., \"contingent\")),\n",
    "           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\n",
    "           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\n",
    "    select(Language_name, contrasts, effect_size) %>%\n",
    "    unnest(cols = c(contrasts)) %>%\n",
    "    mutate(effect_size = map(effect_size, ~ summary(.))) %>%\n",
    "    unnest() %>%\n",
    "    mutate(statistic = coalesce(`z.ratio`,`t.ratio`), .before = p.value) %>%\n",
    "    select (-c(`z.ratio`,`t.ratio`))\n",
    "\n",
    "mlu_nest2 <- MLUw_dat %>%\n",
    "    filter(Language_name %in% case_study_cgtype_compare) %>%\n",
    "    group_by(Language_name) %>%\n",
    "    nest() %>%\n",
    "    mutate(fit = map(data, ~ lmer(num_tokens ~ contingent + caregiver_type +\n",
    "                                (1|transcript_id),\n",
    "                                data = .,\n",
    "                                REML= FALSE)),\n",
    "           summary = map(fit, ~ emmeans(., \"contingent\")),\n",
    "           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\n",
    "           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\n",
    "    select(Language_name, contrasts, effect_size) %>%\n",
    "    unnest(cols = c(contrasts)) %>%\n",
    "    mutate(effect_size = map(effect_size, ~ summary(.))) %>%\n",
    "    unnest() %>%\n",
    "    mutate(statistic = coalesce(`z.ratio`), .before = p.value) %>%\n",
    "    select (-c(`z.ratio`))\n",
    "\n",
    "mlu_nest3 <- MLUw_dat %>%\n",
    "    filter(Language_name %in% no_cgtype_compare) %>%\n",
    "    group_by(Language_name) %>%\n",
    "    nest() %>%\n",
    "    mutate(fit = map(data, ~ lmer(num_tokens ~ contingent + \n",
    "                                (1|target_child_id) +\n",
    "                                (1|transcript_id),\n",
    "                                data = .,\n",
    "                                REML= FALSE)),\n",
    "           summary = map(fit, ~ emmeans(., \"contingent\")),\n",
    "           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\n",
    "           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\n",
    "    select(Language_name, contrasts, effect_size) %>%\n",
    "    unnest(cols = c(contrasts)) %>%\n",
    "    mutate(effect_size = map(effect_size, ~ summary(.))) %>%\n",
    "    unnest() %>%\n",
    "    mutate(statistic = coalesce(`t.ratio`), .before = p.value) %>%\n",
    "    select (-c(`t.ratio`))\n",
    "\n",
    "mlu_nest4 <- MLUw_dat %>%\n",
    "    filter(Language_name %in% case_study) %>%\n",
    "    group_by(Language_name) %>%\n",
    "    nest() %>%\n",
    "    mutate(fit = map(data, ~ lmer(num_tokens ~ contingent +\n",
    "                                (1|transcript_id),\n",
    "                                data = .,\n",
    "                                REML= FALSE)),\n",
    "           summary = map(fit, ~ emmeans(., \"contingent\")),\n",
    "           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\n",
    "           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\n",
    "    select(Language_name, contrasts, effect_size) %>%\n",
    "    unnest(cols = c(contrasts)) %>%\n",
    "    mutate(effect_size = map(effect_size, ~ summary(.))) %>%\n",
    "    unnest() %>%\n",
    "    mutate(statistic = coalesce(`t.ratio`), .before = p.value) %>%\n",
    "    select (-c(`t.ratio`))\n",
    "\n",
    "mlu_nest5 <- MLUw_dat %>%\n",
    "    filter(Language_name %in% single_tran) %>%\n",
    "    group_by(Language_name) %>%\n",
    "    nest() %>%\n",
    "    mutate(fit = map(data, ~ lm(num_tokens ~ contingent,\n",
    "                                data = .,\n",
    "                                REML= FALSE)),\n",
    "           summary = map(fit, ~ emmeans(., \"contingent\")),\n",
    "           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\n",
    "           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\n",
    "    select(Language_name, contrasts, effect_size) %>%\n",
    "    unnest(cols = c(contrasts)) %>%\n",
    "    mutate(effect_size = map(effect_size, ~ summary(.))) %>%\n",
    "    unnest() %>%\n",
    "    rename(statistic = `t.ratio`)\n",
    "    \n",
    "# number of transcripts per language\n",
    "sample_size <- MLUw_dat %>%\n",
    "    group_by(Language_name) %>%\n",
    "    summarize(n = n_distinct(transcript_id))\n",
    "    \n",
    "# combine lmer summaries and correct p-values for multiple comparisons\n",
    "emms_all <- list(mlu_nest1, mlu_nest2, mlu_nest3, mlu_nest4, mlu_nest5) %>% \n",
    "    reduce(bind_rows) %>%\n",
    "    mutate(p.value = p.adjust(p.value, \"holm\", 14)) %>%\n",
    "    left_join(sample_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc1bee59",
   "metadata": {},
   "source": [
    "format statistics table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5789b414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "|Language (n)    |Estimate (SE) | Test statistic| Effect size|Adjusted p-value |\n",
      "|:---------------|:-------------|--------------:|-----------:|:----------------|\n",
      "|Croatian (58)   |-0.36 (0.08)  |          -4.35|       -0.13|0.0002           |\n",
      "|English (872)   |-0.66 (0.03)  |         -23.20|       -0.22|<.0001           |\n",
      "|Estonian (22)   |-0.49 (0.14)  |          -3.54|       -0.18|0.0057           |\n",
      "|French (275)    |-0.53 (0.06)  |          -9.13|       -0.16|<.0001           |\n",
      "|German (38)     |-0.84 (0.11)  |          -7.67|       -0.25|<.0001           |\n",
      "|Japanese (160)  |-0.63 (0.03)  |         -21.58|       -0.30|<.0001           |\n",
      "|Korean (28)     |-0.43 (0.08)  |          -5.52|       -0.21|<.0001           |\n",
      "|Mandarin (2)    |-0.79 (0.49)  |          -1.62|       -0.25|1.0000           |\n",
      "|Norwegian (26)  |-0.47 (0.15)  |          -3.16|       -0.17|0.0226           |\n",
      "|Persian (11)    |-0.48 (0.33)  |          -1.46|       -0.19|1.0000           |\n",
      "|Polish (1)      |0 (0.7)       |           0.00|        0.00|1.0000           |\n",
      "|Portuguese (23) |-0.68 (0.14)  |          -4.85|       -0.21|<.0001           |\n",
      "|Spanish (30)    |-0.35 (0.08)  |          -4.22|       -0.15|0.0003           |\n",
      "|Swedish (16)    |-0.54 (0.1)   |          -5.37|       -0.23|<.0001           |\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "table_maker = function(data) { data %>%\n",
    "    select(Language_name, n, estimate, SE, statistic, effect.size, p.value) %>%\n",
    "    `colnames<-`(c(\"Language\", \"n\", \"Estimate\", \"SE\", \"Test statistic\", \"Effect size\", \"Adjusted p-value\")) %>%\n",
    "    mutate_at(vars(-c(`Adjusted p-value`,Language)), round,2) %>%\n",
    "    mutate(`Adjusted p-value` = format(round(`Adjusted p-value`,4),nsmall=4)) %>%\n",
    "    mutate(`Adjusted p-value` = gsub(\"0.0000\",\"<.0001\",`Adjusted p-value`)) %>%\n",
    "    unite(\"Estimate (SE)\", c('Estimate','SE'), sep=\" (\") %>%\n",
    "    mutate(`Estimate (SE)` = paste0(`Estimate (SE)`,\")\")) %>%\n",
    "    unite(\"Language (n)\", c('Language','n'), sep=\" (\") %>%\n",
    "    mutate(`Language (n)` = paste0(`Language (n)`,\")\")) %>%\n",
    "    arrange(`Language (n)`)\n",
    "    }\n",
    "\n",
    "MLU_stats_table <- table_maker(emms_all)\n",
    "\n",
    "kable(MLU_stats_table,\"pipe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8971e4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R \n",
    "\n",
    "# add columns sample and measure and save\n",
    "\n",
    "MLU_stats_table %>%\n",
    "    mutate(sample = \"rand\",\n",
    "           measure = \"mlu\") %>%\n",
    "    write.csv(file = \"../data/rand_mlu_stats.csv\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9058914b",
   "metadata": {},
   "source": [
    "By play context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "598851a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_mlu_stats_contex = (rand_dat_inc_cg.groupby([\"context\",\"target_child_id\",\"transcript_id\",\"contingent\"])\n",
    "                                  .num_tokens\n",
    "                                  .agg([\"mean\"])\n",
    "                                  .reset_index())\n",
    "\n",
    "rand_mlu_stats_contex =  rand_mlu_stats_contex.rename({'mean': 'means'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9d2ee04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining with `by = join_by(context)`\n"
     ]
    }
   ],
   "source": [
    "%%R -i rand_mlu_stats_contex\n",
    "\n",
    "# vectors for rows to remove from lmer\n",
    "single_tran <- c(\"Home: interview/unstructured\") # only 1 transcript\n",
    "\n",
    "contex_sample_size <- rand_mlu_stats_contex %>%\n",
    "    group_by(context) %>%\n",
    "    summarize(n = n_distinct(transcript_id))\n",
    "\n",
    "mlu_contex_nest_1 <- rand_mlu_stats_contex %>%\n",
    "    filter(!context %in% single_tran) %>%\n",
    "    group_by(context) %>%\n",
    "    nest() %>%\n",
    "    mutate(fit = map(data, ~ lmer(means ~ contingent +\n",
    "                                (1|transcript_id),\n",
    "                                data = .,\n",
    "                                REML= FALSE)),\n",
    "           summary = map(fit, ~ emmeans(., \"contingent\")),\n",
    "           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\n",
    "           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\n",
    "    select(context, contrasts, effect_size) %>%\n",
    "    unnest(cols = c(contrasts)) %>%\n",
    "    mutate(effect_size = map(effect_size, ~ summary(.))) %>%\n",
    "    unnest() %>%\n",
    "    mutate(statistic = coalesce(`t.ratio`), .before = p.value) %>%\n",
    "    select (-c(`t.ratio`))\n",
    "    \n",
    "mlu_contex_nest_2 <- rand_mlu_stats_contex %>%\n",
    "    filter(context %in% single_tran) %>%\n",
    "    group_by(context) %>%\n",
    "    nest() %>%\n",
    "    mutate(fit = map(data, ~ lm(means ~ contingent,\n",
    "                                data = .,\n",
    "                                REML= FALSE)),\n",
    "           summary = map(fit, ~ emmeans(., \"contingent\")),\n",
    "           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\")))) %>%\n",
    "    select(context, contrasts) %>%\n",
    "    unnest(cols = c(contrasts))  %>%\n",
    "    rename(statistic = `t.ratio`)\n",
    "\n",
    "# combine lmer summaries and correct p-values for multiple comparisons\n",
    "context_emms_all <- list(mlu_contex_nest_1, mlu_contex_nest_2) %>% \n",
    "    reduce(bind_rows) %>%\n",
    "    mutate(p.value = p.adjust(p.value, \"holm\", 7)) %>%\n",
    "    left_join(contex_sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d149873f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "|Play context (n)                  |Estimate (SE) | Test statistic| Effect size|Adjusted p-value |\n",
      "|:---------------------------------|:-------------|--------------:|-----------:|:----------------|\n",
      "|Home: book reading (28)           |-0.47 (0.08)  |          -5.64|       -1.54|<.0001           |\n",
      "|Home: interview/unstructured (1)  |0 (NaN)       |            NaN|          NA|NaN              |\n",
      "|Home: other (20)                  |-0.51 (0.13)  |          -3.85|       -1.25|0.0066           |\n",
      "|Home: unstructured (898)          |-0.65 (0.04)  |         -16.92|       -0.80|<.0001           |\n",
      "|Lab: interview/unstructured (360) |-0.44 (0.1)   |          -4.57|       -0.35|<.0001           |\n",
      "|Lab: unstructured (26)            |-0.1 (0.1)    |          -0.96|       -0.27|1.0000           |\n",
      "|Other: unstructured (128)         |-0.8 (0.07)   |         -12.10|       -1.52|<.0001           |\n",
      "|Unreported (101)                  |-0.38 (0.09)  |          -4.38|       -0.62|0.0002           |\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "table_maker = function(data) { data %>%\n",
    "    select(context, n, estimate, SE, statistic, effect.size, p.value) %>%\n",
    "    `colnames<-`(c(\"Play context\", \"n\", \"Estimate\", \"SE\", \"Test statistic\", \"Effect size\", \"Adjusted p-value\")) %>%\n",
    "    mutate_at(vars(-c(`Adjusted p-value`,`Play context`)), round,2) %>%\n",
    "    mutate(`Adjusted p-value` = format(round(`Adjusted p-value`,4),nsmall=4)) %>%\n",
    "    mutate(`Adjusted p-value` = gsub(\"0.0000\",\"<.0001\",`Adjusted p-value`)) %>%\n",
    "    unite(\"Estimate (SE)\", c('Estimate','SE'), sep=\" (\") %>%\n",
    "    mutate(`Estimate (SE)` = paste0(`Estimate (SE)`,\")\")) %>%\n",
    "    unite(\"Play context (n)\", c(`Play context`,'n'), sep=\" (\") %>%\n",
    "    mutate(`Play context (n)` = paste0(`Play context (n)`,\")\")) %>%\n",
    "    arrange(`Play context (n)`)\n",
    "    }\n",
    "    \n",
    "mlu_context_stats_table <- table_maker(context_emms_all)\n",
    "\n",
    "kable(mlu_context_stats_table)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1940f7ea",
   "metadata": {},
   "source": [
    "By context, dropping English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "456cfcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop English\n",
    "rand_dat_inc_cg_no_eng = rand_dat_inc_cg[rand_dat_inc_cg[\"Language_name\"] != \"English\"]\n",
    "\n",
    "rand_mlu_stats_contex_no_eng = (rand_dat_inc_cg_no_eng.groupby([\"context\",\"target_child_id\",\"transcript_id\",\"contingent\"])\n",
    "                                  .num_tokens\n",
    "                                  .agg([\"mean\"])\n",
    "                                  .reset_index())\n",
    "\n",
    "rand_mlu_stats_contex_no_eng =  rand_mlu_stats_contex_no_eng.rename({'mean': 'means'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d09cd7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining with `by = join_by(context)`\n"
     ]
    }
   ],
   "source": [
    "%%R -i rand_mlu_stats_contex_no_eng\n",
    "\n",
    "# # vectors for rows to remove from lmer\n",
    "single_tran <- c(\"Home: interview/unstructured\") # only 1 transcript\n",
    "\n",
    "contex_sample_size_no_eng <- rand_mlu_stats_contex_no_eng %>%\n",
    "    group_by(context) %>%\n",
    "    summarize(n = n_distinct(transcript_id))\n",
    "\n",
    "mlu_contex_nest_1_no_eng <- rand_mlu_stats_contex_no_eng %>%\n",
    "    filter(!context %in% single_tran) %>%\n",
    "    group_by(context) %>%\n",
    "    nest() %>%\n",
    "    mutate(fit = map(data, ~ lmer(means ~ contingent +\n",
    "                                (1|transcript_id),\n",
    "                                data = .,\n",
    "                                REML= FALSE)),\n",
    "           summary = map(fit, ~ emmeans(., \"contingent\")),\n",
    "           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\n",
    "           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\n",
    "    select(context, contrasts, effect_size) %>%\n",
    "    unnest(cols = c(contrasts)) %>%\n",
    "    mutate(effect_size = map(effect_size, ~ summary(.))) %>%\n",
    "    unnest() %>%\n",
    "    mutate(statistic = coalesce(`t.ratio`), .before = p.value) %>%\n",
    "    select (-c(`t.ratio`))\n",
    "\n",
    "mlu_contex_nest_2_no_eng <- rand_mlu_stats_contex_no_eng %>%\n",
    "    filter(context %in% single_tran) %>%\n",
    "    group_by(context) %>%\n",
    "    nest() %>%\n",
    "    mutate(fit = map(data, ~ lm(means ~ contingent,\n",
    "                                data = .,\n",
    "                                REML= FALSE)),\n",
    "           summary = map(fit, ~ emmeans(., \"contingent\")),\n",
    "           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\")))) %>%\n",
    "    select(context, contrasts) %>%\n",
    "    unnest(cols = c(contrasts))  %>%\n",
    "    rename(statistic = `t.ratio`)\n",
    "    \n",
    "# combine lmer summaries and correct p-values for multiple comparisons\n",
    "context_no_eng_emms_all <- list(mlu_contex_nest_1_no_eng, mlu_contex_nest_2_no_eng) %>% \n",
    "    reduce(bind_rows) %>%\n",
    "    mutate(p.value = p.adjust(p.value, \"holm\", 3)) %>%\n",
    "    left_join(contex_sample_size_no_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a50bbddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "|Play context (n)                 |Estimate (SE) | Test statistic| Effect size|Adjusted p-value |\n",
      "|:--------------------------------|:-------------|--------------:|-----------:|:----------------|\n",
      "|Home: book reading (28)          |-0.47 (0.08)  |          -5.64|       -1.54|<.0001           |\n",
      "|Home: interview/unstructured (1) |0 (NaN)       |            NaN|          NA|NaN              |\n",
      "|Home: unstructured (560)         |-0.54 (0.04)  |         -12.68|       -0.76|<.0001           |\n"
     ]
    }
   ],
   "source": [
    "%%R \n",
    "\n",
    "table_maker = function(data) { data %>%\n",
    "    select(context, n, estimate, SE, statistic, effect.size, p.value) %>%\n",
    "    `colnames<-`(c(\"Play context\", \"n\", \"Estimate\", \"SE\", \"Test statistic\", \"Effect size\", \"Adjusted p-value\")) %>%\n",
    "    mutate_at(vars(-c(`Adjusted p-value`,`Play context`)), round,2) %>%\n",
    "    mutate(`Adjusted p-value` = format(round(`Adjusted p-value`,4),nsmall=4)) %>%\n",
    "    mutate(`Adjusted p-value` = gsub(\"0.0000\",\"<.0001\",`Adjusted p-value`)) %>%\n",
    "    unite(\"Estimate (SE)\", c('Estimate','SE'), sep=\" (\") %>%\n",
    "    mutate(`Estimate (SE)` = paste0(`Estimate (SE)`,\")\")) %>%\n",
    "    unite(\"Play context (n)\", c(`Play context`,'n'), sep=\" (\") %>%\n",
    "    mutate(`Play context (n)` = paste0(`Play context (n)`,\")\")) %>%\n",
    "    arrange(`Play context (n)`)\n",
    "    }\n",
    "    \n",
    "mlu_context_stats_table_no_eng <- table_maker(context_no_eng_emms_all)\n",
    "\n",
    "kable(mlu_context_stats_table_no_eng)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By language family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_mlu_stats_fam = (rand_dat_inc_cg.groupby([\"Language_Family\",\"target_child_id\",\"transcript_id\",\"contingent\"])\n",
    "                                  .num_tokens\n",
    "                                  .agg([\"mean\"])\n",
    "                                  .reset_index())\n",
    "rand_mlu_stats_fam =  rand_mlu_stats_fam.rename({'mean': 'means'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining, by = \"Language_Family\"\n",
      "\n",
      "\n",
      "|Language Family (n)  |Estimate (SE) | Test statistic| Effect size|Adjusted p-value |\n",
      "|:--------------------|:-------------|--------------:|-----------:|:----------------|\n",
      "|Indo-European (1483) |-0.58 (0.04)  |         -15.22|       -0.57|<.0001           |\n",
      "|Japonic (160)        |-0.63 (0.04)  |         -17.67|       -1.98|<.0001           |\n",
      "|Koreanic (28)        |-0.46 (0.07)  |          -6.48|       -1.76|<.0001           |\n",
      "|Sino-Tibetan (2)     |-0.93 (0.12)  |          -7.66|      -10.83|0.0078           |\n",
      "|Uralic (22)          |-0.62 (0.11)  |          -5.54|       -1.71|0.0001           |\n"
     ]
    }
   ],
   "source": [
    "%%R -i rand_mlu_stats_fam\n",
    "\n",
    "# plot\n",
    "\n",
    "library('ggplot2')\n",
    "\n",
    "p <- ggplot(rand_mlu_stats_fam, aes(x = contingent, y = means, color = Language_Family)) +\n",
    "     stat_summary(fun.y=mean, geom=\"point\", shape=19, size=1.75) + \n",
    "     stat_summary(fun.data = mean_se, geom = \"errorbar\", size=1.25, width = .5) +\n",
    "     facet_wrap(. ~ Language_Family,ncol=5) + \n",
    "     labs(y = \"Mean length of utterance\", x = \"\") +\n",
    "     theme_classic() +\n",
    "     theme(text = element_text(size=16),\n",
    "           axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),\n",
    "           legend.title = element_blank(),\n",
    "           legend.background = element_rect(fill=alpha(\"white\",0.90),\n",
    "                                                            size=0, linetype=\"dotted\",\n",
    "                                                            colour = \"white\"),\n",
    "           legend.text=element_text(size=16))\n",
    "    ggsave(\"../figures/token_mlu_family.pdf\", width = 11.7, height = 6.2)\n",
    "    \n",
    "# statistical analysis\n",
    "\n",
    "fam_sample_size <- rand_mlu_stats_fam %>%\n",
    "    group_by(Language_Family) %>%\n",
    "    summarize(n = n_distinct(transcript_id))\n",
    "    \n",
    "mlu_fam_nest <- rand_mlu_stats_fam %>%\n",
    "    group_by(Language_Family) %>%\n",
    "    nest() %>%\n",
    "    mutate(fit = map(data, ~ lmer(means ~ contingent +\n",
    "                                (1|transcript_id),\n",
    "                                data = .,\n",
    "                                REML= FALSE)),\n",
    "           summary = map(fit, ~ emmeans(., \"contingent\")),\n",
    "           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\n",
    "           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\n",
    "    select(Language_Family, contrasts, effect_size) %>%\n",
    "    unnest(cols = c(contrasts)) %>%\n",
    "    mutate(effect_size = map(effect_size, ~ summary(.))) %>%\n",
    "    unnest() %>%\n",
    "    mutate(statistic = coalesce(`t.ratio`), .before = p.value) %>%\n",
    "    select (-c(`t.ratio`)) %>%\n",
    "    mutate(p.value = p.adjust(p.value, \"holm\", 5)) %>%\n",
    "    left_join(fam_sample_size)\n",
    "    \n",
    "    table_maker = function(data) { data %>%\n",
    "    select(Language_Family, n, estimate, SE, statistic, effect.size, p.value) %>%\n",
    "    `colnames<-`(c(\"Language Family\", \"n\", \"Estimate\", \"SE\", \"Test statistic\", \"Effect size\", \"Adjusted p-value\")) %>%\n",
    "    mutate_at(vars(-c(`Adjusted p-value`,`Language Family`)), round,2) %>%\n",
    "    mutate(`Adjusted p-value` = format(round(`Adjusted p-value`,4),nsmall=4)) %>%\n",
    "    mutate(`Adjusted p-value` = gsub(\"0.0000\",\"<.0001\",`Adjusted p-value`)) %>%\n",
    "    unite(\"Estimate (SE)\", c('Estimate','SE'), sep=\" (\") %>%\n",
    "    mutate(`Estimate (SE)` = paste0(`Estimate (SE)`,\")\")) %>%\n",
    "    unite(\"Language Family (n)\", c(`Language Family`,'n'), sep=\" (\") %>%\n",
    "    mutate(`Language Family (n)` = paste0(`Language Family (n)`,\")\")) %>%\n",
    "    arrange(`Language Family (n)`)\n",
    "    }\n",
    "    \n",
    "mlu_fam_stats_table <- table_maker(mlu_fam_nest)\n",
    "\n",
    "kable(mlu_fam_stats_table)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By language genus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_mlu_stats_gen = (rand_dat_inc_cg.groupby([\"Language_Genus\",\"target_child_id\",\"transcript_id\",\"contingent\"])\n",
    "                                  .num_tokens\n",
    "                                  .agg([\"mean\"])\n",
    "                                  .reset_index())\n",
    "rand_mlu_stats_gen = rand_mlu_stats_gen.rename({'mean': 'means'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: boundary (singular) fit: see help('isSingular')\n",
      "\n",
      "R[write to console]: boundary (singular) fit: see help('isSingular')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining, by = \"Language_Genus\"\n",
      "\n",
      "\n",
      "|Language Genus (n) |Estimate (SE) | Test statistic| Effect size|Adjusted p-value |\n",
      "|:------------------|:-------------|--------------:|-----------:|:----------------|\n",
      "|Chinese (2)        |-0.93 (0.12)  |          -7.66|      -10.83|0.0078           |\n",
      "|Finnic (22)        |-0.62 (0.11)  |          -5.54|       -1.71|0.0001           |\n",
      "|Germanic (1077)    |-0.63 (0.05)  |         -12.91|       -0.57|<.0001           |\n",
      "|Iranian (11)       |-0.44 (0.28)  |          -1.59|       -0.71|0.6855           |\n",
      "|Japanese (160)     |-0.63 (0.04)  |         -17.67|       -1.98|<.0001           |\n",
      "|Korean (28)        |-0.46 (0.07)  |          -6.48|       -1.76|<.0001           |\n",
      "|Romance (335)      |-0.48 (0.06)  |          -7.68|       -0.60|<.0001           |\n",
      "|Savlic (60)        |-0.34 (0.08)  |          -4.29|       -0.80|0.0003           |\n"
     ]
    }
   ],
   "source": [
    "%%R -i rand_mlu_stats_gen\n",
    "\n",
    "library('ggplot2')\n",
    "\n",
    "# plot\n",
    "\n",
    "p <- ggplot(rand_mlu_stats_gen, aes(x = contingent, y = means, color = Language_Genus)) +\n",
    "     stat_summary(fun.y=mean, geom=\"point\", shape=19, size=1.75) + \n",
    "     stat_summary(fun.data = mean_se, geom = \"errorbar\", size=1.25, width = .5) +\n",
    "     facet_wrap(. ~ Language_Genus,ncol=8) + \n",
    "     labs(y = \"Mean length of utterance\", x = \"\") +\n",
    "     theme_classic() +\n",
    "     theme(text = element_text(size=16),\n",
    "           axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),\n",
    "           legend.title = element_blank(),\n",
    "           legend.background = element_rect(fill=alpha(\"white\",0.90),\n",
    "                                                            size=0, linetype=\"dotted\",\n",
    "                                                            colour = \"white\"),\n",
    "           legend.text=element_text(size=16))\n",
    "    ggsave(\"../figures/token_mlu_genus.pdf\", width = 11.7, height = 6.2)\n",
    "    \n",
    "# statistical analysis\n",
    "\n",
    "gen_sample_size <- rand_mlu_stats_gen %>%\n",
    "    group_by(Language_Genus) %>%\n",
    "    summarize(n = n_distinct(transcript_id))\n",
    "    \n",
    "mlu_gen_nest <- rand_mlu_stats_gen %>%\n",
    "    group_by(Language_Genus) %>%\n",
    "    nest() %>%\n",
    "    mutate(fit = map(data, ~ lmer(means ~ contingent +\n",
    "                                (1|transcript_id),\n",
    "                                data = .,\n",
    "                                REML= FALSE)),\n",
    "           summary = map(fit, ~ emmeans(., \"contingent\")),\n",
    "           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\n",
    "           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\n",
    "    select(Language_Genus, contrasts, effect_size) %>%\n",
    "    unnest(cols = c(contrasts)) %>%\n",
    "    mutate(effect_size = map(effect_size, ~ summary(.))) %>%\n",
    "    unnest() %>%\n",
    "    mutate(statistic = coalesce(`t.ratio`), .before = p.value) %>%\n",
    "    select (-c(`t.ratio`)) %>%\n",
    "    mutate(p.value = p.adjust(p.value, \"holm\", 5)) %>%\n",
    "    left_join(gen_sample_size)\n",
    "    \n",
    "table_maker = function(data) { data %>%\n",
    "    select(Language_Genus, n, estimate, SE, statistic, effect.size, p.value) %>%\n",
    "    `colnames<-`(c(\"Language Genus\", \"n\", \"Estimate\", \"SE\", \"Test statistic\", \"Effect size\", \"Adjusted p-value\")) %>%\n",
    "    mutate_at(vars(-c(`Adjusted p-value`,`Language Genus`)), round,2) %>%\n",
    "    mutate(`Adjusted p-value` = format(round(`Adjusted p-value`,4),nsmall=4)) %>%\n",
    "    mutate(`Adjusted p-value` = gsub(\"0.0000\",\"<.0001\",`Adjusted p-value`)) %>%\n",
    "    unite(\"Estimate (SE)\", c('Estimate','SE'), sep=\" (\") %>%\n",
    "    mutate(`Estimate (SE)` = paste0(`Estimate (SE)`,\")\")) %>%\n",
    "    unite(\"Language Genus (n)\", c(`Language Genus`,'n'), sep=\" (\") %>%\n",
    "    mutate(`Language Genus (n)` = paste0(`Language Genus (n)`,\")\")) %>%\n",
    "    arrange(`Language Genus (n)`)\n",
    "    }\n",
    "    \n",
    "lexdiv_gen_stats_table <- table_maker(mlu_gen_nest)\n",
    "\n",
    "kable(lexdiv_gen_stats_table)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By agglutinative status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_mlu_stats_aggl = (rand_dat_inc_cg.groupby([\"Agglutinative\",\"target_child_id\",\"transcript_id\",\"contingent\"])\n",
    "                                  .num_tokens\n",
    "                                  .agg([\"mean\"])\n",
    "                                  .reset_index())\n",
    "rand_mlu_stats_aggl = rand_mlu_stats_aggl.rename({'mean': 'means'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining, by = \"Agglutinative\"\n",
      "\n",
      "\n",
      "|Agglutinative Status (n) |Estimate (SE) | Test statistic| Effect size|Adjusted p-value |\n",
      "|:------------------------|:-------------|--------------:|-----------:|:----------------|\n",
      "|0 (1485)                 |-0.58 (0.04)  |         -15.25|       -0.57|<.0001           |\n",
      "|1 (210)                  |-0.61 (0.03)  |         -19.47|       -1.90|<.0001           |\n"
     ]
    }
   ],
   "source": [
    "%%R -i rand_mlu_stats_aggl\n",
    "\n",
    "library('ggplot2')\n",
    "\n",
    "# plot\n",
    "\n",
    "p <- ggplot(rand_mlu_stats_aggl, aes(x = contingent, y = means, color = Agglutinative)) +\n",
    "     stat_summary(fun.y=mean, geom=\"point\", shape=19, size=1.75) + \n",
    "     stat_summary(fun.data = mean_se, geom = \"errorbar\", size=1.25, width = .5) +\n",
    "     facet_wrap(. ~ Agglutinative) + \n",
    "     labs(y = \"Mean length of utterance\", x = \"\") +\n",
    "     theme_classic() +\n",
    "     theme(text = element_text(size=16),\n",
    "           axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),\n",
    "           legend.title = element_blank(),\n",
    "           legend.background = element_rect(fill=alpha(\"white\",0.90),\n",
    "                                                            size=0, linetype=\"dotted\",\n",
    "                                                            colour = \"white\"),\n",
    "           legend.text=element_text(size=16))\n",
    "    ggsave(\"../figures/token_mlu_aggl.pdf\", width = 11.7, height = 6.2)\n",
    "    \n",
    "# statistical analysis\n",
    "    \n",
    "agg_sample_size <- rand_mlu_stats_aggl %>%\n",
    "    group_by(Agglutinative) %>%\n",
    "    summarize(n = n_distinct(transcript_id))\n",
    "    \n",
    "mlu_agg_nest <- rand_mlu_stats_aggl %>%\n",
    "    group_by(Agglutinative) %>%\n",
    "    nest() %>%\n",
    "    mutate(fit = map(data, ~ lmer(means ~ contingent +\n",
    "                                (1|transcript_id),\n",
    "                                data = .,\n",
    "                                REML= FALSE)),\n",
    "           summary = map(fit, ~ emmeans(., \"contingent\")),\n",
    "           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\n",
    "           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\n",
    "    select(Agglutinative, contrasts, effect_size) %>%\n",
    "    unnest(cols = c(contrasts)) %>%\n",
    "    mutate(effect_size = map(effect_size, ~ summary(.))) %>%\n",
    "    unnest() %>%\n",
    "    mutate(statistic = coalesce(`t.ratio`), .before = p.value) %>%\n",
    "    select (-c(`t.ratio`)) %>%\n",
    "    mutate(p.value = p.adjust(p.value, \"holm\", 5)) %>%\n",
    "    left_join(agg_sample_size)\n",
    "    \n",
    "table_maker = function(data) { data %>%\n",
    "    select(Agglutinative, n, estimate, SE, statistic, effect.size, p.value) %>%\n",
    "    `colnames<-`(c(\"Agglutinative Status\", \"n\", \"Estimate\", \"SE\", \"Test statistic\", \"Effect size\", \"Adjusted p-value\")) %>%\n",
    "    mutate_at(vars(-c(`Adjusted p-value`,`Agglutinative Status`)), round,2) %>%\n",
    "    mutate(`Adjusted p-value` = format(round(`Adjusted p-value`,4),nsmall=4)) %>%\n",
    "    mutate(`Adjusted p-value` = gsub(\"0.0000\",\"<.0001\",`Adjusted p-value`)) %>%\n",
    "    unite(\"Estimate (SE)\", c('Estimate','SE'), sep=\" (\") %>%\n",
    "    mutate(`Estimate (SE)` = paste0(`Estimate (SE)`,\")\")) %>%\n",
    "    unite(\"Agglutinative Status (n)\", c(`Agglutinative Status`,'n'), sep=\" (\") %>%\n",
    "    mutate(`Agglutinative Status (n)` = paste0(`Agglutinative Status (n)`,\")\")) %>%\n",
    "    arrange(`Agglutinative Status (n)`)\n",
    "    }\n",
    "    \n",
    "mlu_agg_stats_table <- table_maker(mlu_agg_nest)\n",
    "\n",
    "kable(mlu_agg_stats_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "689e7528",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
