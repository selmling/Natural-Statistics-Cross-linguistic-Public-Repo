{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Statistics Cross-linguistic: \n",
    "\n",
    "#### MLUw analysis - random sample\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0, \"data_proc\")\n",
    "import contingent_extraction\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_dat_inc = pd.read_csv(\"../data/rand_dat_inc_master.csv\",index_col=0,low_memory=False)\n",
    "rand_dat_inc=rand_dat_inc[rand_dat_inc[\"language\"]!=\"ara\"]\n",
    "rand_dat_inc=rand_dat_inc[(rand_dat_inc[\"target_child_age\"]>=5) & (rand_dat_inc[\"target_child_age\"]<=30)]\n",
    "\n",
    "rand_dat_inc_cg = rand_dat_inc[rand_dat_inc[\"caregiver\"]==\"caregiver\"]\n",
    "\n",
    "rand_dat_inc_cg[\"contingent\"] = np.where(rand_dat_inc_cg[\"contingent\"]==1, \"contingent\", \"non-contingent\")\n",
    "\n",
    "rand_dat_inc_cg = rand_dat_inc_cg[rand_dat_inc_cg[\"gloss\"].notna()]\n",
    "rand_dat_inc_cg = rand_dat_inc_cg[rand_dat_inc_cg[\"gloss\"]!=\"xxx\"]\n",
    "rand_dat_inc_cg = rand_dat_inc_cg[rand_dat_inc_cg[\"gloss\"]!=\"yyy\"]\n",
    "rand_dat_inc_cg = rand_dat_inc_cg[rand_dat_inc_cg[\"gloss\"]!=\"www\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_mlu_stats = (rand_dat_inc_cg.groupby([\"Language_name\",\"target_child_id\",\"transcript_id\",\"contingent\"])\n",
    "                                  .num_tokens\n",
    "                                  .agg([\"mean\"])\n",
    "                                  .reset_index())\n",
    "rand_mlu_sumstats =  rand_mlu_stats.rename({'mean': 'means'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_mlu_sumstats.to_csv(\"../data/rand_mlu_sumstats.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### MLUw plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c25847b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Loading required package: Matrix\n",
      "\n",
      "R[write to console]: \n",
      "Attaching package: ‘lmerTest’\n",
      "\n",
      "\n",
      "R[write to console]: The following object is masked from ‘package:lme4’:\n",
      "\n",
      "    lmer\n",
      "\n",
      "\n",
      "R[write to console]: The following object is masked from ‘package:stats’:\n",
      "\n",
      "    step\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n",
      "✔ ggplot2 3.3.6      ✔ purrr   0.3.4 \n",
      "✔ tibble  3.1.8      ✔ dplyr   1.0.10\n",
      "✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n",
      "✔ readr   2.1.2      ✔ forcats 0.5.2 \n",
      "── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "✖ tidyr::expand() masks Matrix::expand()\n",
      "✖ dplyr::filter() masks stats::filter()\n",
      "✖ dplyr::lag()    masks stats::lag()\n",
      "✖ tidyr::pack()   masks Matrix::pack()\n",
      "✖ tidyr::unpack() masks Matrix::unpack()\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "library(\"lme4\")\n",
    "library(\"knitr\")\n",
    "library(\"broom\")\n",
    "library(\"emmeans\")\n",
    "library(\"lmerTest\")\n",
    "library(\"tidyverse\")\n",
    "\n",
    "options(scipen = 999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i rand_mlu_sumstats\n",
    "\n",
    "library('ggplot2')\n",
    "library('repr')\n",
    "options(repr.plot.width=6, repr.plot.height=12)\n",
    "\n",
    "xlabs <- c(\"C\", \"NC\")\n",
    "\n",
    "# ara_label <- data.frame(means=c(0),contingent = c(1.5),language=\"ara\") # no adult speech transcribed\n",
    "deu_label <- data.frame(means=c(5.8),contingent = c(1.5),Language_name=\"German\")\n",
    "eng_label <- data.frame(means=c(5.8),contingent = c(1.5),Language_name=\"English\")\n",
    "est_label <- data.frame(means=c(5.8),contingent = c(1.5),Language_name=\"Estonian\")\n",
    "# fas_label <- data.frame(means=c(5.8),contingent = c(1.5),Language_name=\"Persian\")\n",
    "fas_ns_label <- data.frame(means=c(6),contingent = c(1.5),Language_name=\"Persian\")\n",
    "fra_label <- data.frame(means=c(5.8),contingent = c(1.5),Language_name=\"French\")\n",
    "hrv_label <- data.frame(means=c(5.8),contingent = c(1.5),Language_name=\"Croatian\")\n",
    "jpn_label <- data.frame(means=c(5.8),contingent = c(1.5),Language_name=\"Japanese\")\n",
    "kor_label <- data.frame(means=c(5.8),contingent = c(1.5),Language_name=\"Korean\")\n",
    "# nor_label <- data.frame(means=c(5.8),contingent = c(1.5),Language_name=\"Norwegian\")\n",
    "nor_ns_label <- data.frame(means=c(5.8),contingent = c(1.5),Language_name=\"Norwegian\")\n",
    "pol_label <- data.frame(means=c(6),contingent = c(1.5),Language_name=\"Polish\")\n",
    "por_label <- data.frame(means=c(5.8),contingent = c(1.5),Language_name=\"Portuguese\")\n",
    "spa_label <- data.frame(means=c(5.8),contingent = c(1.5),Language_name=\"Spanish\")\n",
    "swe_label <- data.frame(means=c(5.8),contingent = c(1.5),Language_name=\"Swedish\")\n",
    "# zho_label <- data.frame(means=c(5.8),contingent = c(1.5),Language_name=\"Mandarin\")\n",
    "zho_ns_label <- data.frame(means=c(6),contingent = c(1.5),Language_name=\"Mandarin\")\n",
    "\n",
    "\n",
    "p <- ggplot(rand_mlu_sumstats, aes(x = contingent, y = means, color = Language_name)) +\n",
    "     stat_summary(fun.y=mean, geom=\"point\", shape=19, size=1.75) + \n",
    "     stat_summary(fun.data = mean_se, geom = \"errorbar\", size=1.25, width = .5) +\n",
    "     facet_wrap(. ~ Language_name,ncol = 7) + \n",
    "     geom_text(data = deu_label,label = \"***\",size=8,color=\"black\") + \n",
    "     geom_text(data = eng_label,label = \"***\",size=8,color=\"black\") +  \n",
    "     geom_text(data = est_label,label = \"**\",size=8,color=\"black\") +  \n",
    "     geom_text(data = fas_ns_label,label = \"ns\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "#      geom_text(data = fas_label,label = \"*\",size=8, color=\"black\") +\n",
    "     geom_text(data = fra_label,label = \"***\",size=8,color=\"black\") +  \n",
    "     geom_text(data = hrv_label,label = \"***\",size=8,color=\"black\") + \n",
    "     geom_text(data = jpn_label,label = \"***\",size=8,color=\"black\") + \n",
    "     geom_text(data = kor_label,label = \"***\",size=8,color=\"black\") +  \n",
    "     geom_text(data = nor_ns_label,label = \"**\",size=8,color=\"black\") +  \n",
    "     geom_text(data = pol_label,label = \"ns\", size=4,color=\"black\",fontface = \"italic\") +  \n",
    "     geom_text(data = por_label,label = \"***\",size=8,color=\"black\") +  \n",
    "     geom_text(data = spa_label,label = \"***\",size=8,color=\"black\") + \n",
    "     geom_text(data = swe_label,label = \"***\",size=8,color=\"black\") + \n",
    "     geom_text(data = zho_ns_label,label = \"ns\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "#      geom_text(data = zho_label,label = \"*\",size=8, color=\"black\") +\n",
    "     ylim(0, 6) +\n",
    "     labs(tag=\"B\",\n",
    "          y = \"Mean Length of Utterances in Words\",\n",
    "          x = \"\") +\n",
    "     theme_classic() +\n",
    "     scale_x_discrete(labels= xlabs) +\n",
    "     theme(text = element_text(size=16),\n",
    "           axis.text.x = element_text(vjust = 0.5, hjust=0.5),\n",
    "           legend.title = element_blank(),\n",
    "           legend.background = element_rect(fill=alpha(\"white\",0.90),\n",
    "                                                            size=0, linetype=\"dotted\",\n",
    "                                                            colour = \"white\"),\n",
    "           legend.text=element_text(size=16))\n",
    "      ggsave(\"../figures/token_mlu_rand.pdf\", width = 11.7, height = 6.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for manuscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i rand_mlu_sumstats\n",
    "\n",
    "library('ggplot2')\n",
    "library('repr')\n",
    "options(repr.plot.width=6, repr.plot.height=12)\n",
    "\n",
    "xlabs <- c(\"C\", \"NC\")\n",
    "\n",
    "# ara_label <- data.frame(means=c(0),contingent = c(1.5),language=\"ara\") # no adult speech transcribed\n",
    "deu_label <- data.frame(means=c(5.65),contingent = c(1.5),Language_name=\"German\")\n",
    "eng_label <- data.frame(means=c(5.65),contingent = c(1.5),Language_name=\"English\")\n",
    "est_label <- data.frame(means=c(5.65),contingent = c(1.5),Language_name=\"Estonian\")\n",
    "# fas_label <- data.frame(means=c(5.8),contingent = c(1.5),Language_name=\"Persian\")\n",
    "fas_ns_label <- data.frame(means=c(6),contingent = c(1.5),Language_name=\"Persian\")\n",
    "fra_label <- data.frame(means=c(5.65),contingent = c(1.5),Language_name=\"French\")\n",
    "hrv_label <- data.frame(means=c(5.65),contingent = c(1.5),Language_name=\"Croatian\")\n",
    "jpn_label <- data.frame(means=c(5.65),contingent = c(1.5),Language_name=\"Japanese\")\n",
    "kor_label <- data.frame(means=c(5.65),contingent = c(1.5),Language_name=\"Korean\")\n",
    "# nor_label <- data.frame(means=c(5.8),contingent = c(1.5),Language_name=\"Norwegian\")\n",
    "nor_ns_label <- data.frame(means=c(5.65),contingent = c(1.5),Language_name=\"Norwegian\")\n",
    "pol_label <- data.frame(means=c(6),contingent = c(1.5),Language_name=\"Polish\")\n",
    "por_label <- data.frame(means=c(5.65),contingent = c(1.5),Language_name=\"Portuguese\")\n",
    "spa_label <- data.frame(means=c(5.65),contingent = c(1.5),Language_name=\"Spanish\")\n",
    "swe_label <- data.frame(means=c(5.65),contingent = c(1.5),Language_name=\"Swedish\")\n",
    "# zho_label <- data.frame(means=c(5.8),contingent = c(1.5),Language_name=\"Mandarin\")\n",
    "zho_ns_label <- data.frame(means=c(6),contingent = c(1.5),Language_name=\"Mandarin\")\n",
    "\n",
    "\n",
    "p <- ggplot(rand_mlu_sumstats, aes(x = contingent, y = means, color = Language_name)) +\n",
    "     stat_summary(fun.y=mean, geom=\"point\", shape=19, size=1.75) + \n",
    "     stat_summary(fun.data = mean_se, geom = \"errorbar\", size=1.25, width = .4) +\n",
    "     facet_wrap(. ~ Language_name,ncol = 7) + \n",
    "     geom_text(data = deu_label,label = \"***\",size=6,color=\"black\") + \n",
    "     geom_text(data = eng_label,label = \"***\",size=6,color=\"black\") +  \n",
    "     geom_text(data = est_label,label = \"**\",size=6,color=\"black\") +  \n",
    "     geom_text(data = fas_ns_label,label = \"ns\",size=3,color=\"black\",fontface = \"italic\") +\n",
    "#      geom_text(data = fas_label,label = \"*\",size=8, color=\"black\") +\n",
    "     geom_text(data = fra_label,label = \"***\",size=6,color=\"black\") +  \n",
    "     geom_text(data = hrv_label,label = \"***\",size=6,color=\"black\") + \n",
    "     geom_text(data = jpn_label,label = \"***\",size=6,color=\"black\") + \n",
    "     geom_text(data = kor_label,label = \"***\",size=6,color=\"black\") +  \n",
    "     geom_text(data = nor_ns_label,label = \"**\",size=6,color=\"black\") +  \n",
    "#      geom_text(data = pol_label,label = \"ns\", size=3,color=\"black\",fontface = \"italic\") +  \n",
    "     geom_text(data = por_label,label = \"***\",size=6,color=\"black\") +  \n",
    "     geom_text(data = spa_label,label = \"***\",size=6,color=\"black\") + \n",
    "     geom_text(data = swe_label,label = \"***\",size=6,color=\"black\") + \n",
    "     geom_text(data = zho_ns_label,label = \"ns\",size=3,color=\"black\",fontface = \"italic\") +\n",
    "#      geom_text(data = zho_label,label = \"*\",size=8, color=\"black\") +\n",
    "     ylim(0, 6) +\n",
    "     labs(tag=\"B\",\n",
    "          y = \"Mean Length of Utterances in Words\", x = \"\") +\n",
    "     theme_classic() +\n",
    "     scale_x_discrete(labels= xlabs) +\n",
    "     theme(text = element_text(size=11.5),\n",
    "           axis.text.x = element_text(vjust = 0.5, hjust=0.5),\n",
    "           legend.position=\"none\")\n",
    "      ggsave(\"../figures/figure_2_B.pdf\", width = 11.5, height = 4.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot + effect estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "deu_est_label <- data.frame(means=c(.25),contingent = c(1),Language_name=\"German\")\n",
    "eng_est_label <- data.frame(means=c(.25),contingent = c(1),Language_name=\"English\")\n",
    "est_est_label <- data.frame(means=c(.25),contingent = c(1),Language_name=\"Estonian\")\n",
    "fra_est_label <- data.frame(means=c(.25),contingent = c(1),Language_name=\"French\")\n",
    "hrv_est_label <- data.frame(means=c(.25),contingent = c(1),Language_name=\"Croatian\")\n",
    "jpn_est_label <- data.frame(means=c(.25),contingent = c(1),Language_name=\"Japanese\")\n",
    "kor_est_label <- data.frame(means=c(.25),contingent = c(1),Language_name=\"Korean\")\n",
    "nor_est_label <- data.frame(means=c(.25),contingent = c(1),Language_name=\"Norwegian\")\n",
    "por_est_label <- data.frame(means=c(.25),contingent = c(1),Language_name=\"Portuguese\")\n",
    "spa_est_label <- data.frame(means=c(.25),contingent = c(1),Language_name=\"Spanish\")\n",
    "swe_est_label <- data.frame(means=c(.25),contingent = c(1),Language_name=\"Swedish\")\n",
    "\n",
    "p <- p + geom_text(data = deu_est_label,label = \"est=-.99\",size=4,color=\"black\") +\n",
    "         geom_text(data = eng_est_label,label = \"est=-.62\",size=4,color=\"black\") +\n",
    "         geom_text(data = est_est_label,label = \"est=-.48\",size=4,color=\"black\") +\n",
    "         geom_text(data = fra_est_label,label = \"est=-.39\",size=4,color=\"black\") +\n",
    "         geom_text(data = hrv_est_label,label = \"est=-.46\",size=4,color=\"black\") +\n",
    "         geom_text(data = jpn_est_label,label = \"est=-.65\",size=4,color=\"black\") +\n",
    "         geom_text(data = kor_est_label,label = \"est=-.47\",size=4,color=\"black\") +\n",
    "#          geom_text(data = nor_est_label,label = \"est=-.68\",size=4,color=\"black\") +\n",
    "         geom_text(data = por_est_label,label = \"est=-.66\",size=4,color=\"black\") +\n",
    "         geom_text(data = spa_est_label,label = \"est=-.42\",size=4,color=\"black\") +\n",
    "         geom_text(data = swe_est_label,label = \"est=-.67\",size=4,color=\"black\")\n",
    "         \n",
    "\n",
    "ggsave(\"../figures/token_mlu_rand_eff.pdf\", width = 11.7, height = 6.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\+ sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "deu_n_label <- data.frame(means=c(.25),contingent = c(1.7),Language_name=\"German\")\n",
    "eng_n_label <- data.frame(means=c(.25),contingent = c(1.7),Language_name=\"English\")\n",
    "est_n_label <- data.frame(means=c(.25),contingent = c(1.7),Language_name=\"Estonian\")\n",
    "fas_n_label <- data.frame(means=c(.25),contingent = c(1.7),Language_name=\"Persian\")\n",
    "fra_n_label <- data.frame(means=c(.25),contingent = c(1.7),Language_name=\"French\")\n",
    "hrv_n_label <- data.frame(means=c(.25),contingent = c(1.7),Language_name=\"Croatian\")\n",
    "jpn_n_label <- data.frame(means=c(.25),contingent = c(1.7),Language_name=\"Japanese\")\n",
    "kor_n_label <- data.frame(means=c(.25),contingent = c(1.7),Language_name=\"Korean\")\n",
    "nor_n_label <- data.frame(means=c(.25),contingent = c(1.7),Language_name=\"Norwegian\")\n",
    "pol_n_label <- data.frame(means=c(.25),contingent = c(1.7),Language_name=\"Polish\")\n",
    "por_n_label <- data.frame(means=c(.25),contingent = c(1.7),Language_name=\"Portuguese\")\n",
    "spa_n_label <- data.frame(means=c(.25),contingent = c(1.7),Language_name=\"Spanish\")\n",
    "swe_n_label <- data.frame(means=c(.25),contingent = c(1.7),Language_name=\"Swedish\")\n",
    "zho_n_label <- data.frame(means=c(.25),contingent = c(1.7),Language_name=\"Mandarin\")\n",
    "\n",
    "deu_sz_label <- data.frame(means=c(.25),contingent = c(2.1),Language_name=\"German\")\n",
    "eng_sz_label <- data.frame(means=c(.25),contingent = c(2.1),Language_name=\"English\")\n",
    "est_sz_label <- data.frame(means=c(.25),contingent = c(2.1),Language_name=\"Estonian\")\n",
    "fas_sz_label <- data.frame(means=c(.25),contingent = c(2.1),Language_name=\"Persian\")\n",
    "fra_sz_label <- data.frame(means=c(.25),contingent = c(2.1),Language_name=\"French\")\n",
    "hrv_sz_label <- data.frame(means=c(.25),contingent = c(2.1),Language_name=\"Croatian\")\n",
    "jpn_sz_label <- data.frame(means=c(.25),contingent = c(2.1),Language_name=\"Japanese\")\n",
    "kor_sz_label <- data.frame(means=c(.25),contingent = c(2.1),Language_name=\"Korean\")\n",
    "nor_sz_label <- data.frame(means=c(.25),contingent = c(2.1),Language_name=\"Norwegian\")\n",
    "pol_sz_label <- data.frame(means=c(.25),contingent = c(2.1),Language_name=\"Polish\")\n",
    "por_sz_label <- data.frame(means=c(.25),contingent = c(2.1),Language_name=\"Portuguese\")\n",
    "spa_sz_label <- data.frame(means=c(.25),contingent = c(2.1),Language_name=\"Spanish\")\n",
    "swe_sz_label <- data.frame(means=c(.25),contingent = c(2.1),Language_name=\"Swedish\")\n",
    "zho_sz_label <- data.frame(means=c(.25),contingent = c(2.1),Language_name=\"Mandarin\")\n",
    "\n",
    "p <- p + geom_text(data = deu_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = eng_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = est_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = fas_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = fra_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = hrv_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = jpn_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = kor_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = nor_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = pol_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = por_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = spa_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = swe_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = zho_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = deu_sz_label,label = \" = 39\",size=4,color=\"black\") +\n",
    "         geom_text(data = eng_sz_label,label = \" = 1005\",size=4,color=\"black\") +\n",
    "         geom_text(data = est_sz_label,label = \" = 22\",size=4,color=\"black\") +\n",
    "         geom_text(data = fas_sz_label,label = \" = 12\",size=4,color=\"black\") +\n",
    "         geom_text(data = fra_sz_label,label = \" = 303\",size=4,color=\"black\") +\n",
    "         geom_text(data = hrv_sz_label,label = \" = 79\",size=4,color=\"black\") +\n",
    "         geom_text(data = jpn_sz_label,label = \" = 139\",size=4,color=\"black\") +\n",
    "         geom_text(data = kor_sz_label,label = \" = 37\",size=4,color=\"black\") +\n",
    "         geom_text(data = nor_sz_label,label = \" = 56\",size=4,color=\"black\") +\n",
    "         geom_text(data = pol_sz_label,label = \" = 1\",size=4,color=\"black\") +\n",
    "         geom_text(data = por_sz_label,label = \" = 24\",size=4,color=\"black\") +\n",
    "         geom_text(data = spa_sz_label,label = \" = 31\",size=4,color=\"black\") +\n",
    "         geom_text(data = swe_sz_label,label = \" = 16\",size=4,color=\"black\") +\n",
    "         geom_text(data = zho_sz_label,label = \" = 2\",size=4,color=\"black\")\n",
    "         \n",
    "\n",
    "ggsave(\"../figures/token_mlu_rand_eff_n.pdf\", width = 11.7, height = 6.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By language family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_mlu_stats_fam = (rand_dat_inc_cg.groupby([\"Language_Family\",\"target_child_id\",\"transcript_id\",\"contingent\"])\n",
    "                                  .num_tokens\n",
    "                                  .agg([\"mean\"])\n",
    "                                  .reset_index())\n",
    "rand_mlu_stats_fam =  rand_mlu_stats_fam.rename({'mean': 'means'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining, by = \"Language_Family\"\n",
      "\n",
      "\n",
      "|Language Family (n)  |Estimate (SE) | Test statistic| Effect size|Adjusted p-value |\n",
      "|:--------------------|:-------------|--------------:|-----------:|:----------------|\n",
      "|Indo-European (1483) |-0.58 (0.04)  |         -15.22|       -0.57|<.0001           |\n",
      "|Japonic (160)        |-0.63 (0.04)  |         -17.67|       -1.98|<.0001           |\n",
      "|Koreanic (28)        |-0.46 (0.07)  |          -6.48|       -1.76|<.0001           |\n",
      "|Sino-Tibetan (2)     |-0.93 (0.12)  |          -7.66|      -10.83|0.0078           |\n",
      "|Uralic (22)          |-0.62 (0.11)  |          -5.54|       -1.71|0.0001           |\n"
     ]
    }
   ],
   "source": [
    "%%R -i rand_mlu_stats_fam\n",
    "\n",
    "# plot\n",
    "\n",
    "library('ggplot2')\n",
    "\n",
    "p <- ggplot(rand_mlu_stats_fam, aes(x = contingent, y = means, color = Language_Family)) +\n",
    "     stat_summary(fun.y=mean, geom=\"point\", shape=19, size=1.75) + \n",
    "     stat_summary(fun.data = mean_se, geom = \"errorbar\", size=1.25, width = .5) +\n",
    "     facet_wrap(. ~ Language_Family,ncol=5) + \n",
    "     labs(y = \"Mean length of utterance\", x = \"\") +\n",
    "     theme_classic() +\n",
    "     theme(text = element_text(size=16),\n",
    "           axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),\n",
    "           legend.title = element_blank(),\n",
    "           legend.background = element_rect(fill=alpha(\"white\",0.90),\n",
    "                                                            size=0, linetype=\"dotted\",\n",
    "                                                            colour = \"white\"),\n",
    "           legend.text=element_text(size=16))\n",
    "    ggsave(\"../figures/token_mlu_family.pdf\", width = 11.7, height = 6.2)\n",
    "    \n",
    "# statistical analysis\n",
    "\n",
    "fam_sample_size <- rand_mlu_stats_fam %>%\n",
    "    group_by(Language_Family) %>%\n",
    "    summarize(n = n_distinct(transcript_id))\n",
    "    \n",
    "mlu_fam_nest <- rand_mlu_stats_fam %>%\n",
    "    group_by(Language_Family) %>%\n",
    "    nest() %>%\n",
    "    mutate(fit = map(data, ~ lmer(means ~ contingent +\n",
    "                                (1|transcript_id),\n",
    "                                data = .,\n",
    "                                REML= FALSE)),\n",
    "           summary = map(fit, ~ emmeans(., \"contingent\")),\n",
    "           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\n",
    "           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\n",
    "    select(Language_Family, contrasts, effect_size) %>%\n",
    "    unnest(cols = c(contrasts)) %>%\n",
    "    mutate(effect_size = map(effect_size, ~ summary(.))) %>%\n",
    "    unnest() %>%\n",
    "    mutate(statistic = coalesce(`t.ratio`), .before = p.value) %>%\n",
    "    select (-c(`t.ratio`)) %>%\n",
    "    mutate(p.value = p.adjust(p.value, \"holm\", 5)) %>%\n",
    "    left_join(fam_sample_size)\n",
    "    \n",
    "    table_maker = function(data) { data %>%\n",
    "    select(Language_Family, n, estimate, SE, statistic, effect.size, p.value) %>%\n",
    "    `colnames<-`(c(\"Language Family\", \"n\", \"Estimate\", \"SE\", \"Test statistic\", \"Effect size\", \"Adjusted p-value\")) %>%\n",
    "    mutate_at(vars(-c(`Adjusted p-value`,`Language Family`)), round,2) %>%\n",
    "    mutate(`Adjusted p-value` = format(round(`Adjusted p-value`,4),nsmall=4)) %>%\n",
    "    mutate(`Adjusted p-value` = gsub(\"0.0000\",\"<.0001\",`Adjusted p-value`)) %>%\n",
    "    unite(\"Estimate (SE)\", c('Estimate','SE'), sep=\" (\") %>%\n",
    "    mutate(`Estimate (SE)` = paste0(`Estimate (SE)`,\")\")) %>%\n",
    "    unite(\"Language Family (n)\", c(`Language Family`,'n'), sep=\" (\") %>%\n",
    "    mutate(`Language Family (n)` = paste0(`Language Family (n)`,\")\")) %>%\n",
    "    arrange(`Language Family (n)`)\n",
    "    }\n",
    "    \n",
    "mlu_fam_stats_table <- table_maker(mlu_fam_nest)\n",
    "\n",
    "kable(mlu_fam_stats_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By language genus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_mlu_stats_gen = (rand_dat_inc_cg.groupby([\"Language_Genus\",\"target_child_id\",\"transcript_id\",\"contingent\"])\n",
    "                                  .num_tokens\n",
    "                                  .agg([\"mean\"])\n",
    "                                  .reset_index())\n",
    "rand_mlu_stats_gen = rand_mlu_stats_gen.rename({'mean': 'means'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: boundary (singular) fit: see help('isSingular')\n",
      "\n",
      "R[write to console]: boundary (singular) fit: see help('isSingular')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining, by = \"Language_Genus\"\n",
      "\n",
      "\n",
      "|Language Genus (n) |Estimate (SE) | Test statistic| Effect size|Adjusted p-value |\n",
      "|:------------------|:-------------|--------------:|-----------:|:----------------|\n",
      "|Chinese (2)        |-0.93 (0.12)  |          -7.66|      -10.83|0.0078           |\n",
      "|Finnic (22)        |-0.62 (0.11)  |          -5.54|       -1.71|0.0001           |\n",
      "|Germanic (1077)    |-0.63 (0.05)  |         -12.91|       -0.57|<.0001           |\n",
      "|Iranian (11)       |-0.44 (0.28)  |          -1.59|       -0.71|0.6855           |\n",
      "|Japanese (160)     |-0.63 (0.04)  |         -17.67|       -1.98|<.0001           |\n",
      "|Korean (28)        |-0.46 (0.07)  |          -6.48|       -1.76|<.0001           |\n",
      "|Romance (335)      |-0.48 (0.06)  |          -7.68|       -0.60|<.0001           |\n",
      "|Savlic (60)        |-0.34 (0.08)  |          -4.29|       -0.80|0.0003           |\n"
     ]
    }
   ],
   "source": [
    "%%R -i rand_mlu_stats_gen\n",
    "\n",
    "library('ggplot2')\n",
    "\n",
    "# plot\n",
    "\n",
    "p <- ggplot(rand_mlu_stats_gen, aes(x = contingent, y = means, color = Language_Genus)) +\n",
    "     stat_summary(fun.y=mean, geom=\"point\", shape=19, size=1.75) + \n",
    "     stat_summary(fun.data = mean_se, geom = \"errorbar\", size=1.25, width = .5) +\n",
    "     facet_wrap(. ~ Language_Genus,ncol=8) + \n",
    "     labs(y = \"Mean length of utterance\", x = \"\") +\n",
    "     theme_classic() +\n",
    "     theme(text = element_text(size=16),\n",
    "           axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),\n",
    "           legend.title = element_blank(),\n",
    "           legend.background = element_rect(fill=alpha(\"white\",0.90),\n",
    "                                                            size=0, linetype=\"dotted\",\n",
    "                                                            colour = \"white\"),\n",
    "           legend.text=element_text(size=16))\n",
    "    ggsave(\"../figures/token_mlu_genus.pdf\", width = 11.7, height = 6.2)\n",
    "    \n",
    "# statistical analysis\n",
    "\n",
    "gen_sample_size <- rand_mlu_stats_gen %>%\n",
    "    group_by(Language_Genus) %>%\n",
    "    summarize(n = n_distinct(transcript_id))\n",
    "    \n",
    "mlu_gen_nest <- rand_mlu_stats_gen %>%\n",
    "    group_by(Language_Genus) %>%\n",
    "    nest() %>%\n",
    "    mutate(fit = map(data, ~ lmer(means ~ contingent +\n",
    "                                (1|transcript_id),\n",
    "                                data = .,\n",
    "                                REML= FALSE)),\n",
    "           summary = map(fit, ~ emmeans(., \"contingent\")),\n",
    "           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\n",
    "           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\n",
    "    select(Language_Genus, contrasts, effect_size) %>%\n",
    "    unnest(cols = c(contrasts)) %>%\n",
    "    mutate(effect_size = map(effect_size, ~ summary(.))) %>%\n",
    "    unnest() %>%\n",
    "    mutate(statistic = coalesce(`t.ratio`), .before = p.value) %>%\n",
    "    select (-c(`t.ratio`)) %>%\n",
    "    mutate(p.value = p.adjust(p.value, \"holm\", 5)) %>%\n",
    "    left_join(gen_sample_size)\n",
    "    \n",
    "table_maker = function(data) { data %>%\n",
    "    select(Language_Genus, n, estimate, SE, statistic, effect.size, p.value) %>%\n",
    "    `colnames<-`(c(\"Language Genus\", \"n\", \"Estimate\", \"SE\", \"Test statistic\", \"Effect size\", \"Adjusted p-value\")) %>%\n",
    "    mutate_at(vars(-c(`Adjusted p-value`,`Language Genus`)), round,2) %>%\n",
    "    mutate(`Adjusted p-value` = format(round(`Adjusted p-value`,4),nsmall=4)) %>%\n",
    "    mutate(`Adjusted p-value` = gsub(\"0.0000\",\"<.0001\",`Adjusted p-value`)) %>%\n",
    "    unite(\"Estimate (SE)\", c('Estimate','SE'), sep=\" (\") %>%\n",
    "    mutate(`Estimate (SE)` = paste0(`Estimate (SE)`,\")\")) %>%\n",
    "    unite(\"Language Genus (n)\", c(`Language Genus`,'n'), sep=\" (\") %>%\n",
    "    mutate(`Language Genus (n)` = paste0(`Language Genus (n)`,\")\")) %>%\n",
    "    arrange(`Language Genus (n)`)\n",
    "    }\n",
    "    \n",
    "lexdiv_gen_stats_table <- table_maker(mlu_gen_nest)\n",
    "\n",
    "kable(lexdiv_gen_stats_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By agglutinative status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_mlu_stats_aggl = (rand_dat_inc_cg.groupby([\"Agglutinative\",\"target_child_id\",\"transcript_id\",\"contingent\"])\n",
    "                                  .num_tokens\n",
    "                                  .agg([\"mean\"])\n",
    "                                  .reset_index())\n",
    "rand_mlu_stats_aggl = rand_mlu_stats_aggl.rename({'mean': 'means'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining, by = \"Agglutinative\"\n",
      "\n",
      "\n",
      "|Agglutinative Status (n) |Estimate (SE) | Test statistic| Effect size|Adjusted p-value |\n",
      "|:------------------------|:-------------|--------------:|-----------:|:----------------|\n",
      "|0 (1485)                 |-0.58 (0.04)  |         -15.25|       -0.57|<.0001           |\n",
      "|1 (210)                  |-0.61 (0.03)  |         -19.47|       -1.90|<.0001           |\n"
     ]
    }
   ],
   "source": [
    "%%R -i rand_mlu_stats_aggl\n",
    "\n",
    "library('ggplot2')\n",
    "\n",
    "# plot\n",
    "\n",
    "p <- ggplot(rand_mlu_stats_aggl, aes(x = contingent, y = means, color = Agglutinative)) +\n",
    "     stat_summary(fun.y=mean, geom=\"point\", shape=19, size=1.75) + \n",
    "     stat_summary(fun.data = mean_se, geom = \"errorbar\", size=1.25, width = .5) +\n",
    "     facet_wrap(. ~ Agglutinative) + \n",
    "     labs(y = \"Mean length of utterance\", x = \"\") +\n",
    "     theme_classic() +\n",
    "     theme(text = element_text(size=16),\n",
    "           axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),\n",
    "           legend.title = element_blank(),\n",
    "           legend.background = element_rect(fill=alpha(\"white\",0.90),\n",
    "                                                            size=0, linetype=\"dotted\",\n",
    "                                                            colour = \"white\"),\n",
    "           legend.text=element_text(size=16))\n",
    "    ggsave(\"../figures/token_mlu_aggl.pdf\", width = 11.7, height = 6.2)\n",
    "    \n",
    "# statistical analysis\n",
    "    \n",
    "agg_sample_size <- rand_mlu_stats_aggl %>%\n",
    "    group_by(Agglutinative) %>%\n",
    "    summarize(n = n_distinct(transcript_id))\n",
    "    \n",
    "mlu_agg_nest <- rand_mlu_stats_aggl %>%\n",
    "    group_by(Agglutinative) %>%\n",
    "    nest() %>%\n",
    "    mutate(fit = map(data, ~ lmer(means ~ contingent +\n",
    "                                (1|transcript_id),\n",
    "                                data = .,\n",
    "                                REML= FALSE)),\n",
    "           summary = map(fit, ~ emmeans(., \"contingent\")),\n",
    "           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\n",
    "           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\n",
    "    select(Agglutinative, contrasts, effect_size) %>%\n",
    "    unnest(cols = c(contrasts)) %>%\n",
    "    mutate(effect_size = map(effect_size, ~ summary(.))) %>%\n",
    "    unnest() %>%\n",
    "    mutate(statistic = coalesce(`t.ratio`), .before = p.value) %>%\n",
    "    select (-c(`t.ratio`)) %>%\n",
    "    mutate(p.value = p.adjust(p.value, \"holm\", 5)) %>%\n",
    "    left_join(agg_sample_size)\n",
    "    \n",
    "table_maker = function(data) { data %>%\n",
    "    select(Agglutinative, n, estimate, SE, statistic, effect.size, p.value) %>%\n",
    "    `colnames<-`(c(\"Agglutinative Status\", \"n\", \"Estimate\", \"SE\", \"Test statistic\", \"Effect size\", \"Adjusted p-value\")) %>%\n",
    "    mutate_at(vars(-c(`Adjusted p-value`,`Agglutinative Status`)), round,2) %>%\n",
    "    mutate(`Adjusted p-value` = format(round(`Adjusted p-value`,4),nsmall=4)) %>%\n",
    "    mutate(`Adjusted p-value` = gsub(\"0.0000\",\"<.0001\",`Adjusted p-value`)) %>%\n",
    "    unite(\"Estimate (SE)\", c('Estimate','SE'), sep=\" (\") %>%\n",
    "    mutate(`Estimate (SE)` = paste0(`Estimate (SE)`,\")\")) %>%\n",
    "    unite(\"Agglutinative Status (n)\", c(`Agglutinative Status`,'n'), sep=\" (\") %>%\n",
    "    mutate(`Agglutinative Status (n)` = paste0(`Agglutinative Status (n)`,\")\")) %>%\n",
    "    arrange(`Agglutinative Status (n)`)\n",
    "    }\n",
    "    \n",
    "mlu_agg_stats_table <- table_maker(mlu_agg_nest)\n",
    "\n",
    "kable(mlu_agg_stats_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "689e7528",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLUw_dat = rand_dat_inc_cg[['Language_name','num_tokens','contingent','transcript_id','target_child_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "#### MLUw mixed models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c024fb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: boundary (singular) fit: see help('isSingular')\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'pbkrtest.limit = 6251' (or larger)\n",
      "[or, globally, 'set emm_options(pbkrtest.limit = 6251)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'lmerTest.limit = 6251' (or larger)\n",
      "[or, globally, 'set emm_options(lmerTest.limit = 6251)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'pbkrtest.limit = 113356' (or larger)\n",
      "[or, globally, 'set emm_options(pbkrtest.limit = 113356)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'lmerTest.limit = 113356' (or larger)\n",
      "[or, globally, 'set emm_options(lmerTest.limit = 113356)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'pbkrtest.limit = 21241' (or larger)\n",
      "[or, globally, 'set emm_options(pbkrtest.limit = 21241)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'lmerTest.limit = 21241' (or larger)\n",
      "[or, globally, 'set emm_options(lmerTest.limit = 21241)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'pbkrtest.limit = 4452' (or larger)\n",
      "[or, globally, 'set emm_options(pbkrtest.limit = 4452)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'lmerTest.limit = 4452' (or larger)\n",
      "[or, globally, 'set emm_options(lmerTest.limit = 4452)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'pbkrtest.limit = 25124' (or larger)\n",
      "[or, globally, 'set emm_options(pbkrtest.limit = 25124)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'lmerTest.limit = 25124' (or larger)\n",
      "[or, globally, 'set emm_options(lmerTest.limit = 25124)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'pbkrtest.limit = 4375' (or larger)\n",
      "[or, globally, 'set emm_options(pbkrtest.limit = 4375)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'lmerTest.limit = 4375' (or larger)\n",
      "[or, globally, 'set emm_options(lmerTest.limit = 4375)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'pbkrtest.limit = 4615' (or larger)\n",
      "[or, globally, 'set emm_options(pbkrtest.limit = 4615)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'lmerTest.limit = 4615' (or larger)\n",
      "[or, globally, 'set emm_options(lmerTest.limit = 4615)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining, by = \"Language_name\"\n"
     ]
    }
   ],
   "source": [
    "%%R -i MLUw_dat\n",
    "\n",
    "# vectors for rows to remove from lmer\n",
    "case_study <- c(\"Korean\", \"Mandarin\", \"Persian\") # only 1 target child analyzed\n",
    "\n",
    "single_tran <- c(\"Polish\") # only 1 transcript\n",
    "\n",
    "# nests of models\n",
    "mlu_nest1 <- MLUw_dat %>%\n",
    "    filter(!Language_name %in% case_study) %>%\n",
    "    filter(!Language_name %in% single_tran) %>%\n",
    "    group_by(Language_name) %>%\n",
    "    nest() %>%\n",
    "    mutate(fit = map(data, ~ lmer(num_tokens ~ contingent +\n",
    "                                (1|target_child_id) +\n",
    "                                (1|transcript_id),\n",
    "                                data = .,\n",
    "                                REML= FALSE)),\n",
    "           summary = map(fit, ~ emmeans(., \"contingent\")),\n",
    "           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\n",
    "           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\n",
    "    select(Language_name, contrasts, effect_size) %>%\n",
    "    unnest(cols = c(contrasts)) %>%\n",
    "    mutate(effect_size = map(effect_size, ~ summary(.))) %>%\n",
    "    unnest() %>%\n",
    "    mutate(statistic = coalesce(`z.ratio`,`t.ratio`), .before = p.value) %>%\n",
    "    select (-c(`z.ratio`,`t.ratio`))\n",
    "\n",
    "mlu_nest2 <- MLUw_dat %>%\n",
    "    filter(Language_name %in% case_study) %>%\n",
    "    group_by(Language_name) %>%\n",
    "    nest() %>%\n",
    "    mutate(fit = map(data, ~ lmer(num_tokens ~ contingent +\n",
    "                                (1|transcript_id),\n",
    "                                data = .,\n",
    "                                REML= FALSE)),\n",
    "           summary = map(fit, ~ emmeans(., \"contingent\")),\n",
    "           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\n",
    "           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\n",
    "    select(Language_name, contrasts, effect_size) %>%\n",
    "    unnest(cols = c(contrasts)) %>%\n",
    "    mutate(effect_size = map(effect_size, ~ summary(.))) %>%\n",
    "    unnest() %>%\n",
    "    mutate(statistic = coalesce(`z.ratio`,`t.ratio`), .before = p.value) %>%\n",
    "    select (-c(`z.ratio`,`t.ratio`))\n",
    "\n",
    "mlu_nest3 <- MLUw_dat %>%\n",
    "    filter(Language_name %in% single_tran) %>%\n",
    "    group_by(Language_name) %>%\n",
    "    nest() %>%\n",
    "    mutate(fit = map(data, ~ lm(num_tokens ~ contingent,\n",
    "                                data = .,\n",
    "                                REML= FALSE)),\n",
    "           summary = map(fit, ~ emmeans(., \"contingent\")),\n",
    "           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\n",
    "           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\n",
    "    select(Language_name, contrasts, effect_size) %>%\n",
    "    unnest(cols = c(contrasts)) %>%\n",
    "    mutate(effect_size = map(effect_size, ~ summary(.))) %>%\n",
    "    unnest() %>%\n",
    "    rename(statistic = `t.ratio`)\n",
    "    \n",
    "# number of transcripts per language\n",
    "sample_size <- MLUw_dat %>%\n",
    "    group_by(Language_name) %>%\n",
    "    summarize(n = n_distinct(transcript_id))\n",
    "    \n",
    "# combine lmer summaries and correct p-values for multiple comparisons\n",
    "emms_all <- list(mlu_nest1, mlu_nest2, mlu_nest3) %>% \n",
    "    reduce(bind_rows) %>%\n",
    "    mutate(p.value = p.adjust(p.value, \"holm\", 14)) %>%\n",
    "    left_join(sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1bee59",
   "metadata": {},
   "source": [
    "format statistics table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5789b414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "|Language (n)    |Estimate (SE) | Test statistic| Effect size|Adjusted p-value |\n",
      "|:---------------|:-------------|--------------:|-----------:|:----------------|\n",
      "|Croatian (59)   |-0.36 (0.07)  |          -4.96|       -0.13|<.0001           |\n",
      "|English (995)   |-0.69 (0.03)  |         -26.23|       -0.23|<.0001           |\n",
      "|Estonian (22)   |-0.61 (0.12)  |          -4.89|       -0.22|<.0001           |\n",
      "|French (282)    |-0.53 (0.05)  |          -9.76|       -0.16|<.0001           |\n",
      "|German (38)     |-0.89 (0.11)  |          -8.37|       -0.26|<.0001           |\n",
      "|Japanese (160)  |-0.65 (0.03)  |         -23.53|       -0.32|<.0001           |\n",
      "|Korean (28)     |-0.46 (0.07)  |          -6.67|       -0.22|<.0001           |\n",
      "|Mandarin (2)    |-1 (0.42)     |          -2.37|       -0.31|0.2592           |\n",
      "|Norwegian (28)  |-0.66 (0.14)  |          -4.60|       -0.24|0.0001           |\n",
      "|Persian (11)    |-0.45 (0.23)  |          -1.95|       -0.19|0.7247           |\n",
      "|Polish (1)      |0.22 (0.6)    |           0.36|        0.10|1.0000           |\n",
      "|Portuguese (23) |-0.69 (0.13)  |          -5.32|       -0.22|<.0001           |\n",
      "|Spanish (30)    |-0.53 (0.07)  |          -7.37|       -0.23|<.0001           |\n",
      "|Swedish (16)    |-0.65 (0.09)  |          -6.99|       -0.28|<.0001           |\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "table_maker = function(data) { data %>%\n",
    "    select(Language_name, n, estimate, SE, statistic, effect.size, p.value) %>%\n",
    "    `colnames<-`(c(\"Language\", \"n\", \"Estimate\", \"SE\", \"Test statistic\", \"Effect size\", \"Adjusted p-value\")) %>%\n",
    "    mutate_at(vars(-c(`Adjusted p-value`,Language)), round,2) %>%\n",
    "    mutate(`Adjusted p-value` = format(round(`Adjusted p-value`,4),nsmall=4)) %>%\n",
    "    mutate(`Adjusted p-value` = gsub(\"0.0000\",\"<.0001\",`Adjusted p-value`)) %>%\n",
    "    unite(\"Estimate (SE)\", c('Estimate','SE'), sep=\" (\") %>%\n",
    "    mutate(`Estimate (SE)` = paste0(`Estimate (SE)`,\")\")) %>%\n",
    "    unite(\"Language (n)\", c('Language','n'), sep=\" (\") %>%\n",
    "    mutate(`Language (n)` = paste0(`Language (n)`,\")\")) %>%\n",
    "    arrange(`Language (n)`)\n",
    "    }\n",
    "\n",
    "MLU_stats_table <- table_maker(emms_all)\n",
    "\n",
    "kable(MLU_stats_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8971e4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R \n",
    "\n",
    "# add columns sample and measure and save\n",
    "\n",
    "MLU_stats_table %>%\n",
    "    mutate(sample = \"rand\",\n",
    "           measure = \"mlu\") %>%\n",
    "    write.csv(file = \"../data/rand_mlu_stats.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fd5dde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
