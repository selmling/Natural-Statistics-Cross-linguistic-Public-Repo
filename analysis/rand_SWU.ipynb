{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Statistics Cross-linguistic: \n",
    "\n",
    "#### Proportion of single-word utterances analysis\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0, \"data_proc\")\n",
    "import contingent_extraction\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_dat_inc = pd.read_csv(\"../data/rand_dat_inc_master.csv\",index_col=0,low_memory=False)\n",
    "rand_dat_inc=rand_dat_inc[rand_dat_inc[\"language\"]!=\"ara\"]\n",
    "rand_dat_inc=rand_dat_inc[(rand_dat_inc[\"target_child_age\"]>=5) & (rand_dat_inc[\"target_child_age\"]<=30)]\n",
    "rand_dat_inc_cg = rand_dat_inc[rand_dat_inc[\"caregiver\"]==\"caregiver\"]\n",
    "\n",
    "rand_dat_inc_cg[\"contingent\"] = np.where(rand_dat_inc_cg[\"contingent\"]==1, \"contingent\", \"non-contingent\")\n",
    "\n",
    "rand_dat_inc_cg = rand_dat_inc_cg[rand_dat_inc_cg[\"gloss\"].notna()]\n",
    "rand_dat_inc_cg = rand_dat_inc_cg[rand_dat_inc_cg[\"gloss\"]!=\"xxx\"]\n",
    "rand_dat_inc_cg = rand_dat_inc_cg[rand_dat_inc_cg[\"gloss\"]!=\"yyy\"]\n",
    "rand_dat_inc_cg = rand_dat_inc_cg[rand_dat_inc_cg[\"gloss\"]!=\"www\"]\n",
    "\n",
    "rand_dat_inc_cg[\"swu\"]=np.where(rand_dat_inc_cg[\"num_tokens\"]==1,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_swu_stats = (rand_dat_inc_cg.groupby([\"Language_name\",\"target_child_id\",\"transcript_id\",\"contingent\"])\n",
    "                                  .swu\n",
    "                                  .agg([\"mean\"])\n",
    "                                  .reset_index())\n",
    "rand_swu_sumstats =  rand_swu_stats.rename({'mean': 'means'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_swu_sumstats.to_csv(\"../data/rand_swu_sumstats.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### Proportion single-word utterances plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Loading required package: Matrix\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──\n",
      "✔ ggplot2 3.3.6      ✔ purrr   0.3.4 \n",
      "✔ tibble  3.1.8      ✔ dplyr   1.0.10\n",
      "✔ tidyr   1.2.1      ✔ stringr 1.4.1 \n",
      "✔ readr   2.1.2      ✔ forcats 0.5.2 \n",
      "── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "✖ tidyr::expand() masks Matrix::expand()\n",
      "✖ dplyr::filter() masks stats::filter()\n",
      "✖ dplyr::lag()    masks stats::lag()\n",
      "✖ tidyr::pack()   masks Matrix::pack()\n",
      "✖ tidyr::unpack() masks Matrix::unpack()\n"
     ]
    }
   ],
   "source": [
    "%%R -i rand_swu_sumstats\n",
    "\n",
    "library(\"lme4\")\n",
    "library(\"repr\")\n",
    "library(\"knitr\")\n",
    "library(\"broom\")\n",
    "library(\"emmeans\")\n",
    "library(\"tidyverse\")\n",
    "\n",
    "options(repr.plot.width=6, repr.plot.height=12, scipen=999)\n",
    "\n",
    "xlabs <- c(\"C\", \"NC\")\n",
    "\n",
    "# # ara_label <- data.frame(means=c(.9),contingent = c(1.5),language=\"ara\")\n",
    "deu_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"German\")\n",
    "# deu_ns_label <- data.frame(means=c(.5),contingent = c(1.5),Language_name=\"German\")\n",
    "eng_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"English\")\n",
    "est_label <- data.frame(means=c(.5),contingent = c(1.5),Language_name=\"Estonian\")\n",
    "# est_ns_label <- data.frame(means=c(.5),contingent = c(1.5),Language_name=\"Estonian\")\n",
    "fas_label <- data.frame(means=c(.5),contingent = c(1.5),Language_name=\"Persian\")\n",
    "fra_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"French\")\n",
    "hrv_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"Croatian\")\n",
    "jpn_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"Japanese\")\n",
    "kor_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"Korean\")\n",
    "nor_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"Norwegian\")\n",
    "pol_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"Polish\")\n",
    "por_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"Portuguese\")\n",
    "spa_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"Spanish\")\n",
    "swe_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"Swedish\")\n",
    "zho_label <- data.frame(means=c(.5),contingent = c(1.5),Language_name=\"Mandarin\")\n",
    "\n",
    "\n",
    "p <- ggplot(rand_swu_sumstats, aes(x = contingent, y = means, color = Language_name)) +\n",
    "     stat_summary(fun.y=mean, geom=\"point\", shape=19, size=1.75) + \n",
    "     stat_summary(fun.data = mean_se, geom = \"errorbar\", size=1.25, width = .5) +\n",
    "     facet_wrap(. ~ Language_name,ncol = 7) + \n",
    "     geom_text(data = deu_label,label = \"***\",size=8,color=\"black\") +\n",
    "     geom_text(data = eng_label,label = \"***\",size=8,color=\"black\") +  \n",
    "     geom_text(data = est_label,label = \"ns\", size=4,color=\"black\",fontface = \"italic\") +  \n",
    "     geom_text(data = fas_label,label = \"ns\", size=4,color=\"black\",fontface = \"italic\") + \n",
    "     geom_text(data = fra_label,label = \"***\",size=8,color=\"black\") +  \n",
    "     geom_text(data = hrv_label,label = \"***\",size=8,color=\"black\") + \n",
    "     geom_text(data = jpn_label,label = \"***\",size=8,color=\"black\") + \n",
    "     geom_text(data = kor_label,label = \"***\",size=8,color=\"black\") +  \n",
    "     geom_text(data = nor_label,label = \"**\",size=8,color=\"black\") +  \n",
    "     geom_text(data = pol_label,label = \"ns\", size=4,color=\"black\",fontface = \"italic\") +    \n",
    "     geom_text(data = por_label,label = \"***\",size=8,color=\"black\") +  \n",
    "     geom_text(data = spa_label,label = \"***\",size=8,color=\"black\") + \n",
    "     geom_text(data = swe_label,label = \"***\",size=8,color=\"black\") + \n",
    "     geom_text(data = zho_label,label = \"ns\", size=4, color=\"black\",fontface = \"italic\") +\n",
    "     ylim(0, .5) +\n",
    "     labs(tag=\"C\",\n",
    "          y = \"Proportion of Single Word Utterances\",\n",
    "          x = \"\") +\n",
    "     theme_classic() +\n",
    "     scale_x_discrete(labels= xlabs) +\n",
    "     theme(text = element_text(size=16),\n",
    "           axis.text.x = element_text(vjust = 0.5, hjust = 0.5),\n",
    "           legend.title = element_blank(),\n",
    "           legend.background = element_rect(fill=alpha(\"white\",0.90),\n",
    "                                                            size=0, linetype=\"dotted\",\n",
    "                                                            colour = \"white\"),\n",
    "           legend.text=element_text(size=16))\n",
    "      ggsave(\"../figures/token_rand_swu.pdf\", width = 11.7, height = 6.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for manuscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i rand_swu_sumstats\n",
    "\n",
    "library('ggplot2')\n",
    "library('repr')\n",
    "options(repr.plot.width=6, repr.plot.height=12)\n",
    "\n",
    "xlabs <- c(\"C\", \"NC\")\n",
    "\n",
    "# # ara_label <- data.frame(means=c(.9),contingent = c(1.5),language=\"ara\")\n",
    "deu_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"German\")\n",
    "# deu_ns_label <- data.frame(means=c(.5),contingent = c(1.5),Language_name=\"German\")\n",
    "eng_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"English\")\n",
    "est_label <- data.frame(means=c(.5),contingent = c(1.5),Language_name=\"Estonian\")\n",
    "# est_ns_label <- data.frame(means=c(.5),contingent = c(1.5),Language_name=\"Estonian\")\n",
    "fas_label <- data.frame(means=c(.5),contingent = c(1.5),Language_name=\"Persian\")\n",
    "fra_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"French\")\n",
    "hrv_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"Croatian\")\n",
    "jpn_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"Japanese\")\n",
    "kor_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"Korean\")\n",
    "nor_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"Norwegian\")\n",
    "pol_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"Polish\")\n",
    "por_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"Portuguese\")\n",
    "spa_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"Spanish\")\n",
    "swe_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"Swedish\")\n",
    "zho_label <- data.frame(means=c(.5),contingent = c(1.5),Language_name=\"Mandarin\")\n",
    "\n",
    "\n",
    "p <- ggplot(rand_swu_sumstats, aes(x = contingent, y = means, color = Language_name)) +\n",
    "     stat_summary(fun.y=mean, geom=\"point\", shape=19, size=1.75) + \n",
    "     stat_summary(fun.data = mean_se, geom = \"errorbar\", size=1.25, width = .5) +\n",
    "     facet_wrap(. ~ Language_name,ncol = 7) + \n",
    "     geom_text(data = deu_label,label = \"***\",size=8,color=\"black\") +\n",
    "     geom_text(data = eng_label,label = \"***\",size=8,color=\"black\") +  \n",
    "     geom_text(data = est_label,label = \"ns\", size=4,color=\"black\",fontface = \"italic\") +  \n",
    "     geom_text(data = fas_label,label = \"ns\", size=4,color=\"black\",fontface = \"italic\") + \n",
    "     geom_text(data = fra_label,label = \"***\",size=8,color=\"black\") +  \n",
    "     geom_text(data = hrv_label,label = \"***\",size=8,color=\"black\") + \n",
    "     geom_text(data = jpn_label,label = \"***\",size=8,color=\"black\") + \n",
    "     geom_text(data = kor_label,label = \"***\",size=8,color=\"black\") +  \n",
    "     geom_text(data = nor_label,label = \"**\",size=8,color=\"black\") +  \n",
    "     geom_text(data = pol_label,label = \"ns\", size=4,color=\"black\",fontface = \"italic\") +    \n",
    "     geom_text(data = por_label,label = \"***\",size=8,color=\"black\") +  \n",
    "     geom_text(data = spa_label,label = \"***\",size=8,color=\"black\") + \n",
    "     geom_text(data = swe_label,label = \"***\",size=8,color=\"black\") + \n",
    "     geom_text(data = zho_label,label = \"ns\", size=4, color=\"black\",fontface = \"italic\") +\n",
    "     ylim(0, .5) +\n",
    "     labs(tag=\"C\",\n",
    "          y = \"Proportion of Single Word Utterances\",\n",
    "          x = \"\") +\n",
    "     theme_classic() +\n",
    "     scale_x_discrete(labels= xlabs) +\n",
    "     theme(text = element_text(size=11.5),\n",
    "           axis.text.x = element_text(vjust = 0.5, hjust=0.5),\n",
    "           legend.position=\"none\")\n",
    "\n",
    "      ggsave(\"../figures/figure_2_C.pdf\", width = 11.5, height = 4.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot + effect estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "deu_est_label <- data.frame(means=c(.02),contingent = c(1),Language_name=\"German\")\n",
    "eng_est_label <- data.frame(means=c(.02),contingent = c(1),Language_name=\"English\")\n",
    "est_est_label <- data.frame(means=c(.02),contingent = c(1),Language_name=\"Estonian\")\n",
    "fra_est_label <- data.frame(means=c(.02),contingent = c(1),Language_name=\"French\")\n",
    "hrv_est_label <- data.frame(means=c(.02),contingent = c(1),Language_name=\"Croatian\")\n",
    "jpn_est_label <- data.frame(means=c(.02),contingent = c(1),Language_name=\"Japanese\")\n",
    "kor_est_label <- data.frame(means=c(.02),contingent = c(1),Language_name=\"Korean\")\n",
    "nor_est_label <- data.frame(means=c(.02),contingent = c(1),Language_name=\"Norwegian\")\n",
    "por_est_label <- data.frame(means=c(.02),contingent = c(1),Language_name=\"Portuguese\")\n",
    "spa_est_label <- data.frame(means=c(.02),contingent = c(1),Language_name=\"Spanish\")\n",
    "swe_est_label <- data.frame(means=c(.02),contingent = c(1),Language_name=\"Swedish\")\n",
    "\n",
    "p <- p + geom_text(data = deu_est_label,label = \"est=.08\",size=4,color=\"black\") +\n",
    "         geom_text(data = eng_est_label,label = \"est=.09\",size=4,color=\"black\") +\n",
    "         geom_text(data = est_est_label,label = \"est=.04\",size=4,color=\"black\") +\n",
    "         geom_text(data = fra_est_label,label = \"est=.04\",size=4,color=\"black\") +\n",
    "         geom_text(data = hrv_est_label,label = \"est=.08\",size=4,color=\"black\") +\n",
    "         geom_text(data = jpn_est_label,label = \"est=.18\",size=4,color=\"black\") +\n",
    "         geom_text(data = kor_est_label,label = \"est=.08\",size=4,color=\"black\") +\n",
    "         geom_text(data = nor_est_label,label = \"est=.03\",size=4,color=\"black\") +\n",
    "         geom_text(data = por_est_label,label = \"est=.06\",size=4,color=\"black\") +\n",
    "         geom_text(data = spa_est_label,label = \"est=.06\",size=4,color=\"black\") +\n",
    "         geom_text(data = swe_est_label,label = \"est=.15\",size=4,color=\"black\")\n",
    "         \n",
    "\n",
    "ggsave(\"../figures/token_swu_rand_eff.pdf\", width = 11.7, height = 6.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\+ sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "deu_n_label <- data.frame(means=c(.02),contingent = c(1.7),Language_name=\"German\")\n",
    "eng_n_label <- data.frame(means=c(.02),contingent = c(1.7),Language_name=\"English\")\n",
    "est_n_label <- data.frame(means=c(.02),contingent = c(1.7),Language_name=\"Estonian\")\n",
    "fas_n_label <- data.frame(means=c(.02),contingent = c(1.7),Language_name=\"Persian\")\n",
    "fra_n_label <- data.frame(means=c(.02),contingent = c(1.7),Language_name=\"French\")\n",
    "hrv_n_label <- data.frame(means=c(.02),contingent = c(1.7),Language_name=\"Croatian\")\n",
    "jpn_n_label <- data.frame(means=c(.02),contingent = c(1.7),Language_name=\"Japanese\")\n",
    "kor_n_label <- data.frame(means=c(.02),contingent = c(1.7),Language_name=\"Korean\")\n",
    "nor_n_label <- data.frame(means=c(.02),contingent = c(1.7),Language_name=\"Norwegian\")\n",
    "pol_n_label <- data.frame(means=c(.02),contingent = c(1.7),Language_name=\"Polish\")\n",
    "por_n_label <- data.frame(means=c(.02),contingent = c(1.7),Language_name=\"Portuguese\")\n",
    "spa_n_label <- data.frame(means=c(.02),contingent = c(1.7),Language_name=\"Spanish\")\n",
    "swe_n_label <- data.frame(means=c(.02),contingent = c(1.7),Language_name=\"Swedish\")\n",
    "zho_n_label <- data.frame(means=c(.02),contingent = c(1.7),Language_name=\"Mandarin\")\n",
    "\n",
    "deu_sz_label <- data.frame(means=c(.02),contingent = c(2.1),Language_name=\"German\")\n",
    "eng_sz_label <- data.frame(means=c(.02),contingent = c(2.1),Language_name=\"English\")\n",
    "est_sz_label <- data.frame(means=c(.02),contingent = c(2.1),Language_name=\"Estonian\")\n",
    "fas_sz_label <- data.frame(means=c(.02),contingent = c(2.1),Language_name=\"Persian\")\n",
    "fra_sz_label <- data.frame(means=c(.02),contingent = c(2.1),Language_name=\"French\")\n",
    "hrv_sz_label <- data.frame(means=c(.02),contingent = c(2.1),Language_name=\"Croatian\")\n",
    "jpn_sz_label <- data.frame(means=c(.02),contingent = c(2.1),Language_name=\"Japanese\")\n",
    "kor_sz_label <- data.frame(means=c(.02),contingent = c(2.1),Language_name=\"Korean\")\n",
    "nor_sz_label <- data.frame(means=c(.02),contingent = c(2.1),Language_name=\"Norwegian\")\n",
    "pol_sz_label <- data.frame(means=c(.02),contingent = c(2.1),Language_name=\"Polish\")\n",
    "por_sz_label <- data.frame(means=c(.02),contingent = c(2.1),Language_name=\"Portuguese\")\n",
    "spa_sz_label <- data.frame(means=c(.02),contingent = c(2.1),Language_name=\"Spanish\")\n",
    "swe_sz_label <- data.frame(means=c(.02),contingent = c(2.1),Language_name=\"Swedish\")\n",
    "zho_sz_label <- data.frame(means=c(.02),contingent = c(2.1),Language_name=\"Mandarin\")\n",
    "\n",
    "p <- p + geom_text(data = deu_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = eng_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = est_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = fas_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = fra_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = hrv_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = jpn_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = kor_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = nor_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = pol_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = por_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = spa_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = swe_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = zho_n_label,label = \"n\",size=4,color=\"black\",fontface = \"italic\") +\n",
    "         geom_text(data = deu_sz_label,label = \" = 39\",size=4,color=\"black\") +\n",
    "         geom_text(data = eng_sz_label,label = \" = 1005\",size=4,color=\"black\") +\n",
    "         geom_text(data = est_sz_label,label = \" = 22\",size=4,color=\"black\") +\n",
    "         geom_text(data = fas_sz_label,label = \" = 12\",size=4,color=\"black\") +\n",
    "         geom_text(data = fra_sz_label,label = \" = 303\",size=4,color=\"black\") +\n",
    "         geom_text(data = hrv_sz_label,label = \" = 79\",size=4,color=\"black\") +\n",
    "         geom_text(data = jpn_sz_label,label = \" = 139\",size=4,color=\"black\") +\n",
    "         geom_text(data = kor_sz_label,label = \" = 37\",size=4,color=\"black\") +\n",
    "         geom_text(data = nor_sz_label,label = \" = 56\",size=4,color=\"black\") +\n",
    "         geom_text(data = pol_sz_label,label = \" = 1\",size=4,color=\"black\") +\n",
    "         geom_text(data = por_sz_label,label = \" = 24\",size=4,color=\"black\") +\n",
    "         geom_text(data = spa_sz_label,label = \" = 31\",size=4,color=\"black\") +\n",
    "         geom_text(data = swe_sz_label,label = \" = 16\",size=4,color=\"black\") +\n",
    "         geom_text(data = zho_sz_label,label = \" = 2\",size=4,color=\"black\")\n",
    "         \n",
    "\n",
    "ggsave(\"../figures/token_swu_rand_eff_n.pdf\", width = 11.7, height = 6.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By language family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_swu_stats_fam = (rand_dat_inc_cg.groupby([\"Language_Family\",\"target_child_id\",\"transcript_id\",\"contingent\"])\n",
    "                                  .swu\n",
    "                                  .agg([\"mean\"])\n",
    "                                  .reset_index())\n",
    "rand_swu_stats_fam = rand_swu_stats_fam.rename({'mean': 'means'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining, by = \"Language_Family\"\n",
      "\n",
      "\n",
      "|Language Family (n)  |Estimate (SE) | Test statistic| Effect size|Adjusted p-value |\n",
      "|:--------------------|:-------------|--------------:|-----------:|:----------------|\n",
      "|Indo-European (1483) |0.08 (0.01)   |          16.25|        0.61|<.0001           |\n",
      "|Japonic (160)        |0.18 (0.01)   |          19.75|        2.21|<.0001           |\n",
      "|Koreanic (28)        |0.08 (0.02)   |           5.45|        1.48|<.0001           |\n",
      "|Sino-Tibetan (2)     |0.09 (0.02)   |           4.55|        6.43|0.0522           |\n",
      "|Uralic (22)          |0.06 (0.02)   |           3.36|        1.04|0.0134           |\n"
     ]
    }
   ],
   "source": [
    "%%R -i rand_swu_stats_fam\n",
    "\n",
    "library('ggplot2')\n",
    "\n",
    "# figure\n",
    "\n",
    "p <- ggplot(rand_swu_stats_fam, aes(x = contingent, y = means, color = Language_Family)) +\n",
    "     stat_summary(fun.y=mean, geom=\"point\", shape=19, size=1.75) + \n",
    "     stat_summary(fun.data = mean_se, geom = \"errorbar\", size=1.25, width = .5) +\n",
    "     facet_wrap(. ~ Language_Family,ncol=5) + \n",
    "     ylim(0, .5) +\n",
    "     labs(y = \"Prop. single word utt.\", x = \"\") +\n",
    "     theme_classic() +\n",
    "     theme(text = element_text(size=16),\n",
    "           axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),\n",
    "           legend.title = element_blank(),\n",
    "           legend.background = element_rect(fill=alpha(\"white\",0.90),\n",
    "                                                            size=0, linetype=\"dotted\",\n",
    "                                                            colour = \"white\"),\n",
    "           legend.text=element_text(size=16))\n",
    "\n",
    "    ggsave(\"../figures/token_swu_family.pdf\", width = 11.7, height = 6.2)\n",
    "    \n",
    "# statistical analysis\n",
    "\n",
    "fam_sample_size <- rand_swu_stats_fam %>%\n",
    "    group_by(Language_Family) %>%\n",
    "    summarize(n = n_distinct(transcript_id))\n",
    "    \n",
    "swu_fam_nest <- rand_swu_stats_fam %>%\n",
    "    group_by(Language_Family) %>%\n",
    "    nest() %>%\n",
    "    mutate(fit = map(data, ~ lmer(means ~ contingent +\n",
    "                                (1|transcript_id),\n",
    "                                data = .,\n",
    "                                REML= FALSE)),\n",
    "           summary = map(fit, ~ emmeans(., \"contingent\")),\n",
    "           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\n",
    "           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\n",
    "    select(Language_Family, contrasts, effect_size) %>%\n",
    "    unnest(cols = c(contrasts)) %>%\n",
    "    mutate(effect_size = map(effect_size, ~ summary(.))) %>%\n",
    "    unnest() %>%\n",
    "    mutate(statistic = coalesce(`t.ratio`), .before = p.value) %>%\n",
    "    select (-c(`t.ratio`)) %>%\n",
    "    mutate(p.value = p.adjust(p.value, \"holm\", 5)) %>%\n",
    "    left_join(fam_sample_size)\n",
    "    \n",
    "table_maker = function(data) { data %>%\n",
    "    select(Language_Family, n, estimate, SE, statistic, effect.size, p.value) %>%\n",
    "    `colnames<-`(c(\"Language Family\", \"n\", \"Estimate\", \"SE\", \"Test statistic\", \"Effect size\", \"Adjusted p-value\")) %>%\n",
    "    mutate_at(vars(-c(`Adjusted p-value`,`Language Family`)), round,2) %>%\n",
    "    mutate(`Adjusted p-value` = format(round(`Adjusted p-value`,4),nsmall=4)) %>%\n",
    "    mutate(`Adjusted p-value` = gsub(\"0.0000\",\"<.0001\",`Adjusted p-value`)) %>%\n",
    "    unite(\"Estimate (SE)\", c('Estimate','SE'), sep=\" (\") %>%\n",
    "    mutate(`Estimate (SE)` = paste0(`Estimate (SE)`,\")\")) %>%\n",
    "    unite(\"Language Family (n)\", c(`Language Family`,'n'), sep=\" (\") %>%\n",
    "    mutate(`Language Family (n)` = paste0(`Language Family (n)`,\")\")) %>%\n",
    "    arrange(`Language Family (n)`)\n",
    "    }\n",
    "    \n",
    "swu_fam_stats_table <- table_maker(swu_fam_nest)\n",
    "\n",
    "kable(swu_fam_stats_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By language Genus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_swu_stats_gen = (rand_dat_inc_cg.groupby([\"Language_Genus\",\"target_child_id\",\"transcript_id\",\"contingent\"])\n",
    "                                  .swu\n",
    "                                  .agg([\"mean\"])\n",
    "                                  .reset_index())\n",
    "rand_swu_stats_gen = rand_swu_stats_gen.rename({'mean': 'means'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining, by = \"Language_Genus\"\n",
      "\n",
      "\n",
      "|Language Genus (n) |Estimate (SE) | Test statistic| Effect size|Adjusted p-value |\n",
      "|:------------------|:-------------|--------------:|-----------:|:----------------|\n",
      "|Chinese (2)        |0.09 (0.02)   |           4.55|        6.43|0.0522           |\n",
      "|Finnic (22)        |0.06 (0.02)   |           3.36|        1.04|0.0134           |\n",
      "|Germanic (1077)    |0.09 (0.01)   |          14.69|        0.65|<.0001           |\n",
      "|Iranian (11)       |0.12 (0.05)   |           2.58|        1.15|0.1205           |\n",
      "|Japanese (160)     |0.18 (0.01)   |          19.75|        2.21|<.0001           |\n",
      "|Korean (28)        |0.08 (0.02)   |           5.45|        1.48|<.0001           |\n",
      "|Romance (335)      |0.05 (0.01)   |           5.89|        0.46|<.0001           |\n",
      "|Savlic (60)        |0.07 (0.02)   |           4.28|        0.79|0.0003           |\n"
     ]
    }
   ],
   "source": [
    "%%R -i rand_swu_stats_gen\n",
    "\n",
    "library('ggplot2')\n",
    "\n",
    "# plot\n",
    "\n",
    "p <- ggplot(rand_swu_stats_gen, aes(x = contingent, y = means, color = Language_Genus)) +\n",
    "     stat_summary(fun.y=mean, geom=\"point\", shape=19, size=1.75) + \n",
    "     stat_summary(fun.data = mean_se, geom = \"errorbar\", size=1.25, width = .5) +\n",
    "     facet_wrap(. ~ Language_Genus,ncol=8) + \n",
    "     ylim(0, .5) +\n",
    "     labs(y = \"Prop. single word utt.\", x = \"\") +\n",
    "     theme_classic() +\n",
    "     theme(text = element_text(size=16),\n",
    "           axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),\n",
    "           legend.title = element_blank(),\n",
    "           legend.background = element_rect(fill=alpha(\"white\",0.90),\n",
    "                                                            size=0, linetype=\"dotted\",\n",
    "                                                            colour = \"white\"),\n",
    "           legend.text=element_text(size=16))\n",
    "    ggsave(\"../figures/token_swu_genus.pdf\", width = 11.7, height = 6.2)\n",
    "    \n",
    "# statistical analysis\n",
    "\n",
    "gen_sample_size <- rand_swu_stats_gen %>%\n",
    "    group_by(Language_Genus) %>%\n",
    "    summarize(n = n_distinct(transcript_id))\n",
    "    \n",
    "swu_gen_nest <- rand_swu_stats_gen %>%\n",
    "    group_by(Language_Genus) %>%\n",
    "    nest() %>%\n",
    "    mutate(fit = map(data, ~ lmer(means ~ contingent +\n",
    "                                (1|transcript_id),\n",
    "                                data = .,\n",
    "                                REML= FALSE)),\n",
    "           summary = map(fit, ~ emmeans(., \"contingent\")),\n",
    "           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\n",
    "           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\n",
    "    select(Language_Genus, contrasts, effect_size) %>%\n",
    "    unnest(cols = c(contrasts)) %>%\n",
    "    mutate(effect_size = map(effect_size, ~ summary(.))) %>%\n",
    "    unnest() %>%\n",
    "    mutate(statistic = coalesce(`t.ratio`), .before = p.value) %>%\n",
    "    select (-c(`t.ratio`)) %>%\n",
    "    mutate(p.value = p.adjust(p.value, \"holm\", 5)) %>%\n",
    "    left_join(gen_sample_size)\n",
    "    \n",
    "table_maker = function(data) { data %>%\n",
    "    select(Language_Genus, n, estimate, SE, statistic, effect.size, p.value) %>%\n",
    "    `colnames<-`(c(\"Language Genus\", \"n\", \"Estimate\", \"SE\", \"Test statistic\", \"Effect size\", \"Adjusted p-value\")) %>%\n",
    "    mutate_at(vars(-c(`Adjusted p-value`,`Language Genus`)), round,2) %>%\n",
    "    mutate(`Adjusted p-value` = format(round(`Adjusted p-value`,4),nsmall=4)) %>%\n",
    "    mutate(`Adjusted p-value` = gsub(\"0.0000\",\"<.0001\",`Adjusted p-value`)) %>%\n",
    "    unite(\"Estimate (SE)\", c('Estimate','SE'), sep=\" (\") %>%\n",
    "    mutate(`Estimate (SE)` = paste0(`Estimate (SE)`,\")\")) %>%\n",
    "    unite(\"Language Genus (n)\", c(`Language Genus`,'n'), sep=\" (\") %>%\n",
    "    mutate(`Language Genus (n)` = paste0(`Language Genus (n)`,\")\")) %>%\n",
    "    arrange(`Language Genus (n)`)\n",
    "    }\n",
    "    \n",
    "swu_gen_stats_table <- table_maker(swu_gen_nest)\n",
    "\n",
    "kable(swu_gen_stats_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By agglutinative status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_swu_stats_aggl = (rand_dat_inc_cg.groupby([\"Agglutinative\",\"target_child_id\",\"transcript_id\",\"contingent\"])\n",
    "                                  .swu\n",
    "                                  .agg([\"mean\"])\n",
    "                                  .reset_index())\n",
    "rand_swu_stats_aggl =  rand_swu_stats_aggl.rename({'mean': 'means'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining, by = \"Agglutinative\"\n",
      "\n",
      "\n",
      "|Agglutinative Status (n) |Estimate (SE) | Test statistic| Effect size|Adjusted p-value |\n",
      "|:------------------------|:-------------|--------------:|-----------:|:----------------|\n",
      "|0 (1485)                 |0.08 (0.01)   |          16.27|        0.61|<.0001           |\n",
      "|1 (210)                  |0.15 (0.01)   |          19.10|        1.87|<.0001           |\n"
     ]
    }
   ],
   "source": [
    "%%R -i rand_swu_stats_aggl\n",
    "\n",
    "library('ggplot2')\n",
    "\n",
    "# plot\n",
    "\n",
    "p <- ggplot(rand_swu_stats_aggl, aes(x = contingent, y = means, color = Agglutinative)) +\n",
    "     stat_summary(fun.y=mean, geom=\"point\", shape=19, size=1.75) + \n",
    "     stat_summary(fun.data = mean_se, geom = \"errorbar\", size=1.25, width = .5) +\n",
    "     facet_wrap(. ~ Agglutinative,ncol=2) + \n",
    "     ylim(0, .5) +\n",
    "     labs(y = \"Prop. single word utt.\", x = \"\") +\n",
    "     theme_classic() +\n",
    "     theme(text = element_text(size=16),\n",
    "           axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1),\n",
    "           legend.title = element_blank(),\n",
    "           legend.background = element_rect(fill=alpha(\"white\",0.90),\n",
    "                                                            size=0, linetype=\"dotted\",\n",
    "                                                            colour = \"white\"),\n",
    "           legend.text=element_text(size=16))\n",
    "\n",
    "    ggsave(\"../figures/token_swu_aggl.pdf\", width = 11.7, height = 6.2)\n",
    "  \n",
    "# statistical analysis\n",
    "    \n",
    "agg_sample_size <- rand_swu_stats_aggl %>%\n",
    "    group_by(Agglutinative) %>%\n",
    "    summarize(n = n_distinct(transcript_id))\n",
    "    \n",
    "swu_agg_nest <- rand_swu_stats_aggl %>%\n",
    "    group_by(Agglutinative) %>%\n",
    "    nest() %>%\n",
    "    mutate(fit = map(data, ~ lmer(means ~ contingent +\n",
    "                                (1|transcript_id),\n",
    "                                data = .,\n",
    "                                REML= FALSE)),\n",
    "           summary = map(fit, ~ emmeans(., \"contingent\")),\n",
    "           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\n",
    "           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\n",
    "    select(Agglutinative, contrasts, effect_size) %>%\n",
    "    unnest(cols = c(contrasts)) %>%\n",
    "    mutate(effect_size = map(effect_size, ~ summary(.))) %>%\n",
    "    unnest() %>%\n",
    "    mutate(statistic = coalesce(`t.ratio`), .before = p.value) %>%\n",
    "    select (-c(`t.ratio`)) %>%\n",
    "    mutate(p.value = p.adjust(p.value, \"holm\", 5)) %>%\n",
    "    left_join(agg_sample_size)\n",
    "    \n",
    "table_maker = function(data) { data %>%\n",
    "    select(Agglutinative, n, estimate, SE, statistic, effect.size, p.value) %>%\n",
    "    `colnames<-`(c(\"Agglutinative Status\", \"n\", \"Estimate\", \"SE\", \"Test statistic\", \"Effect size\", \"Adjusted p-value\")) %>%\n",
    "    mutate_at(vars(-c(`Adjusted p-value`,`Agglutinative Status`)), round,2) %>%\n",
    "    mutate(`Adjusted p-value` = format(round(`Adjusted p-value`,4),nsmall=4)) %>%\n",
    "    mutate(`Adjusted p-value` = gsub(\"0.0000\",\"<.0001\",`Adjusted p-value`)) %>%\n",
    "    unite(\"Estimate (SE)\", c('Estimate','SE'), sep=\" (\") %>%\n",
    "    mutate(`Estimate (SE)` = paste0(`Estimate (SE)`,\")\")) %>%\n",
    "    unite(\"Agglutinative Status (n)\", c(`Agglutinative Status`,'n'), sep=\" (\") %>%\n",
    "    mutate(`Agglutinative Status (n)` = paste0(`Agglutinative Status (n)`,\")\")) %>%\n",
    "    arrange(`Agglutinative Status (n)`)\n",
    "    }\n",
    "    \n",
    "swu_agg_stats_table <- table_maker(swu_agg_nest)\n",
    "\n",
    "kable(swu_agg_stats_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bde3ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SWU_dat = rand_dat_inc_cg[['Language_name','swu','contingent','transcript_id','target_child_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "486a39d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: boundary (singular) fit: see help('isSingular')\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'pbkrtest.limit = 6251' (or larger)\n",
      "[or, globally, 'set emm_options(pbkrtest.limit = 6251)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'lmerTest.limit = 6251' (or larger)\n",
      "[or, globally, 'set emm_options(lmerTest.limit = 6251)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'pbkrtest.limit = 113356' (or larger)\n",
      "[or, globally, 'set emm_options(pbkrtest.limit = 113356)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'lmerTest.limit = 113356' (or larger)\n",
      "[or, globally, 'set emm_options(lmerTest.limit = 113356)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'pbkrtest.limit = 21241' (or larger)\n",
      "[or, globally, 'set emm_options(pbkrtest.limit = 21241)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'lmerTest.limit = 21241' (or larger)\n",
      "[or, globally, 'set emm_options(lmerTest.limit = 21241)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'pbkrtest.limit = 4452' (or larger)\n",
      "[or, globally, 'set emm_options(pbkrtest.limit = 4452)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'lmerTest.limit = 4452' (or larger)\n",
      "[or, globally, 'set emm_options(lmerTest.limit = 4452)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'pbkrtest.limit = 25124' (or larger)\n",
      "[or, globally, 'set emm_options(pbkrtest.limit = 25124)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'lmerTest.limit = 25124' (or larger)\n",
      "[or, globally, 'set emm_options(lmerTest.limit = 25124)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'pbkrtest.limit = 4375' (or larger)\n",
      "[or, globally, 'set emm_options(pbkrtest.limit = 4375)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'lmerTest.limit = 4375' (or larger)\n",
      "[or, globally, 'set emm_options(lmerTest.limit = 4375)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'pbkrtest.limit = 4615' (or larger)\n",
      "[or, globally, 'set emm_options(pbkrtest.limit = 4615)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'lmerTest.limit = 4615' (or larger)\n",
      "[or, globally, 'set emm_options(lmerTest.limit = 4615)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining, by = \"Language_name\"\n"
     ]
    }
   ],
   "source": [
    "%%R -i SWU_dat\n",
    "\n",
    "# vectors for rows to remove from lmer\n",
    "case_study <- c(\"Korean\", \"Mandarin\", \"Persian\") # only 1 target child analyzed\n",
    "\n",
    "single_tran <- c(\"Polish\") # only 1 transcript\n",
    "\n",
    "# nests of models\n",
    "swu_nest1 <- SWU_dat %>%\n",
    "    filter(!Language_name %in% case_study) %>%\n",
    "    filter(!Language_name %in% single_tran) %>%\n",
    "    group_by(Language_name) %>%\n",
    "    nest() %>%\n",
    "    mutate(fit = map(data, ~ lmer(swu ~ contingent +\n",
    "                                (1|target_child_id) +\n",
    "                                (1|transcript_id),\n",
    "                                data = .,\n",
    "                                REML= FALSE)),\n",
    "           summary = map(fit, ~ emmeans(., \"contingent\")),\n",
    "           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\n",
    "           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\n",
    "    select(Language_name, contrasts, effect_size) %>%\n",
    "    unnest(cols = c(contrasts)) %>%\n",
    "    mutate(effect_size = map(effect_size, ~ summary(.))) %>%\n",
    "    unnest() %>%\n",
    "    mutate(statistic = coalesce(`z.ratio`,`t.ratio`), .before = p.value) %>%\n",
    "    select (-c(`z.ratio`,`t.ratio`))\n",
    "\n",
    "swu_nest2 <- SWU_dat %>%\n",
    "    filter(Language_name %in% case_study) %>%\n",
    "    group_by(Language_name) %>%\n",
    "    nest() %>%\n",
    "    mutate(fit = map(data, ~ lmer(swu ~ contingent +\n",
    "                                (1|transcript_id),\n",
    "                                data = .,\n",
    "                                REML= FALSE)),\n",
    "           summary = map(fit, ~ emmeans(., \"contingent\")),\n",
    "           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\n",
    "           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\n",
    "    select(Language_name, contrasts, effect_size) %>%\n",
    "    unnest(cols = c(contrasts)) %>%\n",
    "    mutate(effect_size = map(effect_size, ~ summary(.))) %>%\n",
    "    unnest() %>%\n",
    "    mutate(statistic = coalesce(`z.ratio`,`t.ratio`), .before = p.value) %>%\n",
    "    select (-c(`z.ratio`,`t.ratio`))\n",
    "\n",
    "swu_nest3 <- SWU_dat %>%\n",
    "    filter(Language_name %in% single_tran) %>%\n",
    "    group_by(Language_name) %>%\n",
    "    nest() %>%\n",
    "    mutate(fit = map(data, ~ lm(swu ~ contingent,\n",
    "                                data = .,\n",
    "                                REML= FALSE)),\n",
    "           summary = map(fit, ~ emmeans(., \"contingent\")),\n",
    "           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\n",
    "           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\n",
    "    select(Language_name, contrasts, effect_size) %>%\n",
    "    unnest(cols = c(contrasts)) %>%\n",
    "    mutate(effect_size = map(effect_size, ~ summary(.))) %>%\n",
    "    unnest() %>%\n",
    "    rename(statistic = `t.ratio`)\n",
    "    \n",
    "# number of transcripts per language\n",
    "sample_size <- SWU_dat %>%\n",
    "    group_by(Language_name) %>%\n",
    "    summarize(n = n_distinct(transcript_id))\n",
    "    \n",
    "# combine lmer summaries and correct p-values for multiple comparisons\n",
    "emms_all <- list(swu_nest1, swu_nest2, swu_nest3) %>% \n",
    "    reduce(bind_rows) %>%\n",
    "    mutate(p.value = p.adjust(p.value, \"holm\", 14)) %>%\n",
    "    left_join(sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fa8ee8",
   "metadata": {},
   "source": [
    "format statistics table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "890d2b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "|Language (n)    |Estimate (SE) | Test statistic| Effect size|Adjusted p-value |\n",
      "|:---------------|:-------------|--------------:|-----------:|:----------------|\n",
      "|Croatian (59)   |0.07 (0.01)   |           6.46|        0.17|<.0001           |\n",
      "|English (995)   |0.11 (0)      |          30.33|        0.27|<.0001           |\n",
      "|Estonian (22)   |0.04 (0.01)   |           2.87|        0.13|0.0571           |\n",
      "|French (282)    |0.05 (0.01)   |           7.78|        0.13|<.0001           |\n",
      "|German (38)     |0.08 (0.01)   |           6.50|        0.20|<.0001           |\n",
      "|Japanese (160)  |0.18 (0.01)   |          27.63|        0.37|<.0001           |\n",
      "|Korean (28)     |0.08 (0.01)   |           8.02|        0.26|<.0001           |\n",
      "|Mandarin (2)    |0.09 (0.04)   |           2.11|        0.27|0.4939           |\n",
      "|Norwegian (28)  |0.1 (0.02)    |           4.78|        0.25|<.0001           |\n",
      "|Persian (11)    |0.13 (0.05)   |           2.70|        0.26|0.0990           |\n",
      "|Polish (1)      |0.04 (0.11)   |           0.40|        0.11|1.0000           |\n",
      "|Portuguese (23) |0.07 (0.01)   |           4.91|        0.20|<.0001           |\n",
      "|Spanish (30)    |0.09 (0.01)   |           7.30|        0.22|<.0001           |\n",
      "|Swedish (16)    |0.14 (0.02)   |           7.89|        0.32|<.0001           |\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "table_maker = function(data) { data %>%\n",
    "    select(Language_name, n, estimate, SE, statistic, effect.size, p.value) %>%\n",
    "    `colnames<-`(c(\"Language\", \"n\", \"Estimate\", \"SE\", \"Test statistic\", \"Effect size\", \"Adjusted p-value\")) %>%\n",
    "    mutate_at(vars(-c(`Adjusted p-value`,Language)), round,2) %>%\n",
    "    mutate(`Adjusted p-value` = format(round(`Adjusted p-value`,4),nsmall=4)) %>%\n",
    "    mutate(`Adjusted p-value` = gsub(\"0.0000\",\"<.0001\",`Adjusted p-value`)) %>%\n",
    "    unite(\"Estimate (SE)\", c('Estimate','SE'), sep=\" (\") %>%\n",
    "    mutate(`Estimate (SE)` = paste0(`Estimate (SE)`,\")\")) %>%\n",
    "    unite(\"Language (n)\", c('Language','n'), sep=\" (\") %>%\n",
    "    mutate(`Language (n)` = paste0(`Language (n)`,\")\")) %>%\n",
    "    arrange(`Language (n)`)\n",
    "    }\n",
    "\n",
    "SWU_stats_table <- table_maker(emms_all)\n",
    "\n",
    "kable(SWU_stats_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7132ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R \n",
    "\n",
    "# add columns sample and measure and save\n",
    "\n",
    "SWU_stats_table %>%\n",
    "    mutate(sample = \"rand\",\n",
    "           measure = \"swu\") %>%\n",
    "    write.csv(file = \"../data/rand_swu_stats.csv\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "#### SWU mixed models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "deu=rand_dat_inc_cg[['language','swu','contingent','transcript_id','target_child_id']][rand_dat_inc_cg[\"language\"]==\"deu\"]\n",
    "eng=rand_dat_inc_cg[['language','swu','contingent','transcript_id','target_child_id']][rand_dat_inc_cg[\"language\"]==\"eng\"]\n",
    "est=rand_dat_inc_cg[['language','swu','contingent','transcript_id','target_child_id']][rand_dat_inc_cg[\"language\"]==\"est\"]\n",
    "fas=rand_dat_inc_cg[['language','swu','contingent','transcript_id','target_child_id']][rand_dat_inc_cg[\"language\"]==\"fas\"]\n",
    "fra=rand_dat_inc_cg[['language','swu','contingent','transcript_id','target_child_id']][rand_dat_inc_cg[\"language\"]==\"fra\"]\n",
    "hrv=rand_dat_inc_cg[['language','swu','contingent','transcript_id','target_child_id']][rand_dat_inc_cg[\"language\"]==\"hrv\"]\n",
    "jpn=rand_dat_inc_cg[['language','swu','contingent','transcript_id','target_child_id']][rand_dat_inc_cg[\"language\"]==\"jpn\"]\n",
    "kor=rand_dat_inc_cg[['language','swu','contingent','transcript_id','target_child_id']][rand_dat_inc_cg[\"language\"]==\"kor\"]\n",
    "nor=rand_dat_inc_cg[['language','swu','contingent','transcript_id','target_child_id']][rand_dat_inc_cg[\"language\"]==\"nor\"]\n",
    "pol=rand_dat_inc_cg[['language','swu','contingent','transcript_id','target_child_id']][rand_dat_inc_cg[\"language\"]==\"pol\"]\n",
    "por=rand_dat_inc_cg[['language','swu','contingent','transcript_id','target_child_id']][rand_dat_inc_cg[\"language\"]==\"por\"]\n",
    "spa=rand_dat_inc_cg[['language','swu','contingent','transcript_id','target_child_id']][rand_dat_inc_cg[\"language\"]==\"spa\"]\n",
    "swe=rand_dat_inc_cg[['language','swu','contingent','transcript_id','target_child_id']][rand_dat_inc_cg[\"language\"]==\"swe\"]\n",
    "zho=rand_dat_inc_cg[['language','swu','contingent','transcript_id','target_child_id']][rand_dat_inc_cg[\"language\"]==\"zho\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Loading required package: Matrix\n",
      "\n",
      "R[write to console]: \n",
      "Attaching package: ‘lmerTest’\n",
      "\n",
      "\n",
      "R[write to console]: The following object is masked from ‘package:lme4’:\n",
      "\n",
      "    lmer\n",
      "\n",
      "\n",
      "R[write to console]: The following object is masked from ‘package:stats’:\n",
      "\n",
      "    step\n",
      "\n",
      "\n",
      "R[write to console]: ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n",
      "\n",
      "R[write to console]: ✔ tibble  3.1.8      ✔ dplyr   1.0.10\n",
      "✔ tidyr   1.2.0      ✔ stringr 1.4.1 \n",
      "✔ readr   2.1.2      ✔ forcats 0.5.2 \n",
      "✔ purrr   0.3.5      \n",
      "\n",
      "R[write to console]: ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "✖ tidyr::expand() masks Matrix::expand()\n",
      "✖ dplyr::filter() masks stats::filter()\n",
      "✖ dplyr::lag()    masks stats::lag()\n",
      "✖ tidyr::pack()   masks Matrix::pack()\n",
      "✖ tidyr::unpack() masks Matrix::unpack()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "library(\"lme4\")\n",
    "library(\"broom\")\n",
    "library(\"emmeans\")\n",
    "library(\"lmerTest\")\n",
    "library(\"tidyverse\")\n",
    "\n",
    "options(scipen = 999)\n",
    "\n",
    "effect_sizes <- data.frame(matrix(ncol = 2, nrow = 0))\n",
    "cols <- c(\"Language_name\", \"rand_effect_size\")\n",
    "colnames(effect_sizes) <- cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'pbkrtest.limit = 4452' (or larger)\n",
      "[or, globally, 'set emm_options(pbkrtest.limit = 4452)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'lmerTest.limit = 4452' (or larger)\n",
      "[or, globally, 'set emm_options(lmerTest.limit = 4452)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate     SE  df z.ratio p.value\n",
      " contingent - (non-contingent)    0.081 0.0125 Inf   6.498  <.0001\n",
      "\n",
      "Degrees-of-freedom method: asymptotic \n",
      "\n",
      "[[2]]\n",
      "[1] 0.00000000008122039\n",
      "\n",
      "[1] 0.000000001137085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Since 'object' is a list, we are using the contrasts already present.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Language_name  rand_effect_size\n",
      "1           deu 0.203791769489804\n"
     ]
    }
   ],
   "source": [
    "%%R -i deu\n",
    "\n",
    "lm2_1 <- lmer(swu ~ contingent + (1|target_child_id) + (1|transcript_id),data=deu)\n",
    "emm2_1<-emmeans(lm2_1,pairwise~contingent)\n",
    "pval<-summary(emm2_1$contrasts)$p.value\n",
    "print(c(emm2_1$contrasts, pval))\n",
    "print(p.adjust(pval, \"holm\", 14))\n",
    "# plot(emm2_1)\n",
    "# summary(emmeans(lm2_1,\"contingent\",infer=TRUE)) #group means\n",
    "# test(contrast(emmeans(lm2_1,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "deu_lname <- deu$language[1]\n",
    "\n",
    "deu_eff <- eff_size(emm2_1,sigma = sigma(lm2_1), edf = df.residual(lm2_1))\n",
    "\n",
    "deu_eff <- summary(deu_eff)$effect.size\n",
    "\n",
    "effect_sizes[nrow(effect_sizes)+1,] <- c(deu_lname,deu_eff)\n",
    "effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'pbkrtest.limit = 113356' (or larger)\n",
      "[or, globally, 'set emm_options(pbkrtest.limit = 113356)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'lmerTest.limit = 113356' (or larger)\n",
      "[or, globally, 'set emm_options(lmerTest.limit = 113356)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate      SE  df z.ratio p.value\n",
      " contingent - (non-contingent)    0.107 0.00351 Inf  30.329  <.0001\n",
      "\n",
      "Degrees-of-freedom method: asymptotic \n",
      "\n",
      "[[2]]\n",
      "[1] 0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000004692424\n",
      "\n",
      "[1] 0.000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000006569394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Since 'object' is a list, we are using the contrasts already present.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Language_name  rand_effect_size\n",
      "1           deu 0.203791769489804\n",
      "2           eng 0.267969063164672\n"
     ]
    }
   ],
   "source": [
    "%%R -i eng\n",
    "\n",
    "lm3_1 <- lmer(swu ~ contingent + (1|target_child_id) + (1|transcript_id),data=eng, REML= FALSE)\n",
    "emm3_1<-emmeans(lm3_1,pairwise~contingent)\n",
    "pval<-summary(emm3_1$contrasts)$p.value\n",
    "print(c(emm3_1$contrasts, pval))\n",
    "print(p.adjust(pval, \"holm\", 14))\n",
    "# summary(emmeans(lm3_1,\"contingent\",infer=TRUE)) #group means\n",
    "# test(contrast(emmeans(lm3_1,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "eng_lname <- eng$language[1]\n",
    "\n",
    "eng_eff <- eff_size(emm3_1,sigma = sigma(lm3_1), edf = df.residual(lm3_1))\n",
    "\n",
    "eng_eff <- summary(eng_eff)$effect.size\n",
    "\n",
    "effect_sizes[nrow(effect_sizes)+1,] <- c(eng_lname,eng_eff)\n",
    "effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate     SE   df t.ratio p.value\n",
      " contingent - (non-contingent)   0.0427 0.0148 2309   2.875  0.0041\n",
      "\n",
      "Degrees-of-freedom method: kenward-roger \n",
      "\n",
      "[[2]]\n",
      "[1] 0.004079875\n",
      "\n",
      "[1] 0.05711826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Since 'object' is a list, we are using the contrasts already present.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Language_name  rand_effect_size\n",
      "1           deu 0.203791769489804\n",
      "2           eng 0.267969063164672\n",
      "3           est 0.125671598106875\n"
     ]
    }
   ],
   "source": [
    "%%R -i est\n",
    "\n",
    "lm4_1 <- lmer(swu ~ contingent + (1|target_child_id) + (1|transcript_id),data=est, REML= FALSE)\n",
    "emm4_1<-emmeans(lm4_1,pairwise~contingent)\n",
    "pval<-summary(emm4_1$contrasts)$p.value\n",
    "print(c(emm4_1$contrasts, pval))\n",
    "print(p.adjust(pval, \"holm\", 14))\n",
    "# summary(emmeans(lm4_1,\"contingent\",infer=TRUE)) #group means\n",
    "# test(contrast(emmeans(lm4_1,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "est_lname <- est$language[1]\n",
    "\n",
    "est_eff <- eff_size(emm4_1,sigma = sigma(lm4_1), edf = df.residual(lm4_1))\n",
    "\n",
    "est_eff <- summary(est_eff)$effect.size\n",
    "\n",
    "effect_sizes[nrow(effect_sizes)+1,] <- c(est_lname,est_eff)\n",
    "effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate     SE  df t.ratio p.value\n",
      " contingent - (non-contingent)    0.125 0.0463 641   2.702  0.0071\n",
      "\n",
      "Degrees-of-freedom method: kenward-roger \n",
      "\n",
      "[[2]]\n",
      "[1] 0.007072117\n",
      "\n",
      "[1] 0.09900964\n",
      "  Language_name  rand_effect_size\n",
      "1           deu 0.203791769489804\n",
      "2           eng 0.267969063164672\n",
      "3           est 0.125671598106875\n",
      "4           fas               NaN\n"
     ]
    }
   ],
   "source": [
    "%%R -i fas\n",
    "\n",
    "lm5_1 <- lmer(swu ~ contingent + (1|transcript_id),data=fas, REML= FALSE)\n",
    "emm5_1<-emmeans(lm5_1,pairwise~contingent)\n",
    "pval<-summary(emm5_1$contrasts)$p.value\n",
    "print(c(emm5_1$contrasts, pval))\n",
    "print(p.adjust(pval, \"holm\", 14))\n",
    "# summary(emmeans(lm5_1,\"contingent\",infer=TRUE)) #group means\n",
    "# test(contrast(emmeans(lm5_1,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "fas_lname <- fas$language[1]\n",
    "\n",
    "effect_sizes[nrow(effect_sizes)+1,] <- c(fas_lname,NaN)\n",
    "effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'pbkrtest.limit = 21241' (or larger)\n",
      "[or, globally, 'set emm_options(pbkrtest.limit = 21241)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'lmerTest.limit = 21241' (or larger)\n",
      "[or, globally, 'set emm_options(lmerTest.limit = 21241)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate      SE  df z.ratio p.value\n",
      " contingent - (non-contingent)   0.0509 0.00654 Inf   7.779  <.0001\n",
      "\n",
      "Degrees-of-freedom method: asymptotic \n",
      "\n",
      "[[2]]\n",
      "[1] 0.000000000000007299281\n",
      "\n",
      "[1] 0.0000000000001021899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Since 'object' is a list, we are using the contrasts already present.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Language_name  rand_effect_size\n",
      "1           deu 0.203791769489804\n",
      "2           eng 0.267969063164672\n",
      "3           est 0.125671598106875\n",
      "4           fas               NaN\n",
      "5           fra 0.129286127432911\n"
     ]
    }
   ],
   "source": [
    "%%R -i fra\n",
    "lm6_1 <- lmer(swu ~ contingent + (1|target_child_id) + (1|transcript_id),data=fra, REML= FALSE)\n",
    "emm6_1<-emmeans(lm6_1,pairwise~contingent)\n",
    "pval<-summary(emm6_1$contrasts)$p.value\n",
    "print(c(emm6_1$contrasts, pval))\n",
    "print(p.adjust(pval, \"holm\", 14))\n",
    "# summary(emmeans(lm6_1,\"contingent\",infer=TRUE)) #group means\n",
    "# test(contrast(emmeans(lm6_1,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "fra_lname <- fra$language[1]\n",
    "\n",
    "fra_eff <- eff_size(emm6_1,sigma = sigma(lm6_1), edf = df.residual(lm6_1))\n",
    "\n",
    "fra_eff <- summary(fra_eff)$effect.size\n",
    "\n",
    "effect_sizes[nrow(effect_sizes)+1,] <- c(fra_lname,fra_eff)\n",
    "effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'pbkrtest.limit = 6251' (or larger)\n",
      "[or, globally, 'set emm_options(pbkrtest.limit = 6251)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'lmerTest.limit = 6251' (or larger)\n",
      "[or, globally, 'set emm_options(lmerTest.limit = 6251)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate     SE  df z.ratio p.value\n",
      " contingent - (non-contingent)   0.0693 0.0107 Inf   6.463  <.0001\n",
      "\n",
      "Degrees-of-freedom method: asymptotic \n",
      "\n",
      "[[2]]\n",
      "[1] 0.0000000001023428\n",
      "\n",
      "[1] 0.000000001432799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Since 'object' is a list, we are using the contrasts already present.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Language_name  rand_effect_size\n",
      "1           deu 0.203791769489804\n",
      "2           eng 0.267969063164672\n",
      "3           est 0.125671598106875\n",
      "4           fas               NaN\n",
      "5           fra 0.129286127432911\n",
      "6           hrv 0.169079925211206\n"
     ]
    }
   ],
   "source": [
    "%%R -i hrv\n",
    "\n",
    "lm7_1 <- lmer(swu ~ contingent + (1|target_child_id) + (1|transcript_id),data=hrv, REML= FALSE)\n",
    "emm7_1<-emmeans(lm7_1,pairwise~contingent)\n",
    "pval<-summary(emm7_1$contrasts)$p.value\n",
    "print(c(emm7_1$contrasts, pval))\n",
    "print(p.adjust(pval, \"holm\", 14))\n",
    "# summary(emmeans(lm7_1,\"contingent\",infer=TRUE)) #group means\n",
    "# test(contrast(emmeans(lm7_1,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "hrv_lname <- hrv$language[1]\n",
    "\n",
    "hrv_eff <- eff_size(emm7_1,sigma = sigma(lm7_1), edf = df.residual(lm7_1))\n",
    "\n",
    "hrv_eff <- summary(hrv_eff)$effect.size\n",
    "\n",
    "effect_sizes[nrow(effect_sizes)+1,] <- c(hrv_lname,hrv_eff)\n",
    "effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'pbkrtest.limit = 25124' (or larger)\n",
      "[or, globally, 'set emm_options(pbkrtest.limit = 25124)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'lmerTest.limit = 25124' (or larger)\n",
      "[or, globally, 'set emm_options(lmerTest.limit = 25124)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate      SE  df z.ratio p.value\n",
      " contingent - (non-contingent)    0.175 0.00634 Inf  27.631  <.0001\n",
      "\n",
      "Degrees-of-freedom method: asymptotic \n",
      "\n",
      "[[2]]\n",
      "[1] 0.000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000004779791\n",
      "\n",
      "[1] 0.00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000006691708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Since 'object' is a list, we are using the contrasts already present.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Language_name  rand_effect_size\n",
      "1           deu 0.203791769489804\n",
      "2           eng 0.267969063164672\n",
      "3           est 0.125671598106875\n",
      "4           fas               NaN\n",
      "5           fra 0.129286127432911\n",
      "6           hrv 0.169079925211206\n",
      "7           jpn 0.370538605687043\n"
     ]
    }
   ],
   "source": [
    "%%R -i jpn\n",
    "\n",
    "lm8_1 <- lmer(swu ~ contingent + (1|target_child_id) + (1|transcript_id),data=jpn, REML= FALSE)\n",
    "emm8_1<-emmeans(lm8_1,pairwise~contingent)\n",
    "pval<-summary(emm8_1$contrasts)$p.value\n",
    "print(c(emm8_1$contrasts, pval))\n",
    "print(p.adjust(pval, \"holm\", 14))\n",
    "# summary(emmeans(lm8_1,\"contingent\",infer=TRUE)) #group means\n",
    "# test(contrast(emmeans(lm8_1,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "jpn_lname <- jpn$language[1]\n",
    "\n",
    "jpn_eff <- eff_size(emm8_1,sigma = sigma(lm8_1), edf = df.residual(lm8_1))\n",
    "\n",
    "jpn_eff <- summary(jpn_eff)$effect.size\n",
    "\n",
    "effect_sizes[nrow(effect_sizes)+1,] <- c(jpn_lname,jpn_eff)\n",
    "effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'pbkrtest.limit = 4615' (or larger)\n",
      "[or, globally, 'set emm_options(pbkrtest.limit = 4615)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'lmerTest.limit = 4615' (or larger)\n",
      "[or, globally, 'set emm_options(lmerTest.limit = 4615)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate     SE  df z.ratio p.value\n",
      " contingent - (non-contingent)   0.0848 0.0106 Inf   8.024  <.0001\n",
      "\n",
      "Degrees-of-freedom method: asymptotic \n",
      "\n",
      "[[2]]\n",
      "[1] 0.000000000000001023043\n",
      "\n",
      "[1] 0.00000000000001432261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Since 'object' is a list, we are using the contrasts already present.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Language_name  rand_effect_size\n",
      "1           deu 0.203791769489804\n",
      "2           eng 0.267969063164672\n",
      "3           est 0.125671598106875\n",
      "4           fas               NaN\n",
      "5           fra 0.129286127432911\n",
      "6           hrv 0.169079925211206\n",
      "7           jpn 0.370538605687043\n",
      "8           kor  0.25819504353917\n"
     ]
    }
   ],
   "source": [
    "%%R -i kor\n",
    "\n",
    "lm9_1 <- lmer(swu ~ contingent + (1|transcript_id),data=kor, REML= FALSE)\n",
    "emm9_1<-emmeans(lm9_1,pairwise~contingent)\n",
    "pval<-summary(emm9_1$contrasts)$p.value\n",
    "print(c(emm9_1$contrasts, pval))\n",
    "print(p.adjust(pval, \"holm\", 14))\n",
    "# summary(emmeans(lm9_1,\"contingent\",infer=TRUE)) #group means\n",
    "# test(contrast(emmeans(lm9_1,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "kor_lname <- kor$language[1]\n",
    "\n",
    "kor_eff <- eff_size(emm9_1,sigma = sigma(lm9_1), edf = df.residual(lm9_1))\n",
    "\n",
    "kor_eff <- summary(kor_eff)$effect.size\n",
    "\n",
    "effect_sizes[nrow(effect_sizes)+1,] <- c(kor_lname,kor_eff)\n",
    "effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: boundary (singular) fit: see help('isSingular')\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate     SE   df t.ratio p.value\n",
      " contingent - (non-contingent)    0.101 0.0211 1923   4.784  <.0001\n",
      "\n",
      "Degrees-of-freedom method: kenward-roger \n",
      "\n",
      "[[2]]\n",
      "[1] 0.000001850965\n",
      "\n",
      "[1] 0.00002591352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Since 'object' is a list, we are using the contrasts already present.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Language_name  rand_effect_size\n",
      "1           deu 0.203791769489804\n",
      "2           eng 0.267969063164672\n",
      "3           est 0.125671598106875\n",
      "4           fas               NaN\n",
      "5           fra 0.129286127432911\n",
      "6           hrv 0.169079925211206\n",
      "7           jpn 0.370538605687043\n",
      "8           kor  0.25819504353917\n",
      "9           nor 0.250109617249279\n"
     ]
    }
   ],
   "source": [
    "%%R -i nor\n",
    "\n",
    "lm10_1 <- lmer(swu ~ contingent + (1|target_child_id) + (1|transcript_id),data=nor, REML= FALSE)\n",
    "emm10_1<-emmeans(lm10_1,pairwise~contingent)\n",
    "pval<-summary(emm10_1$contrasts)$p.value\n",
    "print(c(emm10_1$contrasts, pval))\n",
    "print(p.adjust(pval, \"holm\", 14))\n",
    "# summary(emmeans(lm10_1,\"contingent\",infer=TRUE)) #group means\n",
    "# test(contrast(emmeans(lm10_1,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "nor_lname <- nor$language[1]\n",
    "\n",
    "nor_eff <- eff_size(emm10_1,sigma = sigma(lm10_1), edf = df.residual(lm10_1))\n",
    "\n",
    "nor_eff <- summary(nor_eff)$effect.size\n",
    "\n",
    "effect_sizes[nrow(effect_sizes)+1,] <- c(nor_lname,nor_eff)\n",
    "effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate    SE df t.ratio p.value\n",
      " contingent - (non-contingent)    0.045 0.112 50   0.401  0.6898\n",
      "\n",
      "\n",
      "[[2]]\n",
      "[1] 0.689809\n",
      "\n",
      "[1] 1\n",
      "   Language_name  rand_effect_size\n",
      "1            deu 0.203791769489804\n",
      "2            eng 0.267969063164672\n",
      "3            est 0.125671598106875\n",
      "4            fas               NaN\n",
      "5            fra 0.129286127432911\n",
      "6            hrv 0.169079925211206\n",
      "7            jpn 0.370538605687043\n",
      "8            kor  0.25819504353917\n",
      "9            nor 0.250109617249279\n",
      "10           pol               NaN\n"
     ]
    }
   ],
   "source": [
    "%%R -i pol\n",
    " \n",
    "# simple linear model (no random effects, because only 1 transcript from 1 sub)\n",
    "\n",
    "lm11_1 <- lm(swu ~ contingent,data=pol, REML= FALSE)\n",
    "emm11_1<-emmeans(lm11_1,pairwise~contingent)\n",
    "pval<-summary(emm11_1$contrasts)$p.value\n",
    "print(c(emm11_1$contrasts, pval))\n",
    "print(p.adjust(pval, \"holm\", 14))\n",
    "# summary(emmeans(lm11_1,\"contingent\",infer=TRUE)) #group means\n",
    "# test(contrast(emmeans(lm11_1,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "pol_lname <- pol$language[1]\n",
    "\n",
    "effect_sizes[nrow(effect_sizes)+1,] <- c(pol_lname,NaN)\n",
    "effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate     SE   df t.ratio p.value\n",
      " contingent - (non-contingent)   0.0698 0.0142 2661   4.905  <.0001\n",
      "\n",
      "Degrees-of-freedom method: kenward-roger \n",
      "\n",
      "[[2]]\n",
      "[1] 0.00000099005\n",
      "\n",
      "[1] 0.0000138607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Since 'object' is a list, we are using the contrasts already present.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Language_name  rand_effect_size\n",
      "1            deu 0.203791769489804\n",
      "2            eng 0.267969063164672\n",
      "3            est 0.125671598106875\n",
      "4            fas               NaN\n",
      "5            fra 0.129286127432911\n",
      "6            hrv 0.169079925211206\n",
      "7            jpn 0.370538605687043\n",
      "8            kor  0.25819504353917\n",
      "9            nor 0.250109617249279\n",
      "10           pol               NaN\n",
      "11           por  0.19962474315635\n"
     ]
    }
   ],
   "source": [
    "%%R -i por\n",
    "\n",
    "lm12_1 <- lmer(swu ~ contingent + (1|target_child_id) + (1|transcript_id),data=por, REML= FALSE)\n",
    "emm12_1<-emmeans(lm12_1,pairwise~contingent)\n",
    "pval<-summary(emm12_1$contrasts)$p.value\n",
    "print(c(emm12_1$contrasts, pval))\n",
    "print(p.adjust(pval, \"holm\", 14))\n",
    "# summary(emmeans(lm12_1,\"contingent\",infer=TRUE)) #group means\n",
    "# test(contrast(emmeans(lm12_1,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "por_lname <- por$language[1]\n",
    "\n",
    "por_eff <- eff_size(emm12_1,sigma = sigma(lm12_1), edf = df.residual(lm12_1))\n",
    "\n",
    "por_eff <- summary(por_eff)$effect.size\n",
    "\n",
    "effect_sizes[nrow(effect_sizes)+1,] <- c(por_lname,por_eff)\n",
    "effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'pbkrtest.limit = 4375' (or larger)\n",
      "[or, globally, 'set emm_options(pbkrtest.limit = 4375)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'lmerTest.limit = 4375' (or larger)\n",
      "[or, globally, 'set emm_options(lmerTest.limit = 4375)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate     SE  df z.ratio p.value\n",
      " contingent - (non-contingent)   0.0907 0.0124 Inf   7.301  <.0001\n",
      "\n",
      "Degrees-of-freedom method: asymptotic \n",
      "\n",
      "[[2]]\n",
      "[1] 0.000000000000286318\n",
      "\n",
      "[1] 0.000000000004008452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Since 'object' is a list, we are using the contrasts already present.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Language_name  rand_effect_size\n",
      "1            deu 0.203791769489804\n",
      "2            eng 0.267969063164672\n",
      "3            est 0.125671598106875\n",
      "4            fas               NaN\n",
      "5            fra 0.129286127432911\n",
      "6            hrv 0.169079925211206\n",
      "7            jpn 0.370538605687043\n",
      "8            kor  0.25819504353917\n",
      "9            nor 0.250109617249279\n",
      "10           pol               NaN\n",
      "11           por  0.19962474315635\n",
      "12           spa 0.223848639903587\n"
     ]
    }
   ],
   "source": [
    "%%R -i spa\n",
    "\n",
    "lm13_1 <- lmer(swu ~ contingent + (1|target_child_id) + (1|transcript_id),data=spa, REML= FALSE)\n",
    "emm13_1<-emmeans(lm13_1,pairwise~contingent)\n",
    "pval<-summary(emm13_1$contrasts)$p.value\n",
    "print(c(emm13_1$contrasts, pval))\n",
    "print(p.adjust(pval, \"holm\", 14))\n",
    "# summary(emmeans(lm13_1,\"contingent\",infer=TRUE)) #group means\n",
    "# test(contrast(emmeans(lm13_1,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "spa_lname <- spa$language[1]\n",
    "\n",
    "spa_eff <- eff_size(emm13_1,sigma = sigma(lm13_1), edf = df.residual(lm13_1))\n",
    "\n",
    "spa_eff <- summary(spa_eff)$effect.size\n",
    "\n",
    "effect_sizes[nrow(effect_sizes)+1,] <- c(spa_lname,spa_eff)\n",
    "effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate     SE   df t.ratio p.value\n",
      " contingent - (non-contingent)    0.136 0.0172 2715   7.892  <.0001\n",
      "\n",
      "Degrees-of-freedom method: kenward-roger \n",
      "\n",
      "[[2]]\n",
      "[1] 0.000000000000004279189\n",
      "\n",
      "[1] 0.00000000000005990865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Since 'object' is a list, we are using the contrasts already present.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Language_name  rand_effect_size\n",
      "1            deu 0.203791769489804\n",
      "2            eng 0.267969063164672\n",
      "3            est 0.125671598106875\n",
      "4            fas               NaN\n",
      "5            fra 0.129286127432911\n",
      "6            hrv 0.169079925211206\n",
      "7            jpn 0.370538605687043\n",
      "8            kor  0.25819504353917\n",
      "9            nor 0.250109617249279\n",
      "10           pol               NaN\n",
      "11           por  0.19962474315635\n",
      "12           spa 0.223848639903587\n",
      "13           swe 0.316404337565653\n"
     ]
    }
   ],
   "source": [
    "%%R -i swe\n",
    "\n",
    "\n",
    "lm14_1 <- lmer(swu ~ contingent + (1|target_child_id) + (1|transcript_id),data=swe, REML= FALSE)\n",
    "emm14_1<-emmeans(lm14_1,pairwise~contingent)\n",
    "pval<-summary(emm14_1$contrasts)$p.value\n",
    "print(c(emm14_1$contrasts, pval))\n",
    "print(p.adjust(pval, \"holm\", 14))\n",
    "# summary(emmeans(lm14_1,\"contingent\",infer=TRUE)) #group means\n",
    "# test(contrast(emmeans(lm14_1,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "swe_lname <- swe$language[1]\n",
    "\n",
    "swe_eff <- eff_size(emm14_1,sigma = sigma(lm14_1), edf = df.residual(lm14_1))\n",
    "\n",
    "swe_eff <- summary(swe_eff)$effect.size\n",
    "\n",
    "effect_sizes[nrow(effect_sizes)+1,] <- c(swe_lname,swe_eff)\n",
    "effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      " contrast                      estimate     SE  df t.ratio p.value\n",
      " contingent - (non-contingent)    0.087 0.0412 379   2.113  0.0353\n",
      "\n",
      "Degrees-of-freedom method: kenward-roger \n",
      "\n",
      "[[2]]\n",
      "[1] 0.03527606\n",
      "\n",
      "[1] 0.4938648\n",
      "   Language_name  rand_effect_size\n",
      "1            deu 0.203791769489804\n",
      "2            eng 0.267969063164672\n",
      "3            est 0.125671598106875\n",
      "4            fas               NaN\n",
      "5            fra 0.129286127432911\n",
      "6            hrv 0.169079925211206\n",
      "7            jpn 0.370538605687043\n",
      "8            kor  0.25819504353917\n",
      "9            nor 0.250109617249279\n",
      "10           pol               NaN\n",
      "11           por  0.19962474315635\n",
      "12           spa 0.223848639903587\n",
      "13           swe 0.316404337565653\n",
      "14           zho               NaN\n"
     ]
    }
   ],
   "source": [
    "%%R -i zho\n",
    "\n",
    "lm15_1 <- lmer(swu ~ contingent + (1|transcript_id),data=zho, REML= FALSE)\n",
    "emm15_1<-emmeans(lm15_1,pairwise~contingent)\n",
    "pval<-summary(emm15_1$contrasts)$p.value\n",
    "print(c(emm15_1$contrasts, pval))\n",
    "print(p.adjust(pval, \"holm\", 14))\n",
    "# summary(emmeans(lm15_1,\"contingent\",infer=TRUE)) #group means\n",
    "# test(contrast(emmeans(lm15_1,\"contingent\"), \"trt.vs.ctrl\"), joint = TRUE) #main effect - are any groups different\n",
    "\n",
    "zho_lname <- zho$language[1]\n",
    "\n",
    "effect_sizes[nrow(effect_sizes)+1,] <- c(zho_lname,NaN)\n",
    "effect_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "write.csv(x=effect_sizes,'../data/SWU_effect_sizes.csv', row.names = FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519ef895",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
