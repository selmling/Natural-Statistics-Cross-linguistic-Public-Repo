{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Statistics Cross-linguistic: \n",
    "\n",
    "#### Proportion of single-word utterances analysis\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.insert(0, \"data_proc\")\n",
    "import contingent_extraction\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2363117",
   "metadata": {},
   "outputs": [],
   "source": [
    "TSE_rand_dat_inc = pd.read_csv(\"../data/TSE_cont_dat.csv\")\n",
    "TSE_rand_dat_inc.rename(columns={'Langauge_name': 'Language_name'}, inplace=True)\n",
    "TSE_rand_dat_inc['target_child_id'] = TSE_rand_dat_inc['transcript_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1f3d1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_dat_inc = pd.read_csv(\"../data/rand_dat_inc_master.csv\",index_col=0,low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01a82b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and clean data\n",
    "rand_dat_inc=rand_dat_inc[rand_dat_inc[\"language\"]!=\"ara\"]\n",
    "rand_dat_inc=rand_dat_inc[(rand_dat_inc[\"target_child_age\"]>=5) & (rand_dat_inc[\"target_child_age\"]<=30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca1b1812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this way we include older and younger Tseltal kids\n",
    "rand_dat_inc = pd.concat([TSE_rand_dat_inc, rand_dat_inc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_dat_inc_cg = rand_dat_inc[rand_dat_inc[\"caregiver\"]==\"caregiver\"]\n",
    "\n",
    "rand_dat_inc_cg[\"contingent\"] = np.where(rand_dat_inc_cg[\"contingent\"]==1, \"contingent\", \"non-contingent\")\n",
    "\n",
    "rand_dat_inc_cg = rand_dat_inc_cg[rand_dat_inc_cg[\"gloss\"].notna()]\n",
    "rand_dat_inc_cg = rand_dat_inc_cg[rand_dat_inc_cg[\"gloss\"]!=\"xxx\"]\n",
    "rand_dat_inc_cg = rand_dat_inc_cg[rand_dat_inc_cg[\"gloss\"]!=\"yyy\"]\n",
    "rand_dat_inc_cg = rand_dat_inc_cg[rand_dat_inc_cg[\"gloss\"]!=\"www\"]\n",
    "\n",
    "rand_dat_inc_cg[\"swu\"]=np.where(rand_dat_inc_cg[\"num_tokens\"]==1,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e85955a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add play context and year of study\n",
    "\n",
    "play_context = pd.read_csv(\"../data/context_data.csv\")\n",
    "play_context = play_context.rename(columns={\"Corpus\": \"corpus_name\"})\n",
    "\n",
    "# print(play_context.to_markdown())\n",
    "\n",
    "rand_dat_inc_cg = rand_dat_inc_cg.merge(play_context,on='corpus_name')\n",
    "\n",
    "rand_dat_inc_cg[\"context\"] = rand_dat_inc_cg[\"Location\"] + rand_dat_inc_cg[\"Activity\"]\n",
    "\n",
    "rand_dat_inc_cg[\"context\"] = rand_dat_inc_cg[\"context\"].replace({\"HomeBook-reading\":\"Home: book reading\",\n",
    "                                                                 \"HomeInterview/Unstructured\":\"Home: interview/unstructured\",\n",
    "                                                                 \"HomeNaN\":\"Home: unreported\",\n",
    "                                                                 \"HomeOther\":\"Home: other\",\n",
    "                                                                 \"HomeUnstructured\":\"Home: unstructured\",\n",
    "                                                                 \"LabOther\":\"Lab: other\",\n",
    "                                                                 \"LabTabletop play\":\"Lab: tabletop play\",\n",
    "                                                                 \"LabInterview/Unstructured\":\"Lab: interview/unstructured\",\n",
    "                                                                 \"LabUnstructured\":\"Lab: unstructured\",\n",
    "                                                                 np.nan:\"Unreported\",\n",
    "                                                                 \"OtherUnstructured\":\"Other: unstructured\"})\n",
    "\n",
    "# year of study\n",
    "# corpora_year = pd.read_csv(\"../data/corpora_year.csv\")\n",
    "# corpora_year = corpora_year.rename(columns={\"Corpora\": \"corpus_name\"})\n",
    "# corpora_year = corpora_year[[\"corpus_name\", \"Year collected\"]]\n",
    "\n",
    "# rand_dat_inc_cg = rand_dat_inc_cg.merge(corpora_year,on='corpus_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2b7aeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c4ca659",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Loading required package: Matrix\n",
      "\n",
      "R[write to console]: Welcome to emmeans.\n",
      "Caution: You lose important information if you filter this package's results.\n",
      "See '? untidy'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n",
      "✔ dplyr     1.1.4     ✔ readr     2.1.5\n",
      "✔ forcats   1.0.0     ✔ stringr   1.5.1\n",
      "✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n",
      "✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n",
      "✔ purrr     1.0.2     \n",
      "── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "✖ tidyr::expand() masks Matrix::expand()\n",
      "✖ dplyr::filter() masks stats::filter()\n",
      "✖ dplyr::lag()    masks stats::lag()\n",
      "✖ tidyr::pack()   masks Matrix::pack()\n",
      "✖ tidyr::unpack() masks Matrix::unpack()\n",
      "ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: \n",
      "Attaching package: ‘kableExtra’\n",
      "\n",
      "\n",
      "R[write to console]: The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    group_rows\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R -i rand_dat_inc_cg\n",
    "\n",
    "library(\"lme4\")\n",
    "library(\"repr\")\n",
    "library(\"knitr\")\n",
    "library(\"broom\")\n",
    "library(\"emmeans\")\n",
    "library(\"tidyverse\")\n",
    "library(\"kableExtra\")\n",
    "\n",
    "options(repr.plot.width=6, repr.plot.height=12, scipen=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aaac32e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining with `by = join_by(transcript_id)`\n"
     ]
    }
   ],
   "source": [
    "%%R -o rand_dat_inc_cg\n",
    "\n",
    "# ---- create caregiver type categories\n",
    "\n",
    "caregiver_type <- rand_dat_inc_cg %>%\n",
    "  group_by(transcript_id) %>%\n",
    "  summarise(\n",
    "    caregiver_type = case_when(\n",
    "      all(speaker_role == \"Mother\") ~ \"Mother only\",\n",
    "      all(speaker_role == \"Father\") ~ \"Father only\",\n",
    "      any(speaker_role %in% c(\"Mother\", \"Father\")) ~ \"Mother & Father\",\n",
    "      TRUE ~ \"Unknown\"\n",
    "    )\n",
    "  )\n",
    "\n",
    "# inspect data:\n",
    "# caregiver_type %>%\n",
    "#     kbl(format=\"pipe\")\n",
    "    \n",
    "# ggplot(caregiver_type, aes(x = 1, y = caregiver_type, fill = factor(caregiver_type))) + \n",
    "#   geom_col() +\n",
    "#   coord_polar(theta = \"y\") +\n",
    "#   theme_void()\n",
    "\n",
    "rand_dat_inc_cg <- rand_dat_inc_cg %>%\n",
    "  left_join(caregiver_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_swu_stats = (rand_dat_inc_cg.groupby([\"Language_name\",\"target_child_id\",\"transcript_id\",\"contingent\"])\n",
    "                                  .swu\n",
    "                                  .agg([\"mean\"])\n",
    "                                  .reset_index())\n",
    "rand_swu_sumstats =  rand_swu_stats.rename({'mean': 'means'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f25041a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NULL\n"
     ]
    }
   ],
   "source": [
    "%%R -i rand_swu_sumstats\n",
    "\n",
    "# ^import rand_swu_sumstats into R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd132507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joining with `by = join_by(transcript_id)`\n"
     ]
    }
   ],
   "source": [
    "%%R -o rand_swu_sumstats\n",
    "\n",
    "rand_swu_sumstats <- rand_swu_sumstats %>%\n",
    "    left_join(caregiver_type) %>%\n",
    "    filter(Language_name != \"Mandarin\") %>%\n",
    "    filter(Language_name != \"Polish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data to file:\n",
    "rand_swu_sumstats.to_csv(\"../data/rand_swu_sumstats.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "xlabs <- c(\"C\", \"NC\")\n",
    "\n",
    "# # ara_label <- data.frame(means=c(.9),contingent = c(1.5),language=\"ara\")\n",
    "deu_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"German\")\n",
    "# deu_ns_label <- data.frame(means=c(.5),contingent = c(1.5),Language_name=\"German\")\n",
    "eng_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"English\")\n",
    "est_label <- data.frame(means=c(.5),contingent = c(1.5),Language_name=\"Estonian\")\n",
    "# est_ns_label <- data.frame(means=c(.5),contingent = c(1.5),Language_name=\"Estonian\")\n",
    "fas_label <- data.frame(means=c(.5),contingent = c(1.5),Language_name=\"Persian\")\n",
    "fra_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"French\")\n",
    "hrv_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"Croatian\")\n",
    "jpn_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"Japanese\")\n",
    "kor_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"Korean\")\n",
    "nor_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"Norwegian\")\n",
    "# pol_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"Polish\")\n",
    "por_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"Portuguese\")\n",
    "spa_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"Spanish\")\n",
    "swe_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"Swedish\")\n",
    "tse_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"Tseltal\")\n",
    "# zho_label <- data.frame(means=c(.5),contingent = c(1.5),Language_name=\"Mandarin\")\n",
    "\n",
    "\n",
    "p <- ggplot(rand_swu_sumstats, aes(x = contingent, y = means, color = Language_name)) +\n",
    "     stat_summary(fun.y=mean, geom=\"point\", shape=19, size=1.75) + \n",
    "     stat_summary(fun.data = mean_se, geom = \"errorbar\", size=1.25, width = .5) +\n",
    "     facet_wrap(. ~ Language_name,ncol = 7) + \n",
    "     geom_text(data = deu_label,label = \"***\",size=8,color=\"black\") +\n",
    "     geom_text(data = eng_label,label = \"***\",size=8,color=\"black\") +  \n",
    "     geom_text(data = est_label,label = \"ns\", size=4,color=\"black\",fontface = \"italic\") +  \n",
    "     geom_text(data = fas_label,label = \"ns\", size=4,color=\"black\",fontface = \"italic\") + \n",
    "     geom_text(data = fra_label,label = \"***\",size=8,color=\"black\") +  \n",
    "     geom_text(data = hrv_label,label = \"***\",size=8,color=\"black\") + \n",
    "     geom_text(data = jpn_label,label = \"***\",size=8,color=\"black\") + \n",
    "     geom_text(data = kor_label,label = \"***\",size=8,color=\"black\") +  \n",
    "     geom_text(data = nor_label,label = \"**\",size=8,color=\"black\") +  \n",
    "     # geom_text(data = pol_label,label = \"ns\", size=4,color=\"black\",fontface = \"italic\") +    \n",
    "     geom_text(data = por_label,label = \"***\",size=8,color=\"black\") +  \n",
    "     geom_text(data = spa_label,label = \"***\",size=8,color=\"black\") + \n",
    "     geom_text(data = swe_label,label = \"***\",size=8,color=\"black\") + \n",
    "     # geom_text(data = zho_label,label = \"ns\", size=4, color=\"black\",fontface = \"italic\") +\n",
    "     ylim(0, .5) +\n",
    "     labs(tag=\"C\",\n",
    "          y = \"Proportion of Single Word Utterances\",\n",
    "          x = \"\") +\n",
    "     theme_classic() +\n",
    "     scale_x_discrete(labels= xlabs) +\n",
    "     theme(text = element_text(size=16),\n",
    "           axis.text.x = element_text(vjust = 0.5, hjust = 0.5),\n",
    "           legend.title = element_blank(),\n",
    "           legend.background = element_rect(fill=alpha(\"white\",0.90),\n",
    "                                                            size=0, linetype=\"dotted\",\n",
    "                                                            colour = \"white\"),\n",
    "           legend.text=element_text(size=16))\n",
    "      ggsave(\"../figures/token_rand_swu.pdf\", width = 11.7, height = 6.2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for manuscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i rand_swu_sumstats\n",
    "\n",
    "library('ggplot2')\n",
    "library('repr')\n",
    "options(repr.plot.width=6, repr.plot.height=12)\n",
    "\n",
    "xlabs <- c(\"C\", \"NC\")\n",
    "\n",
    "# # ara_label <- data.frame(means=c(.9),contingent = c(1.5),language=\"ara\")\n",
    "deu_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"German\")\n",
    "# deu_ns_label <- data.frame(means=c(.5),contingent = c(1.5),Language_name=\"German\")\n",
    "eng_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"English\")\n",
    "est_label <- data.frame(means=c(.5),contingent = c(1.5),Language_name=\"Estonian\")\n",
    "# est_ns_label <- data.frame(means=c(.5),contingent = c(1.5),Language_name=\"Estonian\")\n",
    "fas_label <- data.frame(means=c(.5),contingent = c(1.5),Language_name=\"Persian\")\n",
    "fra_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"French\")\n",
    "hrv_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"Croatian\")\n",
    "jpn_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"Japanese\")\n",
    "kor_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"Korean\")\n",
    "nor_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"Norwegian\")\n",
    "# pol_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"Polish\")\n",
    "por_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"Portuguese\")\n",
    "spa_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"Spanish\")\n",
    "swe_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"Swedish\")\n",
    "tse_label <- data.frame(means=c(.47),contingent = c(1.5),Language_name=\"Tseltal\")\n",
    "# zho_label <- data.frame(means=c(.5),contingent = c(1.5),Language_name=\"Mandarin\")\n",
    "\n",
    "\n",
    "p <- ggplot(rand_swu_sumstats, aes(x = contingent, y = means, color = Language_name)) +\n",
    "     stat_summary(fun.y=mean, geom=\"point\", shape=19, size=1.75) + \n",
    "     stat_summary(fun.data = mean_se, geom = \"errorbar\", size=1.25, width = .5) +\n",
    "     facet_wrap(. ~ Language_name,ncol = 7) + \n",
    "     geom_text(data = deu_label,label = \"***\",size=8,color=\"black\") +\n",
    "     geom_text(data = eng_label,label = \"***\",size=8,color=\"black\") +  \n",
    "     geom_text(data = est_label,label = \"ns\", size=4,color=\"black\",fontface = \"italic\") +  \n",
    "     geom_text(data = fas_label,label = \"ns\", size=4,color=\"black\",fontface = \"italic\") + \n",
    "     geom_text(data = fra_label,label = \"***\",size=8,color=\"black\") +  \n",
    "     geom_text(data = hrv_label,label = \"***\",size=8,color=\"black\") + \n",
    "     geom_text(data = jpn_label,label = \"***\",size=8,color=\"black\") + \n",
    "     geom_text(data = kor_label,label = \"***\",size=8,color=\"black\") +  \n",
    "     geom_text(data = nor_label,label = \"**\",size=8,color=\"black\") +  \n",
    "     # geom_text(data = pol_label,label = \"ns\", size=4,color=\"black\",fontface = \"italic\") +    \n",
    "     geom_text(data = por_label,label = \"***\",size=8,color=\"black\") +  \n",
    "     geom_text(data = spa_label,label = \"***\",size=8,color=\"black\") + \n",
    "     geom_text(data = swe_label,label = \"***\",size=8,color=\"black\") + \n",
    "     geom_text(data = tse_label,label = \"\", size=8, color=\"black\") +\n",
    "     # geom_text(data = zho_label,label = \"ns\", size=4, color=\"black\",fontface = \"italic\") +\n",
    "     ylim(0, .5) +\n",
    "     labs(tag=\"C\",\n",
    "          y = \"Proportion of Single Word Utterances\",\n",
    "          x = \"\") +\n",
    "     theme_classic() +\n",
    "     scale_x_discrete(labels= xlabs) +\n",
    "     theme(text = element_text(size=11.5),\n",
    "           axis.text.x = element_text(vjust = 0.5, hjust=0.5),\n",
    "           legend.position=\"none\")\n",
    "\n",
    "      ggsave(\"../figures/figure_2_C.pdf\", width = 11.5, height = 4.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e79df3d",
   "metadata": {},
   "source": [
    "Descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "819e74ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`summarise()` has grouped output by 'Language_name'. You can override using the\n",
      "`.groups` argument.\n",
      "\n",
      "\n",
      "|Language   |Contingent M (SD) |Non-Contingent M (SD) |\n",
      "|:----------|:-----------------|:---------------------|\n",
      "|Croatian   |0.25 (0.1)        |0.19 (0.08)           |\n",
      "|English    |0.29 (0.21)       |0.19 (0.1)            |\n",
      "|Estonian   |0.18 (0.08)       |0.12 (0.05)           |\n",
      "|French     |0.24 (0.19)       |0.2 (0.13)            |\n",
      "|German     |0.26 (0.1)        |0.18 (0.1)            |\n",
      "|Japanese   |0.49 (0.13)       |0.31 (0.08)           |\n",
      "|Korean     |0.18 (0.08)       |0.1 (0.05)            |\n",
      "|Norwegian  |0.31 (0.24)       |0.23 (0.27)           |\n",
      "|Persian    |0.44 (0.14)       |0.32 (0.09)           |\n",
      "|Portuguese |0.17 (0.11)       |0.15 (0.1)            |\n",
      "|Spanish    |0.26 (0.06)       |0.16 (0.07)           |\n",
      "|Swedish    |0.33 (0.1)        |0.2 (0.08)            |\n",
      "|Tseltal    |0.42 (0.14)       |0.29 (0.08)           |\n"
     ]
    }
   ],
   "source": [
    "%%R -i rand_swu_sumstats\n",
    "\n",
    "rand_swu_sumstats %>%\n",
    "    group_by(Language_name, contingent) %>%\n",
    "    summarize(mean = mean(means),\n",
    "              sd = sd(means)) %>%\n",
    "    pivot_wider(names_from = contingent, values_from = c(mean, sd)) %>%\n",
    "    select(Language_name, mean_contingent, sd_contingent, `mean_non-contingent`, `sd_non-contingent`) %>%\n",
    "    `colnames<-`(c(\"Language\", \"Contingent Mean\", \"Contingent SD\", \"Non-Contingent Mean\", \"Non-Contingent SD\")) %>%\n",
    "    mutate(across(where(is.numeric), ~ round(., 2))) %>%\n",
    "    unite(\"Contingent M (SD)\", \"Contingent Mean\", \"Contingent SD\", sep = \" (\", na.rm = TRUE) %>%\n",
    "    mutate(`Contingent M (SD)` = paste0(`Contingent M (SD)`, \")\")) %>%\n",
    "    unite(\"Non-Contingent M (SD)\", \"Non-Contingent Mean\", \"Non-Contingent SD\", sep = \" (\", na.rm = TRUE) %>%\n",
    "    mutate(`Non-Contingent M (SD)` = paste0(`Non-Contingent M (SD)`, \")\")) %>%\n",
    "    kbl(\"pipe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a4be46",
   "metadata": {},
   "source": [
    "#### Statistical analyses\n",
    "\n",
    "By language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef4b624b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SWU_dat = rand_dat_inc_cg[['Language_name','swu','contingent','transcript_id','target_child_id','caregiver_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ffc8588",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: boundary (singular) fit: see help('isSingular')\n",
      "\n",
      "R[write to console]: boundary (singular) fit: see help('isSingular')\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'pbkrtest.limit = 6241' (or larger)\n",
      "[or, globally, 'set emm_options(pbkrtest.limit = 6241)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'lmerTest.limit = 6241' (or larger)\n",
      "[or, globally, 'set emm_options(lmerTest.limit = 6241)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'pbkrtest.limit = 100059' (or larger)\n",
      "[or, globally, 'set emm_options(pbkrtest.limit = 100059)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'lmerTest.limit = 100059' (or larger)\n",
      "[or, globally, 'set emm_options(lmerTest.limit = 100059)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Cannot use mode = \"kenward-roger\" because *pbkrtest* package is not installed\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'pbkrtest.limit = 21178' (or larger)\n",
      "[or, globally, 'set emm_options(pbkrtest.limit = 21178)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'lmerTest.limit = 21178' (or larger)\n",
      "[or, globally, 'set emm_options(lmerTest.limit = 21178)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'pbkrtest.limit = 4452' (or larger)\n",
      "[or, globally, 'set emm_options(pbkrtest.limit = 4452)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'lmerTest.limit = 4452' (or larger)\n",
      "[or, globally, 'set emm_options(lmerTest.limit = 4452)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'pbkrtest.limit = 25124' (or larger)\n",
      "[or, globally, 'set emm_options(pbkrtest.limit = 25124)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'lmerTest.limit = 25124' (or larger)\n",
      "[or, globally, 'set emm_options(lmerTest.limit = 25124)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Cannot use mode = \"kenward-roger\" because *pbkrtest* package is not installed\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'pbkrtest.limit = 4375' (or larger)\n",
      "[or, globally, 'set emm_options(pbkrtest.limit = 4375)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'lmerTest.limit = 4375' (or larger)\n",
      "[or, globally, 'set emm_options(lmerTest.limit = 4375)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Cannot use mode = \"kenward-roger\" because *pbkrtest* package is not installed\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'pbkrtest.limit = 4615' (or larger)\n",
      "[or, globally, 'set emm_options(pbkrtest.limit = 4615)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Note: D.f. calculations have been disabled because the number of observations exceeds 3000.\n",
      "To enable adjustments, add the argument 'lmerTest.limit = 4615' (or larger)\n",
      "[or, globally, 'set emm_options(lmerTest.limit = 4615)' or larger];\n",
      "but be warned that this may result in large computation time and memory use.\n",
      "\n",
      "R[write to console]: Cannot use mode = \"kenward-roger\" because *pbkrtest* package is not installed\n",
      "\n",
      "R[write to console]: Cannot use mode = \"kenward-roger\" because *pbkrtest* package is not installed\n",
      "\n",
      "R[write to console]: Cannot use mode = \"kenward-roger\" because *pbkrtest* package is not installed\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in `mutate()`:\n",
      "ℹ In argument: `statistic = coalesce(z.ratio)`.\n",
      "ℹ In group 1: `Language_name = \"Persian\"`.\n",
      "Caused by error:\n",
      "! object 'z.ratio' not found\n",
      "Run `rlang::last_trace()` to see where the error occurred.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: There were 11 warnings (use warnings() to see them)\n",
      "R[write to console]: \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in mutate(., statistic = coalesce(z.ratio), .before = p.value) : \n",
      "ℹ In group 1: `Language_name = \"Persian\"`.\n",
      "Caused by error:\n",
      "! object 'z.ratio' not found\n"
     ]
    },
    {
     "ename": "RInterpreterError",
     "evalue": "Failed to parse and evaluate line '\\nSWU_dat <- SWU_dat %>%\\n    filter(Language_name != \"Mandarin\") %>%\\n    filter(Language_name != \"Polish\")\\n\\n# vectors for rows to remove from lmer\\ncase_study <- c(\"Persian\") # only 1 target child analyzed\\n\\ncase_study_cgtype_compare <- c(\"Korean\") # only 1 target child analyzed, varies in CG type\\n\\nno_cgtype_compare <- c(\"Portuguese\", \"Tseltal\") # only `Mother only`\\n\\n# single_tran <- c(\"Polish\") # only 1 transcript\\n\\n# nests of models\\nswu_nest1 <- SWU_dat %>%\\n    filter(!Language_name %in% case_study) %>%\\n    filter(!Language_name %in% no_cgtype_compare) %>%\\n    filter(!Language_name %in% case_study_cgtype_compare) %>%\\n    group_by(Language_name) %>%\\n    nest() %>%\\n    mutate(fit = map(data, ~ lmer(swu ~ contingent + caregiver_type +\\n                                (1|target_child_id) +\\n                                (1|transcript_id),\\n                                data = .,\\n                                REML= FALSE)),\\n           summary = map(fit, ~ emmeans(., \"contingent\"), lmer.df = \"asymp\"),\\n           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\\n           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\\n    select(Language_name, contrasts, effect_size) %>%\\n    unnest(cols = c(contrasts)) %>%\\n    mutate(effect_size = map(effect_size, ~ summary(.))) %>%\\n    unnest() %>%\\n    mutate(statistic = coalesce(`z.ratio`,`t.ratio`), .before = p.value) %>%\\n    select (-c(`z.ratio`,`t.ratio`))\\n\\nswu_nest2 <- SWU_dat %>%\\n    filter(Language_name %in% case_study_cgtype_compare) %>%\\n    group_by(Language_name) %>%\\n    nest() %>%\\n    mutate(fit = map(data, ~ lmer(swu ~ contingent + caregiver_type +\\n                                (1|transcript_id),\\n                                data = .,\\n                                REML= FALSE)),\\n           summary = map(fit, ~ emmeans(., \"contingent\"), lmer.df = \"asymp\"),\\n           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\\n           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\\n    select(Language_name, contrasts, effect_size) %>%\\n    unnest(cols = c(contrasts)) %>%\\n    mutate(effect_size = map(effect_size, ~ summary(.))) %>%\\n    unnest() %>%\\n    mutate(statistic = coalesce(`z.ratio`), .before = p.value) %>%\\n    select (-c(`z.ratio`))\\n\\nswu_nest3 <- SWU_dat %>%\\n    filter(Language_name %in% no_cgtype_compare) %>%\\n    group_by(Language_name) %>%\\n    nest() %>%\\n    mutate(fit = map(data, ~ lmer(swu ~ contingent +\\n                                (1|target_child_id) +\\n                                (1|transcript_id),\\n                                data = .,\\n                                REML= FALSE)),\\n           summary = map(fit, ~ emmeans(., \"contingent\"), lmer.df = \"asymp\"),\\n           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\\n           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\\n    select(Language_name, contrasts, effect_size) %>%\\n    unnest(cols = c(contrasts)) %>%\\n    mutate(effect_size = map(effect_size, ~ summary(.))) %>%\\n    unnest() %>%\\n    mutate(statistic = coalesce(`t.ratio`), .before = p.value) %>%\\n    select (-c(`t.ratio`))\\n\\nswu_nest4 <- SWU_dat %>%\\n    filter(Language_name %in% case_study) %>%\\n    group_by(Language_name) %>%\\n    nest() %>%\\n    mutate(fit = map(data, ~ lmer(swu ~ contingent +\\n                                (1|transcript_id),\\n                                data = .,\\n                                REML= FALSE)),\\n           summary = map(fit, ~ emmeans(., \"contingent\"), lmer.df = \"asymp\"),\\n           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\\n           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\\n    select(Language_name, contrasts, effect_size) %>%\\n    unnest(cols = c(contrasts)) %>%\\n    mutate(effect_size = map(effect_size, ~ summary(.))) %>%\\n    unnest() %>%\\n    mutate(statistic = coalesce(`z.ratio`), .before = p.value) %>%\\n    select (-c(`z.ratio`))\\n \\n# number of transcripts per language\\nsample_size <- SWU_dat %>%\\n    group_by(Language_name) %>%\\n    summarize(n = n_distinct(transcript_id))\\n    \\n# combine lmer summaries and correct p-values for multiple comparisons\\nemms_all <- list(swu_nest1, swu_nest2, swu_nest3, swu_nest4) %>% \\n    reduce(bind_rows) %>%\\n    mutate(p.value = p.adjust(p.value, \"holm\", 13)) %>%\\n    left_join(sample_size)\\n'.\nR error message: 'Error in mutate(., statistic = coalesce(z.ratio), .before = p.value) : \\nℹ In group 1: `Language_name = \"Persian\"`.\\nCaused by error:\\n! object \\'z.ratio\\' not found'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRRuntimeError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/rpy2/ipython/rmagic.py:385\u001b[0m, in \u001b[0;36mRMagics.eval\u001b[0;34m(self, code)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;66;03m# Need the newline in case the last line in code is a comment.\u001b[39;00m\n\u001b[0;32m--> 385\u001b[0m     value, visible \u001b[38;5;241m=\u001b[39m \u001b[43mro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwithVisible(\u001b[39;49m\u001b[38;5;124;43m{\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m})\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ri\u001b[38;5;241m.\u001b[39membedded\u001b[38;5;241m.\u001b[39mRRuntimeError, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;66;03m# Otherwise next return seems to have copy of error.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/rpy2/robjects/__init__.py:459\u001b[0m, in \u001b[0;36mR.__call__\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    458\u001b[0m p \u001b[38;5;241m=\u001b[39m rinterface\u001b[38;5;241m.\u001b[39mparse(string)\n\u001b[0;32m--> 459\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conversion\u001b[38;5;241m.\u001b[39mget_conversion()\u001b[38;5;241m.\u001b[39mrpy2py(res)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/rpy2/robjects/functions.py:208\u001b[0m, in \u001b[0;36mSignatureTranslatedFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m         kwargs[r_k] \u001b[38;5;241m=\u001b[39m v\n\u001b[0;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSignatureTranslatedFunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/rpy2/robjects/functions.py:131\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m         new_kwargs[k] \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mpy2rpy(v)\n\u001b[0;32m--> 131\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mFunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m res \u001b[38;5;241m=\u001b[39m cv\u001b[38;5;241m.\u001b[39mrpy2py(res)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/rpy2/rinterface_lib/conversion.py:45\u001b[0m, in \u001b[0;36m_cdata_res_to_rinterface.<locals>._\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 45\u001b[0m     cdata \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# TODO: test cdata is of the expected CType\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/rpy2/rinterface.py:817\u001b[0m, in \u001b[0;36mSexpClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m error_occured[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 817\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m embedded\u001b[38;5;241m.\u001b[39mRRuntimeError(_rinterface\u001b[38;5;241m.\u001b[39m_geterrmessage())\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[0;31mRRuntimeError\u001b[0m: Error in mutate(., statistic = coalesce(z.ratio), .before = p.value) : \nℹ In group 1: `Language_name = \"Persian\"`.\nCaused by error:\n! object 'z.ratio' not found\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRInterpreterError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mR\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m-i SWU_dat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mSWU_dat <- SWU_dat \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    filter(Language_name != \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMandarin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m) \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    filter(Language_name != \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPolish\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# vectors for rows to remove from lmer\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mcase_study <- c(\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPersian\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m) # only 1 target child analyzed\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mcase_study_cgtype_compare <- c(\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mKorean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m) # only 1 target child analyzed, varies in CG type\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mno_cgtype_compare <- c(\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPortuguese\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTseltal\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m) # only `Mother only`\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# single_tran <- c(\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPolish\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m) # only 1 transcript\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# nests of models\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mswu_nest1 <- SWU_dat \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    filter(!Language_name \u001b[39;49m\u001b[38;5;132;43;01m%i\u001b[39;49;00m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;132;43;01m% c\u001b[39;49;00m\u001b[38;5;124;43mase_study) \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    filter(!Language_name \u001b[39;49m\u001b[38;5;132;43;01m%i\u001b[39;49;00m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m no_cgtype_compare) \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    filter(!Language_name \u001b[39;49m\u001b[38;5;132;43;01m%i\u001b[39;49;00m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;132;43;01m% c\u001b[39;49;00m\u001b[38;5;124;43mase_study_cgtype_compare) \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    group_by(Language_name) \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    nest() \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    mutate(fit = map(data, ~ lmer(swu ~ contingent + caregiver_type +\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                                (1|target_child_id) +\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                                (1|transcript_id),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                                data = .,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                                REML= FALSE)),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m           summary = map(fit, ~ emmeans(., \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontingent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m), lmer.df = \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43masymp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m           contrasts = map(summary, ~ summary(contrast(., method = \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpairwise\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m))),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    select(Language_name, contrasts, effect_size) \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    unnest(cols = c(contrasts)) \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    mutate(effect_size = map(effect_size, ~ summary(.))) \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    unnest() \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    mutate(statistic = coalesce(`z.ratio`,`t.ratio`), .before = p.value) \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    select (-c(`z.ratio`,`t.ratio`))\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mswu_nest2 <- SWU_dat \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    filter(Language_name \u001b[39;49m\u001b[38;5;132;43;01m%i\u001b[39;49;00m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;132;43;01m% c\u001b[39;49;00m\u001b[38;5;124;43mase_study_cgtype_compare) \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    group_by(Language_name) \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    nest() \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    mutate(fit = map(data, ~ lmer(swu ~ contingent + caregiver_type +\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                                (1|transcript_id),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                                data = .,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                                REML= FALSE)),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m           summary = map(fit, ~ emmeans(., \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontingent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m), lmer.df = \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43masymp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m           contrasts = map(summary, ~ summary(contrast(., method = \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpairwise\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m))),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    select(Language_name, contrasts, effect_size) \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    unnest(cols = c(contrasts)) \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    mutate(effect_size = map(effect_size, ~ summary(.))) \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    unnest() \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    mutate(statistic = coalesce(`z.ratio`), .before = p.value) \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    select (-c(`z.ratio`))\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mswu_nest3 <- SWU_dat \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    filter(Language_name \u001b[39;49m\u001b[38;5;132;43;01m%i\u001b[39;49;00m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m no_cgtype_compare) \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    group_by(Language_name) \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    nest() \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    mutate(fit = map(data, ~ lmer(swu ~ contingent +\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                                (1|target_child_id) +\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                                (1|transcript_id),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                                data = .,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                                REML= FALSE)),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m           summary = map(fit, ~ emmeans(., \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontingent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m), lmer.df = \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43masymp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m           contrasts = map(summary, ~ summary(contrast(., method = \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpairwise\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m))),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    select(Language_name, contrasts, effect_size) \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    unnest(cols = c(contrasts)) \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    mutate(effect_size = map(effect_size, ~ summary(.))) \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    unnest() \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    mutate(statistic = coalesce(`t.ratio`), .before = p.value) \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    select (-c(`t.ratio`))\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mswu_nest4 <- SWU_dat \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    filter(Language_name \u001b[39;49m\u001b[38;5;132;43;01m%i\u001b[39;49;00m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;132;43;01m% c\u001b[39;49;00m\u001b[38;5;124;43mase_study) \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    group_by(Language_name) \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    nest() \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    mutate(fit = map(data, ~ lmer(swu ~ contingent +\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                                (1|transcript_id),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                                data = .,\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                                REML= FALSE)),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m           summary = map(fit, ~ emmeans(., \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontingent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m), lmer.df = \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43masymp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m           contrasts = map(summary, ~ summary(contrast(., method = \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpairwise\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m))),\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    select(Language_name, contrasts, effect_size) \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    unnest(cols = c(contrasts)) \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    mutate(effect_size = map(effect_size, ~ summary(.))) \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    unnest() \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    mutate(statistic = coalesce(`z.ratio`), .before = p.value) \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    select (-c(`z.ratio`))\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# number of transcripts per language\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43msample_size <- SWU_dat \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    group_by(Language_name) \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    summarize(n = n_distinct(transcript_id))\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m# combine lmer summaries and correct p-values for multiple comparisons\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43memms_all <- list(swu_nest1, swu_nest2, swu_nest3, swu_nest4) \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    reduce(bind_rows) \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    mutate(p.value = p.adjust(p.value, \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mholm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m, 13)) \u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    left_join(sample_size)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2478\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2476\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2477\u001b[0m     args \u001b[38;5;241m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2478\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2480\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2481\u001b[0m \u001b[38;5;66;03m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2482\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/rpy2/ipython/rmagic.py:943\u001b[0m, in \u001b[0;36mRMagics.R\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m e\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mendswith(e\u001b[38;5;241m.\u001b[39merr):\n\u001b[1;32m    942\u001b[0m         \u001b[38;5;28mprint\u001b[39m(e\u001b[38;5;241m.\u001b[39merr)\n\u001b[0;32m--> 943\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    945\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01min\u001b[39;00m DEVICES_STATIC:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/rpy2/ipython/rmagic.py:923\u001b[0m, in \u001b[0;36mRMagics.R\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m    921\u001b[0m         return_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 923\u001b[0m     text_result, result, visible \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    924\u001b[0m     text_output \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m text_result\n\u001b[1;32m    925\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m visible:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/rpy2/ipython/rmagic.py:389\u001b[0m, in \u001b[0;36mRMagics.eval\u001b[0;34m(self, code)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ri\u001b[38;5;241m.\u001b[39membedded\u001b[38;5;241m.\u001b[39mRRuntimeError, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;66;03m# Otherwise next return seems to have copy of error.\u001b[39;00m\n\u001b[1;32m    388\u001b[0m     warning_or_other_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m--> 389\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RInterpreterError(code, \u001b[38;5;28mstr\u001b[39m(exception),\n\u001b[1;32m    390\u001b[0m                             warning_or_other_msg)\n\u001b[1;32m    391\u001b[0m text_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m text_output, value, visible[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mRInterpreterError\u001b[0m: Failed to parse and evaluate line '\\nSWU_dat <- SWU_dat %>%\\n    filter(Language_name != \"Mandarin\") %>%\\n    filter(Language_name != \"Polish\")\\n\\n# vectors for rows to remove from lmer\\ncase_study <- c(\"Persian\") # only 1 target child analyzed\\n\\ncase_study_cgtype_compare <- c(\"Korean\") # only 1 target child analyzed, varies in CG type\\n\\nno_cgtype_compare <- c(\"Portuguese\", \"Tseltal\") # only `Mother only`\\n\\n# single_tran <- c(\"Polish\") # only 1 transcript\\n\\n# nests of models\\nswu_nest1 <- SWU_dat %>%\\n    filter(!Language_name %in% case_study) %>%\\n    filter(!Language_name %in% no_cgtype_compare) %>%\\n    filter(!Language_name %in% case_study_cgtype_compare) %>%\\n    group_by(Language_name) %>%\\n    nest() %>%\\n    mutate(fit = map(data, ~ lmer(swu ~ contingent + caregiver_type +\\n                                (1|target_child_id) +\\n                                (1|transcript_id),\\n                                data = .,\\n                                REML= FALSE)),\\n           summary = map(fit, ~ emmeans(., \"contingent\"), lmer.df = \"asymp\"),\\n           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\\n           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\\n    select(Language_name, contrasts, effect_size) %>%\\n    unnest(cols = c(contrasts)) %>%\\n    mutate(effect_size = map(effect_size, ~ summary(.))) %>%\\n    unnest() %>%\\n    mutate(statistic = coalesce(`z.ratio`,`t.ratio`), .before = p.value) %>%\\n    select (-c(`z.ratio`,`t.ratio`))\\n\\nswu_nest2 <- SWU_dat %>%\\n    filter(Language_name %in% case_study_cgtype_compare) %>%\\n    group_by(Language_name) %>%\\n    nest() %>%\\n    mutate(fit = map(data, ~ lmer(swu ~ contingent + caregiver_type +\\n                                (1|transcript_id),\\n                                data = .,\\n                                REML= FALSE)),\\n           summary = map(fit, ~ emmeans(., \"contingent\"), lmer.df = \"asymp\"),\\n           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\\n           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\\n    select(Language_name, contrasts, effect_size) %>%\\n    unnest(cols = c(contrasts)) %>%\\n    mutate(effect_size = map(effect_size, ~ summary(.))) %>%\\n    unnest() %>%\\n    mutate(statistic = coalesce(`z.ratio`), .before = p.value) %>%\\n    select (-c(`z.ratio`))\\n\\nswu_nest3 <- SWU_dat %>%\\n    filter(Language_name %in% no_cgtype_compare) %>%\\n    group_by(Language_name) %>%\\n    nest() %>%\\n    mutate(fit = map(data, ~ lmer(swu ~ contingent +\\n                                (1|target_child_id) +\\n                                (1|transcript_id),\\n                                data = .,\\n                                REML= FALSE)),\\n           summary = map(fit, ~ emmeans(., \"contingent\"), lmer.df = \"asymp\"),\\n           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\\n           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\\n    select(Language_name, contrasts, effect_size) %>%\\n    unnest(cols = c(contrasts)) %>%\\n    mutate(effect_size = map(effect_size, ~ summary(.))) %>%\\n    unnest() %>%\\n    mutate(statistic = coalesce(`t.ratio`), .before = p.value) %>%\\n    select (-c(`t.ratio`))\\n\\nswu_nest4 <- SWU_dat %>%\\n    filter(Language_name %in% case_study) %>%\\n    group_by(Language_name) %>%\\n    nest() %>%\\n    mutate(fit = map(data, ~ lmer(swu ~ contingent +\\n                                (1|transcript_id),\\n                                data = .,\\n                                REML= FALSE)),\\n           summary = map(fit, ~ emmeans(., \"contingent\"), lmer.df = \"asymp\"),\\n           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\\n           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\\n    select(Language_name, contrasts, effect_size) %>%\\n    unnest(cols = c(contrasts)) %>%\\n    mutate(effect_size = map(effect_size, ~ summary(.))) %>%\\n    unnest() %>%\\n    mutate(statistic = coalesce(`z.ratio`), .before = p.value) %>%\\n    select (-c(`z.ratio`))\\n \\n# number of transcripts per language\\nsample_size <- SWU_dat %>%\\n    group_by(Language_name) %>%\\n    summarize(n = n_distinct(transcript_id))\\n    \\n# combine lmer summaries and correct p-values for multiple comparisons\\nemms_all <- list(swu_nest1, swu_nest2, swu_nest3, swu_nest4) %>% \\n    reduce(bind_rows) %>%\\n    mutate(p.value = p.adjust(p.value, \"holm\", 13)) %>%\\n    left_join(sample_size)\\n'.\nR error message: 'Error in mutate(., statistic = coalesce(z.ratio), .before = p.value) : \\nℹ In group 1: `Language_name = \"Persian\"`.\\nCaused by error:\\n! object \\'z.ratio\\' not found'"
     ]
    }
   ],
   "source": [
    "%%R -i SWU_dat\n",
    "\n",
    "SWU_dat <- SWU_dat %>%\n",
    "    filter(Language_name != \"Mandarin\") %>%\n",
    "    filter(Language_name != \"Polish\")\n",
    "\n",
    "# vectors for rows to remove from lmer\n",
    "case_study <- c(\"Persian\") # only 1 target child analyzed\n",
    "\n",
    "case_study_cgtype_compare <- c(\"Korean\") # only 1 target child analyzed, varies in CG type\n",
    "\n",
    "no_cgtype_compare <- c(\"Portuguese\", \"Tseltal\") # only `Mother only`\n",
    "\n",
    "# single_tran <- c(\"Polish\") # only 1 transcript\n",
    "\n",
    "# nests of models\n",
    "swu_nest1 <- SWU_dat %>%\n",
    "    filter(!Language_name %in% case_study) %>%\n",
    "    filter(!Language_name %in% no_cgtype_compare) %>%\n",
    "    filter(!Language_name %in% case_study_cgtype_compare) %>%\n",
    "    group_by(Language_name) %>%\n",
    "    nest() %>%\n",
    "    mutate(fit = map(data, ~ lmer(swu ~ contingent + caregiver_type +\n",
    "                                (1|target_child_id) +\n",
    "                                (1|transcript_id),\n",
    "                                data = .,\n",
    "                                REML= FALSE)),\n",
    "           summary = map(fit, ~ emmeans(., \"contingent\"), lmer.df = \"asymp\"),\n",
    "           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\n",
    "           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\n",
    "    select(Language_name, contrasts, effect_size) %>%\n",
    "    unnest(cols = c(contrasts)) %>%\n",
    "    mutate(effect_size = map(effect_size, ~ summary(.))) %>%\n",
    "    unnest() %>%\n",
    "    mutate(statistic = coalesce(`z.ratio`,`t.ratio`), .before = p.value) %>%\n",
    "    select (-c(`z.ratio`,`t.ratio`))\n",
    "\n",
    "swu_nest2 <- SWU_dat %>%\n",
    "    filter(Language_name %in% case_study_cgtype_compare) %>%\n",
    "    group_by(Language_name) %>%\n",
    "    nest() %>%\n",
    "    mutate(fit = map(data, ~ lmer(swu ~ contingent + caregiver_type +\n",
    "                                (1|transcript_id),\n",
    "                                data = .,\n",
    "                                REML= FALSE)),\n",
    "           summary = map(fit, ~ emmeans(., \"contingent\"), lmer.df = \"asymp\"),\n",
    "           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\n",
    "           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\n",
    "    select(Language_name, contrasts, effect_size) %>%\n",
    "    unnest(cols = c(contrasts)) %>%\n",
    "    mutate(effect_size = map(effect_size, ~ summary(.))) %>%\n",
    "    unnest() %>%\n",
    "    mutate(statistic = coalesce(`z.ratio`), .before = p.value) %>%\n",
    "    select (-c(`z.ratio`))\n",
    "\n",
    "swu_nest3 <- SWU_dat %>%\n",
    "    filter(Language_name %in% no_cgtype_compare) %>%\n",
    "    group_by(Language_name) %>%\n",
    "    nest() %>%\n",
    "    mutate(fit = map(data, ~ lmer(swu ~ contingent +\n",
    "                                (1|target_child_id) +\n",
    "                                (1|transcript_id),\n",
    "                                data = .,\n",
    "                                REML= FALSE)),\n",
    "           summary = map(fit, ~ emmeans(., \"contingent\"), lmer.df = \"asymp\"),\n",
    "           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\n",
    "           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\n",
    "    select(Language_name, contrasts, effect_size) %>%\n",
    "    unnest(cols = c(contrasts)) %>%\n",
    "    mutate(effect_size = map(effect_size, ~ summary(.))) %>%\n",
    "    unnest() %>%\n",
    "    mutate(statistic = coalesce(`t.ratio`), .before = p.value) %>%\n",
    "    select (-c(`t.ratio`))\n",
    "\n",
    "swu_nest4 <- SWU_dat %>%\n",
    "    filter(Language_name %in% case_study) %>%\n",
    "    group_by(Language_name) %>%\n",
    "    nest() %>%\n",
    "    mutate(fit = map(data, ~ lmer(swu ~ contingent +\n",
    "                                (1|transcript_id),\n",
    "                                data = .,\n",
    "                                REML= FALSE)),\n",
    "           summary = map(fit, ~ emmeans(., \"contingent\"), lmer.df = \"asymp\"),\n",
    "           contrasts = map(summary, ~ summary(contrast(., method = \"pairwise\"))),\n",
    "           effect_size = map2(summary, fit, ~ eff_size(.x, sigma = sigma(.y), edf = df.residual(.y)))) %>%\n",
    "    select(Language_name, contrasts, effect_size) %>%\n",
    "    unnest(cols = c(contrasts)) %>%\n",
    "    mutate(effect_size = map(effect_size, ~ summary(.))) %>%\n",
    "    unnest() %>%\n",
    "    mutate(statistic = coalesce(`z.ratio`), .before = p.value) %>%\n",
    "    select (-c(`z.ratio`))\n",
    " \n",
    "# number of transcripts per language\n",
    "sample_size <- SWU_dat %>%\n",
    "    group_by(Language_name) %>%\n",
    "    summarize(n = n_distinct(transcript_id))\n",
    "    \n",
    "# combine lmer summaries and correct p-values for multiple comparisons\n",
    "emms_all <- list(swu_nest1, swu_nest2, swu_nest3, swu_nest4) %>% \n",
    "    reduce(bind_rows) %>%\n",
    "    mutate(p.value = p.adjust(p.value, \"holm\", 13)) %>%\n",
    "    left_join(sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb51a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "|Language (n)    |Estimate (SE) | Test statistic| Effect size|Adjusted p-value |\n",
      "|:---------------|:-------------|--------------:|-----------:|:----------------|\n",
      "|Croatian (58)   |0.07 (0.01)   |           6.50|        0.17|<.0001           |\n",
      "|English (882)   |0.11 (0)      |          30.11|        0.27|<.0001           |\n",
      "|Estonian (22)   |0.04 (0.01)   |           2.88|        0.13|0.0525           |\n",
      "|French (279)    |0.05 (0.01)   |           7.75|        0.13|<.0001           |\n",
      "|German (38)     |0.08 (0.01)   |           6.49|        0.20|<.0001           |\n",
      "|Japanese (160)  |0.18 (0.01)   |          27.63|        0.37|<.0001           |\n",
      "|Korean (28)     |0.08 (0.01)   |           8.04|        0.26|<.0001           |\n",
      "|Norwegian (28)  |0.1 (0.02)    |           4.79|        0.25|<.0001           |\n",
      "|Persian (12)    |0.07 (0.02)   |           3.57|        0.15|0.0047           |\n",
      "|Portuguese (23) |0.07 (0.01)   |           4.91|        0.20|<.0001           |\n",
      "|Spanish (30)    |0.09 (0.01)   |           7.44|        0.23|<.0001           |\n",
      "|Swedish (16)    |0.14 (0.02)   |           7.87|        0.32|<.0001           |\n",
      "|Tseltal (10)    |0.14 (0.02)   |           6.66|        0.31|<.0001           |\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "table_maker = function(data) { data %>%\n",
    "    select(Language_name, n, estimate, SE, statistic, effect.size, p.value) %>%\n",
    "    `colnames<-`(c(\"Language\", \"n\", \"Estimate\", \"SE\", \"Test statistic\", \"Effect size\", \"Adjusted p-value\")) %>%\n",
    "    mutate_at(vars(-c(`Adjusted p-value`,Language)), round,2) %>%\n",
    "    mutate(`Adjusted p-value` = format(round(`Adjusted p-value`,4),nsmall=4)) %>%\n",
    "    mutate(`Adjusted p-value` = gsub(\"0.0000\",\"<.0001\",`Adjusted p-value`)) %>%\n",
    "    unite(\"Estimate (SE)\", c('Estimate','SE'), sep=\" (\") %>%\n",
    "    mutate(`Estimate (SE)` = paste0(`Estimate (SE)`,\")\")) %>%\n",
    "    unite(\"Language (n)\", c('Language','n'), sep=\" (\") %>%\n",
    "    mutate(`Language (n)` = paste0(`Language (n)`,\")\")) %>%\n",
    "    arrange(`Language (n)`)\n",
    "    }\n",
    "\n",
    "SWU_stats_table <- table_maker(emms_all)\n",
    "\n",
    "kable(SWU_stats_table, \"pipe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c587537f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
